---
title             : "The Transition to Grandparenthood and its Impact on the Big Five Personality Traits and Life Satisfaction"
shorttitle        : "Grandparenthood, Big Five, and Life Satisfaction"



author: 
  - name          : "Michael D. Kr&auml;mer" # I've noticed that Umlaute can pose a problem when knitting on Windows 
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "German Institute for Economic Research, Mohrenstr. 58, 10117 Berlin, Germany"
    email         : "mkraemer@diw.de"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Data Curation
      - Formal Analysis
      - Methodology
      - Visualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "Manon A. van Scheppingen"
    affiliation   : "3"
    role:
      - Methodology
      - Writing - Review & Editing
  - name          : "William J. Chopik"
    affiliation   : "4"
    role:
      - Methodology
      - Writing - Review & Editing
  - name          : "David Richter"
    affiliation   : "1,4"
    role:
      - Supervision
      - Methodology
      - Writing - Review & Editing
      
affiliation:
  - id            : "1"
    institution   : "German Institute for Economic Research, Germany"
  - id            : "2"
    institution   : "International Max Planck Research School on the Life Course (LIFE), Germany"
  - id            : "3"
    institution   : "Tilburg University, Netherlands"
  - id            : "4"
    institution   : "Michigan State University, USA"
  - id            : "5"
    institution   : "Freie Universit&auml;t Berlin, Germany"

note: "\\clearpage"

authornote: |
  \addORCIDlink{Michael D. KrÃ¤mer}{0000-0002-9883-5676}, Socio-Economic Panel (SOEP), German Institute for Economic Research (DIW Berlin); International Max Planck Research School on the Life Course (LIFE), Max Planck Institute for Human Development  
  Manon A. van Scheppingen, Department of Developmental Psychology, Tilburg School of Social and Behavioral Sciences, Tilburg University  
  William J. Chopik, Department of Psychology, Michigan State University  
  David Richter, Socio-Economic Panel (SOEP), German Institute for Economic Research (DIW Berlin); Survey Research Division, Department of Education and Psychology, Freie Universit&auml;t Berlin  

abstract: |
 abc  

keywords          : "grandparenthood, Big Five, life satisfaction, development, propensity score matching"
wordcount         : "abc"

bibliography      : ["references-zotero.bib", "references-r.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

csl               : "apa.csl"
documentclass     : "apa7"
classoption       : "man, noextraspace"
output            : papaja::apa6_pdf

header-includes:
  - \usepackage{setspace}
  - \usepackage{amsmath}
#  - \usepackage{float} # these two prevent some weird floating behavior of the figures
#  - \floatplacement{figure}{H}
  - \AtBeginEnvironment{tabular}{\singlespacing}
  - \AtBeginEnvironment{lltable}{\singlespacing}
  - \AtBeginEnvironment{tablenotes}{\doublespacing}
  - \captionsetup[table]{font={stretch=1.5}}
  - \captionsetup[figure]{font={stretch=1.5}}
#  - \raggedbottom # prevents LaTeX from varying the spacing between paragraphs to minimise empty space on pages
#  - \usepackage{floatrow}  # https://github.com/crsh/papaja/issues/342
#  - \floatsetup[figure]{capposition=top}

appendix: gp-manuscript-papaja-appendix.Rmd

---

```{r setup, include = FALSE}
library("papaja") # not on CRAN, see https://github.com/crsh/papaja
library("citr")
library("multcomp") # for confint of linearHypothesis
library("tidyverse")
library("psych") # for 'describe' demographics
library("GPArotation") # needed for omega function in psych
#library("robustlmm") # for robust estimation (appendix)
library("lme4")
library("lmerTest")
#library("interactions") # for plotting interactions
#library("jtools") # for plot config
library("cowplot") # for plot grid
#library("effects")
#library("patchwork") # for plot grid
library("scales")
library("car") # for linearHypothesis
#library("careless") 
#library("corrplot") # appendix
#library("magick") # needed for figure cropping
#library("png") # appendix: external png file
#library("grid") # also needed for external png file because knitr::include_graphics() is buggy
r_refs("references-r.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

# Set default chunk options (can be overridden in later chunks)
knitr::opts_chunk$set(echo = FALSE, 
                      eval = TRUE,
                      message = FALSE, 
                      fig.path='Figs/',
                      fig.width = 7, 
                      fig.height = 7,
                      results = "hide",
                      error = FALSE,
                      warning = FALSE,
                      include = TRUE,
                      cache = FALSE)
```

```{r load data, include=FALSE}
#setwd("")

# Instead of specifying setwd() in the script, choose the working directory from the console after setting option in Rstudio:
# Tools -> Global Options -> R Markdown -> Evaluate chunks in directory
# The default working directory is the directory of the Rmd file (option "Document"). 
# Change this option to the current working directory of your R console (option "Current"), and then change
# your working directory via the console to the location where all the files are located.

# If you don't see this option, then execute install.packages("rmarkdown), close RStudio, and open again.

#source("") # This executes data import & cleaning.

# load final analyses samples
load(file = "data/processed/LISS/lissanalysis_parents.rda")
load(file = "data/processed/LISS/lissanalysis_nonparents.rda")
load(file = "data/processed/HRS/hrsanalysis_parents.rda")
load(file = "data/processed/HRS/hrsanalysis_nonparents.rda")

# these are for sample size numbers (not contained in the final analysis files, anymore)
load(file = "data/processed/LISS/liss_sampleflow_gp.rda")
load(file = "data/processed/LISS/liss_sampleflow_nongp.rda")
load(file = "data/processed/LISS/liss_replacement_controls.rda")
load(file = "data/processed/HRS/hrs_sampleflow_gp.rda")
load(file = "data/processed/HRS/hrs_sampleflow_nongp.rda")
load(file = "data/processed/HRS/hrs_replacement_controls.rda")

# PSM balance tables
load(file = "data/processed/LISS/liss_balance_df.rda")
load(file = "data/processed/HRS/hrs_balance_df.rda")
```
Becoming a grandparent is a pivotal life event for many people in midlife or old age [@infurnaMidlife2020sOpportunities2020]. At the same time, there is considerable heterogeneity in how intensely grandparents are involved in their grandchildren's lives and care [@meyerGrandparentingUnitedStates2017]. In the context of an aging demographic, the time that grandparents are alive and in good health during grandparenthood is prolonged compared to previous generations [@margolisHealthyGrandparenthoodHow2017; @leopoldDemographyGrandparenthoodInternational2015]. In addition, an increased share of childcare functions are being fulfilled by grandparents [@hayslipGrandparentsRaisingGrandchildren2019; @pilkauskasHistoricalTrendsChildren2020]. Thus, intergenerational relations have received heightened attention from psychological and sociological research in recent years [@bengtsonNuclearFamilyIncreasing2001; @coallGrandparentalInvestmentRelic2011]. With regard to personality development, the transition to grandparenthood has been posited as an important developmental task in old age [@huttemanDevelopmentalTasksFramework2014]. However, empirical research into the psychological consequences of becoming a grandparent is sparse. Testing hypotheses derived from neo-socioanalytic theory [@robertsPersonalityDevelopmentContext2006] in a prospective matched control-group design [see @luhmannStudyingChangesLife2014], we investigate whether the transition to grandparenthood affects the Big Five personality traits and life satisfaction using data from two nationally representative panel studies.  

## Personality Development in Middle Adulthood and Old Age

The life span perspective characterizes aging as a lifelong process of development and adaptation [@baltesLifeSpanTheory2006]. In accordance with this perspective, research has found personality traits to be subject to change throughout the entire life span [@spechtWhatDrivesAdult2014; @spechtPersonalityDevelopmentAdulthood2017; @costaPersonalityLifeSpan2019; @grahamTrajectoriesBigFive2020; for recent reviews, see @bleidornPersonalityTraitStability2021; @robertsPersonalityPsychology2021]. Although a major portion of personality development takes place in adolescence and emerging adulthood [@schwabaIndividualDifferencesPersonality2018; @bleidornPersonalityDevelopmentEmerging2017], evidence has accumulated that personality traits also undergo changes in middle and old adulthood [e.g., @allemandLongtermCorrelatedChange2008a; @damianSixteenGoingSixtysix2019; @kandlerPatternsSourcesPersonality2015a; @lucasPersonalityDevelopmentLife2011; @mottusPersonalityTraitsOld2012; @muellerPersonalityDevelopmentOld2016; @wagnerPersonalityTraitDevelopment2016; for a review, see @spechtPersonalityDevelopmentAdulthood2017].  
Here, we examine the Big Five personality traits---agreeableness, conscientiousness, extraversion, neuroticism, and openness to experiences---which constitute a broad categorization of universal patterns of thought, affect, and behavior [@johnParadigmShiftIntegrative2008]. While the policy relevance of the Big Five personality traits has recently been emphasized [@bleidornPolicyRelevancePersonality2019]---especially because of their predictive power regarding many important life outcomes [@ozerPersonalityPredictionConsequential2005; @robertsPowerPersonalityComparative2007; @sotoHowReplicableAre2019; @sotoLinksPersonalityLife2021], we acknowledge that there are other viable taxonomies of personality [@ashtonEmpiricalTheoreticalPractical2007; @ashtonObjectionsHEXACOModel2020] and other levels of breadth and scope that could add valuable insights to personality development in middle adulthood and old age [@mottusDevelopmentDetailsAge2021; @mottusPersonalityTraitsFacets2017].  
Changes over time in the Big Five occur both in mean trait levels [i.e., mean-level change; @robertsPatternsMeanlevelChange2006a] and in the relative ordering of people to each other on trait dimensions [i.e., rank-order stability; @anusicStabilityChangePersonality2016; @robertsRankorderConsistencyPersonality2000]. No observed changes in mean trait levels do not necessarily mean that individual trait levels are stable over time, and perfect rank-order stability does not preclude mean-level changes. Mean-level changes in middle adulthood [ca. 30--60 years old; @huttemanDevelopmentalTasksFramework2014] are typically characterized in terms of greater maturity as evidenced by increased agreeableness and conscientiousness, and decreased neuroticism [@robertsPatternsMeanlevelChange2006a; @damianSixteenGoingSixtysix2019]. In old age [ca. 60 years and older; @huttemanDevelopmentalTasksFramework2014], research is generally more sparse but there is some evidence for a reversal of the maturity effect, especially following retirement [sometimes termed *la dolce vita* effect; @asselmannPersonalityMaturationPersonality2021; @marshMeasurementInvarianceBigfive2013; cf. @schwabaPersonalityTraitDevelopment2019] and at the end of life in ill health [@wagnerPersonalityTraitDevelopment2016].  
In terms of rank-order stability, some prior studies have shown support for an inverted U-shape trajectory [@ardeltStillStableAll2000; @lucasPersonalityDevelopmentLife2011; @spechtStabilityChangePersonality2011; @wortmanStabilityChangeBig2012]: Rank-order stability rises until reaching a plateau in midlife, and decreases, again, in old age. However, evidence is mixed whether rank-order stability actually decreases again in old age [see @costaPersonalityLifeSpan2019]. Nonetheless, the historical view that personality is stable, or "set like plaster" [@spechtPersonalityDevelopmentAdulthood2017, p. 64] after one reaches adulthood [or leaves emerging adulthood behind; @bleidornPersonalityDevelopmentEmerging2017] can largely be abandoned [@spechtWhatDrivesAdult2014].  
Theories explaining the mechanisms of personality development in middle adulthood and old age emphasize both genetic influences and life experiences as interdependent sources of stability and change [@wagnerIntegrativeModelSources2020; @spechtWhatDrivesAdult2014]. In a behavior-genetic twin study, Kandler et al. [-@kandlerPatternsSourcesPersonality2015a] found that non-shared environmental factors were the main source of personality plasticity in old age.<!-- delete sentence & focus on theory? --> Here, we conceptualize the transition to grandparenthood as a life experience that offers the adoption of a new social role according to the social investment principle of neo-socioanalytic theory [@robertsPersonalityDevelopmentContext2006; @lodi-smithSocialInvestmentPersonality2007]. According to the social investment principle, normative life events or transitions such as entering the work force or becoming a parent lead to personality maturation through the adoption of new social roles [@robertsEvaluatingFiveFactor2005]. These new roles encourage or compel people to act in a more agreeable, conscientious, and emotionally stable (i.e., less neurotic) way, and the experiences in these roles as well as societal expectations towards them are hypothesized to drive long-term personality development [@lodi-smithSocialInvestmentPersonality2007; @wrzusProcessesPersonalityDevelopment2017]. Conversely, consistent social roles foster personality stability.  
The paradoxical theory of personality coherence [@caspiWhenIndividualDifferences1993] offers another explanation for personality development through role shifts stating that trait change is more likely whenever people transition into unknown environments where pre-existing behavioral responses are no longer appropriate and societal norms or social expectations give clear indications how to behave instead. On the other hand, stability is favored in environments where no clear guidance how to behave is available. Thus, the finding that age-graded, normative life experiences, such as the transition to grandparenthood, drive personality development would also be in line with the paradoxical theory of personality coherence [see @spechtWhatDrivesAdult2014]. Compared to the transition to parenthood, however, societal expectations on how grandparents should behave (e.g., "Grandparents should help parents with childcare if needed") are less clearly defined and strongly dependent on the degree of (possible) grandparental investment [@lodi-smithSocialInvestmentPersonality2007]. Thus, societal expectations and role demands might differ depending on how close grandparents live to their children, the quality of the relationship with their children, and other sociodemographic factors that exert conflicting role demands [@bordonePatternsGrandparentalChild2017; @lumsdaineRetirementTimingWomen2015; @silversteinHowAmericansEnact2001; cf. @mullerGrandparentingWellbeingHow2011]. In the whole population of first-time grandparents this diversity of role investment might generate pronounced interindividual differences in intraindividual personality change.  
Empirically, certain life events such as the first romantic relationship [@wagnerFirstPartnershipExperience2015] or the transition from high school to university or the first job [@ludtkeRandomWalkUniversity2011; @asselmannPersonalityMaturationPersonality2021] have (partly) been found to be accompanied by mean-level increases in line with the social investment principle [for a review, see @bleidornLifeEventsPersonality2018]. However, recent evidence regarding the transition to parenthood failed to empirically support the social investment principle [@asselmannTestingSocialInvestment2020; @vanscheppingenPersonalityTraitDevelopment2016]. An analysis of monthly trajectories of the Big Five before and after nine major life events only found limited support for the social investment principle: small increases were found in emotional stability following the transition to employment but not for the other traits or for the other life events theoretically linked to social investment [@denissenTransactionsLifeEvents2019]. Recently, it has also been emphasized that effects of life events on the Big Five personality trends generally tend to be small and need to be properly analyzed using robust, prospective designs, and appropriate control groups [@bleidornLifeEventsPersonality2018; @luhmannStudyingChangesLife2014].  
Overall, much remains unknown regarding the environmental factors underlying personality development in middle adulthood and old age. One indication that age-graded, normative life experiences contribute to change following a period of relative stability in midlife is offered by recent research on retirement [@bleidornRetirementAssociatedChange2018; @schwabaPersonalityTraitDevelopment2019]. These results were only partly in line with the social investment principle in terms of mean-level changes and displayed substantial individual differences in change trajectories. The authors discuss that as social role "divestment" [@schwabaPersonalityTraitDevelopment2019, p. 660] retirement functions differently compared to social investment in the classical sense which adds a role. The transition to grandparenthood could represent such an investment into a new role in middle adulthood and old age---given that grandparents have regular contact with their grandchild and actively take part in childcare to some degree [i.e., invest psychologically in the new grandparent role; @lodi-smithSocialInvestmentPersonality2007].  

## Grandparenthood

The transition to grandparenthood, that is, the birth of the first grandchild, can be described as a time-discrete life event marking the beginning of one's status as a grandparent [@luhmannSubjectiveWellbeingAdaptation2012]. In terms of characteristics of major life events [@luhmannDimensionalTaxonomyPerceived2020], the transition to grandparenthood stands out in that it is externally caused [by one's own children; see also @arpinoFamilyHistoriesDemography2018; @margolisCohortPerspectiveDemography2019], while at the same time being predictable as soon as one's children reveal their pregnancy or family planning. The transition to grandparenthood has been labeled a countertransition due to this lack of direct control over if and when someone has their first grandchild [@hagestadAgeLifeCourse1985; as cited in @arpinoFamilyHistoriesDemography2018]. Grandparenthood is also generally positive in valence and emotionally significant---given one maintains a good relationship with their child.  
Grandparenthood can also be characterized as a developmental task [@huttemanDevelopmentalTasksFramework2014] mostly associated with the period of (early) old age---although considerable variation in the age at the transition to grandparenthood exists both within and between cultures [@leopoldDemographyGrandparenthoodInternational2015; @skopekWhoBecomesGrandparent2017]. Still, the period where parents on average experience the birth of their first grandchild coincides with the end of (relative) stability in terms of personality development in midlife [@spechtPersonalityDevelopmentAdulthood2017], where retirement, shifting social roles, and initial cognitive and health declines can be disruptive to life circumstances putting personality development into motion [e.g., @muellerPersonalityDevelopmentOld2016; @stephanPhysicalActivityPersonality2014]. As a developmental task, grandparenthood is expected to be part of a normative sequence of aging that is subject to societal expectations and values differing across cultures and historical time [@huttemanDevelopmentalTasksFramework2014; @baltesLifeSpanTheory2006].  
Mastering developmental tasks (i.e., fulfilling roles and expectations to a high degree) is hypothesized to drive personality development towards maturation similarly to propositions by the social investment principle, that is, leading to higher levels of agreeableness and conscientiousness, and lower levels of neuroticism [@robertsEvaluatingFiveFactor2005; @robertsPersonalityDevelopmentContext2006]. In comparison to the transition to parenthood which has been found to be ambivalent in terms of both personality maturation and life satisfaction [@kramerImpactHavingChildren2020; @vanscheppingenPersonalityTraitDevelopment2016; @aassveFirstGlanceBlack2021; @johnsonImpactHavingChildren2006], Hutteman et al. [-@huttemanDevelopmentalTasksFramework2014] hypothesize that the transition to grandparenthood is generally seen as positive because it (usually) does not impose the stressful demands of daily childcare on grandparents. Grandparental investment in their grandchildren has been discussed as beneficial in terms of the evolutionary, economic, and sociological advantages it provides for the whole intergenerational family structure [@coallGrandparentalInvestmentRelic2011; @coallInterdisciplinaryPerspectivesGrandparental2018].  
While we could not find prior studies investigating development of the Big Five over the transition to grandparenthood, there is some evidence on changes in life satisfaction over the transition to grandparenthood. <!--We define life satisfaction as the general, cognitive appraisal of one's well-being in life based on subjective criteria [@eidScienceSubjectiveWellbeing2008].--> In cross-sectional studies, the preponderance of evidence suggests that grandparents who provide grandchild care or have close relationships with their older grandchildren have higher life satisfaction [e.g., @mahneGrandparenthoodSubjectiveWellBeing2014; @triadoGrandparentsWhoProvide2014]. There are a few longitudinal studies, albeit they offer conflicting conclusions: Data from the Survey of Health, Ageing and Retirement in Europe (SHARE) showed that the birth of a grandchild was followed by improvements to quality of life and life satisfaction, but only among women [@tanskanenTransitionGrandparenthoodSubjective2019] and only in first-time grandmothers via their daughters [@digessaBecomingGrandparentIts2019]. Several studies emphasized that grandparents actively involved in childcare experienced larger increases in life satisfaction [@arpinoGrandparentingEducationSubjective2018; @danielsbackaAssociationGrandparentalInvestment2016; @danielsbackaGrandparentalChildcareHealth2019]. On the other hand, fixed effects regression models[^f2] using SHARE data did not find any effects of first-time grandparenthood on life satisfaction regardless of grandparental investment and only minor decreases of grandmothers' depressive symptoms [@sheppardBecomingFirstTimeGrandparent2019].  
In a similar vein, some prospective studies reported beneficial effects of the transition to grandparenthood and of grandparental childcare investment on various health measures, especially in women  [@chungLongitudinalEffectsGrandchild2018; @condonTransitionGrandparenthoodProspective2018; @digessaHealthImpactIntensive2016; @digessaImpactCaringGrandchildren2016]. Again, beneficial effects on self-rated health did not persevere in fixed effects analyses as reported in Ates [-@atesDoesGrandchildCare2017] who used longitudinal data from the German Aging Survey (DEAS).  <!-- add sentence addressing this conflicting evidence (why?) --> <!-- add paragraph from demographic literature? -->  
We are not aware of any study investigating the rank-order stability of traits over the transition to grandparenthood. The occurrence of other life events has been shown to be associated with the rank-order stability of personality and well-being, although only for certain events and traits [e.g., @denissenTransactionsLifeEvents2019; @hentschelInfluenceMajorLife2017; @spechtStabilityChangePersonality2011].  

[^f2]: Fixed effects regression models exclusively rely on within-person variance [see @bruderlFixedEffectsPanelRegression2015; @mcneishFixedEffectsModels2019].  

## Current Study

In the current study, we revisit the development of life satisfaction across the transition to grandparenthood. We extend this research to psychological development in a more general sense by examining the development of Big Five personality traits. Three research questions motivate the current study which is the first to analyze Big Five personality development over the transition to grandparenthood:

1. What are the effects of the transition to grandparenthood on mean-level trajectories of the Big Five traits and life satisfaction?
2. How large are interindividual differences in intraindividual change for the Big Five traits and life satisfaction over the transition to grandparenthood?
3. How does the transition to grandparenthood affect rank-order stability of the Big Five traits and life satisfaction?

To address these questions, we compare development over the transition to grandparenthood with that of matched participants who do not experience the transition during the study period [@luhmannStudyingChangesLife2014]. This is necessary because pre-existing differences between prospective grandparents and non-grandparents in variables related to the development of the Big Five or life satisfaction introduce confounding bias when estimating the effects of the transition to grandparenthood [@vanderweeleOutcomeWideLongitudinalDesigns2020]. The impact of adjusting (or not adjusting) for pre-existing differences, or background characteristics, has recently been emphasized in the prediction of life outcomes from personality in a mega-analytic framework of ten large panel studies [@beckMegaAnalysisPersonalityPrediction2021]. Propensity score matching is one technique to account for confounding bias by equating the groups in their estimated propensity to experience the event in question [@thoemmesSystematicReviewPropensity2011]. This propensity is calculated from regressing the so-called treatment variable (i.e., the group variable indicating whether someone experienced the event) on covariates related to the likelihood of experiencing the event and to the outcomes. This approach addresses confounding bias by creating balance between the groups in the covariates used to calculate the propensity score [@stuartMatchingMethodsCausal2010].  
We adopt a prospective design that tests the effects of becoming first-time grandparents separately against two propensity-score-matched control groups: first, a matched control group of parents (but not grandparents) with at least one child in reproductive age, and, second, a matched control group of nonparents. Adopting two control groups allows us to disentangle potential effects attributable to becoming a grandparent from effects attributable to being a parent already, thus addressing selection effects into grandparenthood and confounding more comprehensively than previous research. Thereby, we cover the first two of the three causal pathways to not experiencing grandparenthood pointed out by demographic research [@margolisCohortPerspectiveDemography2019]: one's own childlessness, childlessness of one's children, and not living long enough to become a grandparent. Our comparative design also controls for average age-related and historical trends in the Big Five traits and life satisfaction [@luhmannStudyingChangesLife2014], and enables us to report effects of the transition to grandparenthood unconfounded by instrumentation effects, which describe the tendency of reporting lower well-being scores with each repeated measurement [@bairdLifeSatisfactionLifespan2010] [^f12].  
We improve upon previous longitudinal studies utilizing matched control groups [e.g., @anusicDoesPersonalityModerate2014; @anusicTestingSetpointTheory2014; @yapDoesPersonalityModerate2012] in that we performed the matching at a specific time point preceding the transition to grandparenthood (at least two years beforehand) and not based on individual survey years. This design choice ensures that the covariates involved in the matching procedure are not already influenced by the event or anticipation of it [@greenlandQuantifyingBiasesCausal2003; @rosenbaumConsquencesAdjustmentConcomitant1984; @vanderweeleOutcomeWideLongitudinalDesigns2020; @vanderweelePrinciplesConfounderSelection2019], thereby reducing the risk of confounding through collider bias [@elwertEndogenousSelectionBias2014]. Similar approaches in the study of life events have recently been adopted [@balboRoleFamilyOrientations2016; @vanscheppingenTrajectoriesLifeSatisfaction2020; @kramerImpactHavingChildren2020].  
Informed by the social investment principle and previous research on personality development in middle adulthood and old age, we preregistered the following hypotheses (prior to data analysis; https://osf.io/a9zpc/):

* H1a: Following the birth of their first grandchild, grandparents increase in agreeableness and conscientiousness, and decrease in neuroticism compared to the matched control groups of parents (but not grandparents) and nonparents. We do not expect the groups to differ in their trajectories of extraversion and openness to experience.
* H1b: Grandparents' post-transition increases in agreeableness and conscientiousness, and decreases in neuroticism are more pronounced among those who provide substantial grandchild care.
* H1c: Grandmothers increase in life satisfaction following the transition to grandparenthood as compared to the matched control groups but grandfathers do not.
* H2: Individual differences in intraindividual change in the Big Five and life satisfaction are larger in the grandparent group than the control groups.
* H3: Compared to the matched control groups, grandparents' rank-order stability of the Big Five and life satisfaction over the transition to grandparenthood is smaller.<!-- add in intro a few sentences to establish this hypothesis on rank-order stability, maybe Denissen et al. (2019)? -->

Exploratorily, we further probe the moderator performing paid work which could constitute a potential role conflict among grandparents.

[^f12]: Instrumentation effects caused by repeated assessments have only been described for life satisfaction but we assume similar biases exist for certain Big Five items.<!-- is there any research on this?? -->

# Methods

## Samples

To evaluate these hypotheses, we used data from two population-representative panel studies: the Longitudinal Internet Studies for the Social Sciences (LISS) panel from the Netherlands and the Health and Retirement Study (HRS) from the United States.  
The LISS panel is a representative sample of the Dutch population initiated in 2008 with data collection still ongoing [@scherpenzeelDataCollectionProbabilityBased2011; @vanderlaanRepresentativityLISSPanel2009]. It is administered by CentERdata (Tilburg University, The Netherlands). Included households are a true probability sample of households drawn from the population register [@scherpenzeelTrueLongitudinalProbabilitybased2010]. While originally roughly half of invited households consented to participate, refreshment samples were drawn in order to oversample previously underrepresented groups using information about response rates and their association with demographic variables (household type, age, ethnicity; see https://www.lissdata.nl/about-panel/sample-and-recruitment/). Data collection was carried out online and participants lacking the necessary technical equipment were outfitted with it. We included yearly assessments from 2008 to 2020 from several different modules (see *Measures*) <!-- the so-called focal months for the yearly assessments differ both between modules and across years -->as well as data on basic demographics which was assessed on a monthly rate. For later coding of covariates from these monthly demographic data we used the first available assessment in each year.  
The HRS is an ongoing longitudinal population-representative study of older adults in the US [@sonnegaCohortProfileHealth2014] administered by the Survey Research Center (University of Michigan, United States). Initiated in 1992 with a first cohort of individuals aged 51-61 and their spouses, the study has since been extended with additional cohorts in the 1990s (see https://hrs.isr.umich.edu/documentation/survey-design/). In addition to the HRS core interview every two years (in-person or as a telephone survey), the study has since 2006 included a leave-behind questionnaire covering a broad range of psychosocial topics including the Big Five personality traits and life satisfaction. These topics, however, were only administered every four years starting in 2006 for one half of the sample and in 2008 for the other half. We included personality data from 2006 to 2018, all available data for the coding of the transition to grandparenthood from 1996 to 2018, as well as covariate data from 2006 to 2018 including variables drawn from the Imputations File and the Family Data (only available up to 2014).<!-- 2014 family data is the bottleneck... -->  
These two panel studies provided the advantage that they contained several waves of personality data as well as information on grandparent status and a broad range of covariates at each wave. While the HRS provided a large sample with a wider age range, the LISS panel was smaller and younger[^f3] but provided more frequent personality assessments spaced every one to two years. Note that M. van Scheppingen <!-- anonymize! -->has previously used the LISS panel to analyze correlated changes between life satisfaction and Big Five traits across the lifespan (https://osf.io/3cxuy/). W. Chopik and M. van Scheppingen have previously used the HRS to analyze Big Five traits and relationship-related constructs [@vanscheppingenLongitudinalActorPartner2019]. W. Chopik has additionally used the HRS to analyze mean-level and rank-order changes in Big Five traits in response to bereavement [@chopikDoesPersonalityChange2018] and other relationship-related or non-Big Five-related constructs [e.g., optimism; @chopikChangesOptimismPessimism2020]. These publications do not overlap with the current study in the central focus of grandparenthood.[^f4] The present study used de-identified archival data in the public domain, and, thus, it was not necessary to obtain ethical approval from an IRB.

[^f3]: The reason for the included grandparents from the LISS panel being younger was that grandparenthood questions were part of the *Work and Schooling* module and---for reasons unknown to us---filtered to participants performing paid work. Thus, older, retired first-time grandparents from the LISS panel could not be identified.

[^f4]: Publications using LISS panel data can be searched at https://www.dataarchive.lissdata.nl/publications/. Publications using HRS data can be searched at https://hrs.isr.umich.edu/publications/biblio/. 

```{r internal consistency, results="asis", warning=FALSE, message=FALSE}
# internal consistencies at the time of matching (we use omega but need alpha object for 'keys')
# life satisfaction
alpha_swls_liss <- lissanalysis_parents %>% # LISS
  select(starts_with("swls"), -swls) %>%
  psych::alpha(check.keys = TRUE)
omega_swls_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  select(starts_with("swls"), -swls) %>% 
  psych::omega(m = ., keys = alpha.swls_liss$keys, plot = FALSE, nfactors=1)
omega_swls_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  select(starts_with("swls"), -swls) %>% 
  psych::omega(m = ., keys = alpha.swls_liss$keys, plot = FALSE, nfactors=1)

alpha_swls_hrs <- hrsanalysis_parents %>% # HRS
  select(starts_with("swls"), -swls) %>%
  psych::alpha(check.keys = TRUE)
omega_swls_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  select(starts_with("swls"), -swls) %>% 
  psych::omega(m = ., keys = alpha.swls_hrs$keys, plot = FALSE, nfactors=1)
omega_swls_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  select(starts_with("swls"), -swls) %>% 
  psych::omega(m = ., keys = alpha.swls_hrs$keys, plot = FALSE, nfactors=1)

# Big Five: openness to experience
alpha_open_liss <- lissanalysis_parents %>% # LISS
  select(starts_with("open"), -open) %>%
  psych::alpha(check.keys = TRUE)
omega_open_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  select(starts_with("open"), -open) %>% 
  psych::omega(m = ., keys = alpha.open_liss$keys, plot = FALSE, nfactors=1)
omega_open_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  select(starts_with("open"), -open) %>% 
  psych::omega(m = ., keys = alpha.open_liss$keys, plot = FALSE, nfactors=1)

alpha_open_hrs <- hrsanalysis_parents %>% # HRS
  select(starts_with("open"), -open) %>%
  psych::alpha(check.keys = TRUE)
omega_open_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  select(starts_with("open"), -open) %>% 
  psych::omega(m = ., keys = alpha.open_hrs$keys, plot = FALSE, nfactors=1)
omega_open_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  select(starts_with("open"), -open) %>% 
  psych::omega(m = ., keys = alpha.open_hrs$keys, plot = FALSE, nfactors=1)

# Big Five: conscientiousness
alpha_con_liss <- lissanalysis_parents %>% # LISS
  select(starts_with("con"), -con) %>%
  psych::alpha(check.keys = TRUE)
omega_con_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  select(starts_with("con"), -con) %>% 
  psych::omega(m = ., keys = alpha.con_liss$keys, plot = FALSE, nfactors=1)
omega_con_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  select(starts_with("con"), -con) %>% 
  psych::omega(m = ., keys = alpha.con_liss$keys, plot = FALSE, nfactors=1)

alpha_con_hrs <- hrsanalysis_parents %>% # HRS
  select(starts_with("con"), -con) %>%
  psych::alpha(check.keys = TRUE)
omega_con_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  select(starts_with("con"), -con) %>% 
  psych::omega(m = ., keys = alpha.con_hrs$keys, plot = FALSE, nfactors=1)
omega_con_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  select(starts_with("con"), -con) %>% 
  psych::omega(m = ., keys = alpha.con_hrs$keys, plot = FALSE, nfactors=1)

# Big Five: extraversion
alpha_extra_liss <- lissanalysis_parents %>% # LISS
  select(starts_with("extra"), -extra) %>%
  psych::alpha(check.keys = TRUE)
omega_extra_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  select(starts_with("extra"), -extra) %>% 
  psych::omega(m = ., keys = alpha.extra_liss$keys, plot = FALSE, nfactors=1)
omega_extra_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  select(starts_with("extra"), -extra) %>% 
  psych::omega(m = ., keys = alpha.extra_liss$keys, plot = FALSE, nfactors=1)

alpha_extra_hrs <- hrsanalysis_parents %>% # HRS
  select(starts_with("extra"), -extra) %>%
  psych::alpha(check.keys = TRUE)
omega_extra_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  select(starts_with("extra"), -extra) %>% 
  psych::omega(m = ., keys = alpha.extra_hrs$keys, plot = FALSE, nfactors=1)
omega_extra_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  select(starts_with("extra"), -extra) %>% 
  psych::omega(m = ., keys = alpha.extra_hrs$keys, plot = FALSE, nfactors=1)

# Big Five: agreeableness
alpha_agree_liss <- lissanalysis_parents %>% # LISS
  select(starts_with("agree"), -agree) %>%
  psych::alpha(check.keys = TRUE)
omega_agree_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  select(starts_with("agree"), -agree) %>% 
  psych::omega(m = ., keys = alpha.agree_liss$keys, plot = FALSE, nfactors=1)
omega_agree_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  select(starts_with("agree"), -agree) %>% 
  psych::omega(m = ., keys = alpha.agree_liss$keys, plot = FALSE, nfactors=1)

alpha_agree_hrs <- hrsanalysis_parents %>% # HRS
  select(starts_with("agree"), -agree) %>%
  psych::alpha(check.keys = TRUE)
omega_agree_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  select(starts_with("agree"), -agree) %>% 
  psych::omega(m = ., keys = alpha.agree_hrs$keys, plot = FALSE, nfactors=1)
omega_agree_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  select(starts_with("agree"), -agree) %>% 
  psych::omega(m = ., keys = alpha.agree_hrs$keys, plot = FALSE, nfactors=1)

# Big Five: neuroticism
alpha_neur_liss <- lissanalysis_parents %>% # LISS
  select(starts_with("neur"), -neur) %>%
  psych::alpha(check.keys = TRUE)
omega_neur_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  select(starts_with("neur"), -neur) %>% 
  psych::omega(m = ., keys = alpha.neur_liss$keys, plot = FALSE, nfactors=1)
omega_neur_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  select(starts_with("neur"), -neur) %>% 
  psych::omega(m = ., keys = alpha.neur_liss$keys, plot = FALSE, nfactors=1)

alpha_neur_hrs <- hrsanalysis_parents %>% # HRS
  select(starts_with("neur"), -neur) %>%
  psych::alpha(check.keys = TRUE)
omega_neur_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  select(starts_with("neur"), -neur) %>% 
  psych::omega(m = ., keys = alpha.neur_hrs$keys, plot = FALSE, nfactors=1)
omega_neur_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  select(starts_with("neur"), -neur) %>% 
  psych::omega(m = ., keys = alpha.neur_hrs$keys, plot = FALSE, nfactors=1)

# put all BIg Five omegas in one table 
sample <- rep(c("LISS", "LISS", "HRS", "HRS"), 5)
control <- rep(c("parent", "nonparent", "parent", "nonparent"), 5)
bigfive <- c(rep("openness", 4), rep("conscientiousness", 4), rep("extraversion", 4), 
             rep("agreeableness", 4), rep("neuroticism", 4))
all_omega_big_five <- as.data.frame(cbind(bigfive, sample, control))
omega <- c(omega_open_liss_p$omega.tot, omega_open_liss_np$omega.tot, 
           omega_open_hrs_p$omega.tot, omega_open_hrs_np$omega.tot, 
           omega_con_liss_p$omega.tot, omega_con_liss_np$omega.tot, 
           omega_con_hrs_p$omega.tot, omega_con_hrs_np$omega.tot, 
           omega_extra_liss_p$omega.tot, omega_extra_liss_np$omega.tot, 
           omega_extra_hrs_p$omega.tot, omega_extra_hrs_np$omega.tot, 
           omega_agree_liss_p$omega.tot, omega_agree_liss_np$omega.tot, 
           omega_agree_hrs_p$omega.tot, omega_agree_hrs_np$omega.tot, 
           omega_neur_liss_p$omega.tot, omega_neur_liss_np$omega.tot, 
           omega_neur_hrs_p$omega.tot, omega_neur_hrs_np$omega.tot)
all_omega_big_five <- cbind(all_omega_big_five, omega)
```

## Measures

### Personality 

In the LISS panel, the Big Five personality traits were assessed using the 50-item version of the IPIP Big-Five Inventory scales [@goldbergDevelopmentMarkersBigFive1992]. For each Big Five trait, ten 5-point Likert-scale items were answered (1 = *very inaccurate*, 2 = *moderately inaccurate*, 3 = *neither inaccurate nor accurate*, 4 = *moderately accurate*, 5 = *very accurate*). Example items included "Like order" (conscientiousness),  "Sympathize with others' feelings" (agreeableness), "Worry about things" (neuroticism), "Have a vivid imagination" (openness to experience), and "Start conversations" (extraversion). At each wave, we took a participant's mean of each subscale as their trait score. Internal consistencies at the time of matching, as indicated by McDonald's $\omega$ [@mcneishThanksCoefficientAlpha2018], averaged $\omega =$ `r printnum(all_omega_big_five %>% filter(sample=="LISS") %>% summarise(mean(omega)))` over all traits ranging from $\omega =$ `r printnum(all_omega_big_five %>% filter(sample=="LISS") %>% summarise(min(omega)))` (`r (all_omega_big_five %>% filter(sample=="LISS") %>% arrange(omega))[1,1]` in the `r (all_omega_big_five %>% filter(sample=="LISS") %>% arrange(omega))[1,"control"]` control group) to $\omega =$ `r printnum(all_omega_big_five %>% filter(sample=="LISS") %>% summarise(max(omega)))` (`r (all_omega_big_five %>% filter(sample=="LISS") %>% arrange(desc(omega)))[1,1]` in the `r (all_omega_big_five %>% filter(sample=="LISS") %>% arrange(desc(omega)))[1,"control"]` control group). Other studies have shown measurement invariance for these scales across time and age groups, and convergent validity with the Big Five inventory (BFI-2) [@schwabaIndividualDifferencesPersonality2018; @denissenBigFiveInventory2020]. The Big Five (and life satisfaction) were contained in the *Personality* module which was administered yearly but with planned missingness in some years for certain cohorts [see @denissenTransactionsLifeEvents2019]. Thus, there are one to two years between included assessments, given no other sources of missingness.  
In the HRS, the Midlife Development Inventory (MIDI) scales were administered to measure the Big Five [@lachmanMidlifeDevelopmentInventory1997]. This instrument was constructed for use in large-scale panel studies of adults and consisted of 26 adjectives (five each for conscientiousness, agreeableness, and extraversion, four for neuroticism, and seven for openness to experience). Participants were asked to rate on a 4-point scale how well each item described them (1 = *a lot*, 2 = *some*, 3 = *a little*, 4 = *not at all*). Example adjectives included "Organized" (conscientiousness), "Sympathetic" (agreeableness), "Worrying" (neuroticism), "Imaginative" (openness to experience), and "Talkative" (extraversion). For better comparability with the LISS panel, we reverse scored all items so that higher values corresponded to higher trait levels and, at each wave, took the mean of each subscale as the trait score. Big Five trait scores showed satisfactory internal consistencies at the time of matching which averaged $\omega =$ `r printnum(all_omega_big_five %>% filter(sample=="HRS") %>% summarise(mean(omega)))` over all traits ranging from $\omega =$ `r printnum(all_omega_big_five %>% filter(sample=="HRS") %>% summarise(min(omega)))` (`r (all_omega_big_five %>% filter(sample=="HRS") %>% arrange(omega))[1,1]` in the `r (all_omega_big_five %>% filter(sample=="HRS") %>% arrange(omega))[1,"control"]` control group) to $\omega =$ `r printnum(all_omega_big_five %>% filter(sample=="HRS") %>% summarise(max(omega)))` (`r (all_omega_big_five %>% filter(sample=="HRS") %>% arrange(desc(omega)))[1,1]` in the `r (all_omega_big_five %>% filter(sample=="HRS") %>% arrange(desc(omega)))[1,"control"]` control group).   

### Life Satisfaction 

In both samples, life satisfaction was assessed using the 5-item Satisfaction with Life Scale [SWLS; @dienerSatisfactionLifeScale1985] which participants answered on a 7-point Likert scale (1 = *strongly disagree*, 2 = *somewhat disagree*, 3 = *slightly disagree*, 4 = *neither agree or disagree*, 5 = *slightly agree*, 6 = *somewhat agree*, 7 = *strongly agree*)[^f5]. An example item was "I am satisfied with my life". Internal consistency at the time of matching was $\omega =$ `r printnum(omega_swls_liss_p$omega.tot)` in the LISS panel with the parent control sample ($\omega =$ `r printnum(omega_swls_liss_np$omega.tot)` with the nonparent control sample), and $\omega =$ `r printnum(omega_swls_hrs_p$omega.tot)` in the HRS with the parent control sample ($\omega =$ `r printnum(omega_swls_hrs_np$omega.tot)` with the nonparent control sample).

[^f5]: In the LISS panel, the "somewhat" was omitted and instead of "or" "nor" was used.

### Transition to Grandparenthood

The procedure to obtain information on grandparents' transition to grandparenthood generally followed the same steps in both samples. The items this coding was based on, however, differed slightly: In the LISS panel, participants were asked "Do you have children and/or grandchildren?" with "children", "grandchildren", and "no children or grandchildren" as possible answer categories. This question was part of the *Work and Schooling* module and filtered to participants performing paid work. In the HRS, all participants were asked for the total number of grandchildren: "Altogether, how many grandchildren do you (or your husband / wife / partner, or your late husband / wife / partner) have? Include as grandchildren any children of your (or your [late] husband's / wife's / partner's) biological, step- or adopted children". [^f6]  
In both samples, we tracked grandparenthood status (0 = *no grandchildren*, 1 = *at least one grandchild*) over time. Due to longitudinally inconsistent data in some cases<!-- report N? -->, we included in the grandparent group only participants with exactly one transition from 0 to 1 in this grandparenthood status variable, and no transitions backwards (see Fig. SX). We marked participants who continually indicated that they had no grandchildren as potential members of the control groups.  

[^f6]: The listing of biological, step-, or adopted children has been added since wave 2006.

### Moderators

Based on insights from previous research, we tested three variables as potential moderators of the mean-level trajectories of the Big Five and life satisfaction over the transition to grandparenthood: First, we analyzed whether gender acted as a moderator as indicated by research on life satisfaction [see @tanskanenTransitionGrandparenthoodSubjective2019; @digessaBecomingGrandparentIts2019]. We coded a dummy variable indicating female gender (0 = *male*, 1 = *female*).  
Second, we tested whether performing paid work or not was associated with divergent trajectories of the Big Five and life satisfaction [see @schwabaPersonalityTraitDevelopment2019]. Since the LISS subsample of grandparents we identified was based exclusively on participants performing paid work, we performed these analyses only in the HRS subsample. This served two purposes: to test how participants involved in the workforce (even if officially retired) differed from those not working, which might shed light on role conflict and have implications for the social investment mechanisms we described earlier. As a robustness check, these moderation tests also allowed us to assess whether potential differences in the main results between the LISS and HRS samples could be accounted for by including performing paid work as a moderator in analyses of the HRS sample. In other words, perhaps the results in the HRS participants performing paid work are similar to those seen in the LISS sample, which had already been conditioned on this variable through filtering in the questionnaire.  
Third, we examined how involvement in grandchild care moderated trajectories of the Big Five and life satisfaction in grandparents after the transition to grandparenthood [see @arpinoGrandparentingEducationSubjective2018; @danielsbackaAssociationGrandparentalInvestment2016; @danielsbackaGrandparentalChildcareHealth2019]. We coded a dummy variable (0 = *provided less than 100 hours of grandchild care*, 1 = *provided 100 or more hours of grandchild care*) as a moderator based on the question "Did you (or your [late] husband / wife / partner) spend 100 or more hours in total since the last interview / in the last two years taking care of grand- or great grandchildren?". [^f7] This information was only available for grandparents in the HRS; in the LISS panel, too few participants answered follow-up questions on intensity of care to be included in the analyses (<50 in the final analysis sample).  

[^f7]: Although dichotomization of a continuous construct (hours of care) is not ideal for moderation analysis [@maccallumPracticeDichotomizationQuantitative2002], there were too many missing values in the variable assessing hours of care continuously (variables *E063).

```{r descriptive-stats, results="asis", warning=FALSE, message=FALSE}
# age at transition
liss_descriptive1 <- lissanalysis_parents %>% filter(grandparent==1 & matchtime==time) %>%
  mutate(age_transition = age-matchtime) %>% 
  summarise(age_m=mean(age_transition), age_sd=sd(age_transition), gender_m=mean(female), n=n())
hrs_descriptive1 <- hrsanalysis_parents %>% filter(grandparent==1 & last==time) %>% 
  mutate(age_transition = year-birthyr-last) %>% 
  summarise(age_m=mean(age_transition), age_sd=sd(age_transition), gender_m=mean(gender-1), n=n())

# final n
liss_final_n_parents <- lissanalysis_parents %>% group_by(grandparent) %>% 
  summarise(obs = n(), n = n_distinct(match_number))
liss_final_n_nonparents <- lissanalysis_nonparents %>% group_by(grandparent) %>% 
  summarise(obs = n(), n = n_distinct(match_number))
hrs_final_n_parents <- hrsanalysis_parents %>% group_by(grandparent) %>% 
  summarise(obs = n(), n = n_distinct(match_number))
hrs_final_n_nonparents <- hrsanalysis_nonparents %>% group_by(grandparent) %>% 
  summarise(obs = n(), n = n_distinct(match_number))
```

## Procedure

Drawing on all available data, three main restrictions defined the final analysis samples of grandparents (see Fig. SX for participant flowcharts): First, we identified participants who indicated having grandchildren for the first time during study participation (see *Measures*; $N_{LISS} =$ `r liss_sampleflow_gp[1,2]`; $N_{HRS} =$ `r hrs_sampleflow_gp[1,2]`, including HRS waves 1996-2004 before personality assessments were introduced). Second, we restricted the sample to participants with at least one valid personality assessment (valid in the sense that at least one of the six outcomes was non-missing; $N_{LISS} =$ `r liss_sampleflow_gp[2,2]`; $N_{HRS} =$ `r hrs_sampleflow_gp[2,2]`). [^f8] Third, we included only participants with both a valid personality assessment before and one after the transition to grandparenthood ($N_{LISS} =$ `r liss_sampleflow_gp[3,2]`; $N_{HRS} =$ `r hrs_sampleflow_gp[3,2]`). Lastly, few participants were excluded because of inconsistent or missing information regarding their children[^f9] resulting in the final analysis samples of first-time grandparents, $N_{LISS} =$ `r liss_sampleflow_gp[4,2]` (`r printnum(liss_descriptive1$gender_m*100)`$\%$ female; age at transition to grandparenthood $M =$ `r printnum(liss_descriptive1$age_m)`, $SD =$ `r printnum(liss_descriptive1$age_sd)`) and $N_{HRS} =$ `r hrs_sampleflow_gp[4,2]` (`r printnum(hrs_descriptive1$gender_m*100)`$\%$ female; age at transition to grandparenthood $M =$ `r printnum(hrs_descriptive1$age_m)`, $SD =$ `r printnum(hrs_descriptive1$age_sd)`).  
To disentangle effects of the transition to grandparenthood from effects of being a parent, we defined two pools of potential control subjects to be involved in the matching procedure: The first pool of potential control subjects comprised parents who had at least one child in reproductive age (defined as $15 \leq age_{firstborn}\leq65$) but no grandchildren throughout the observation period ($N_{LISS} =$ `r liss_sampleflow_nongp[1, 3]` with `r liss_sampleflow_nongp[1, 2]` longitudinal observations; $N_{HRS} =$ `r hrs_sampleflow_nongp[1, 3]` with `r hrs_sampleflow_nongp[1, 2]` longitudinal observations). The second pool of potential matches comprised participants who reported being childless throughout the observation period ($N_{LISS} =$ `r liss_sampleflow_nongp[2, 3]` with `r liss_sampleflow_nongp[2, 2]` longitudinal observations; $N_{HRS} =$ `r hrs_sampleflow_nongp[2, 3]` with `r hrs_sampleflow_nongp[2, 2]` longitudinal observations). The two control groups were, thus, by definition mutually exclusive.  
In order to match each grandparent with the control participant who was most similar in terms of the included covariates we utilized propensity score matching. 

### Covariates

For propensity score matching, we used a broad set of covariates [@vanderweeleOutcomeWideLongitudinalDesigns2020] covering participants' demographics (e.g., education), economic situation (e.g., income), and health (e.g., mobility difficulties). We also included the pre-transition outcome variables as covariates---as recommended in the literature [@cookHowMuchBias2020; @hallbergPretestMeasuresStudy2018; @steinerImportanceCovariateSelection2010; @vanderweeleOutcomeWideLongitudinalDesigns2020], as well as the panel wave participation count and assessment year in order to control for instrumentation effects and historical trends [e.g., 2008/2009 financial crisis; @bairdLifeSatisfactionLifespan2010; @luhmannStudyingChangesLife2014]. For matching grandparents with the parent control group we additionally included as covariates variables containing information on fertility and family history (e.g., number of children, age of first three children) which were causally related to the timing of the transition to grandparenthood [i.e., entry into treatment; @arpinoFamilyHistoriesDemography2018; @margolisCohortPerspectiveDemography2019].  
Covariate selection has seldom been explicitly discussed in previous longitudinal studies estimating treatment effects of life events (e.g., in matching designs). We see two (in part conflicting) traditions that address covariate selection: First, classical recommendations from psychology argue to include all available variables that are associated with both the treatment assignment process (i.e., selection into treatment) and the outcome [e.g., @steinerImportanceCovariateSelection2010; @stuartMatchingMethodsCausal2010]<!-- good refs? -->. Second, recommendations from a structural causal modeling perspective [see @elwertEndogenousSelectionBias2014; @rohrerThinkingClearlyCorrelations2018] are more cautious aiming to avoid pitfalls such as conditioning on a pre-treatment collider (collider bias) or a mediator (overcontrol bias). Structural causal modeling, however, requires advanced knowledge of the causal structures underlying all involved variables [@pearlCausalInferenceStatistics2009].  
In selecting covariates, we followed guidelines laid out by VanderWeele et al. [-@vanderweeleOutcomeWideLongitudinalDesigns2020; -@vanderweelePrinciplesConfounderSelection2019] which reconcile both views and offer practical guidance[^f13] when complete knowledge of the underlying causal structures is unknown: These authors propose a "modified disjunctive cause criterion" [@vanderweelePrinciplesConfounderSelection2019, p. 218] recommending to select all available covariates which are assumed to be causes of the outcomes, treatment exposure (i.e., the transition to grandparenthood), or both, as well as any proxies for an unmeasured common cause of the outcomes and treatment exposure. To be excluded from this selection are variables assumed to be instrumental variables (i.e., assumed causes of treatment exposure that are unrelated to the outcomes except through the exposure)<!-- could it be argued that some of our covars are IVs? --> and collider variables [@elwertEndogenousSelectionBias2014]. Because all covariates we used for matching were measured at least two years before the birth of the grandchild, we judge the risk of introducing collider bias or overcontrol bias by controlling for these covariates to be relatively small. In addition, as mentioned in the *Introduction*, the event transition to grandparenthood is not planned by or under direct control of grandparents which further reduces the risk of bias introduced by controlling for pre-treatment colliders.  
An overview of the variables we used to compute the propensity scores for matching can be found in the Supplemental Material (see also Tables \@ref(tab:stddiffmeans-balance-liss) & \@ref(tab:stddiffmeans-balance-hrs)). Critically, we also provide justification for each covariate on whether we assume it to be causally<!-- or just associated? --> related to treatment assignment, the outcomes, or both. We tried to find substantively equivalent covariates in both samples but had to compromise in a few cases (e.g., children's educational level only in HRS vs. children living at home only in LISS).  
Estimating propensity scores requires complete covariate data. Therefore, before computing propensity scores, we performed multiple imputations in order to account for missingness in our covariates [@greenlandCriticalLookMethods1995]. Using five imputed data sets computed by classification and regression trees [CART; @burgetteMultipleImputationMissing2010] in the *mice* R package [@mice2011], we predicted treatment assignment (i.e., the transition to grandparenthood) five times per observation in logistic regressions with a logit link function.[^f10] We averaged these five scores per observation to compute the final propensity score to be used for matching [@mitraComparisonTwoMethods2016]. We used imputed data only for propensity score computation and not in later analyses because missing data in the outcome variables due to nonresponse was negligible.  

[^f10]: In these logistic regressions we included all covariates listed above as predictors except for *female* which was later used for exact matching and health-related covariates in LISS-wave 2014 which were not assessed in that wave.

[^f13]: Practical considerations of covariate selection when using large archival datasets (i.e., with no direct control over data collection) are discussed in VanderWeele et al. [-@vanderweeleOutcomeWideLongitudinalDesigns2020].

### Propensity Score Matching

Propensity score matching was performed in a grandparent's survey year which preceded the year when the transition was first reported by at least two years (aside from that choosing the smallest available gap between matching and transition). This served the purpose to ensure that the covariates used for matching were not affected by the event itself or its anticipation [i.e., when one's child was already pregnant with their first child; @greenlandQuantifyingBiasesCausal2003; @rosenbaumConsquencesAdjustmentConcomitant1984; @vanderweeleOutcomeWideLongitudinalDesigns2020].<!-- problem in HRS: if we match at time==-2 (with the first post-transition assessment at time==2), we don't know when exactly the birth of the first grandchild happened between time==-2 and time==0; not a problem if we match at time==-4 (first post-transition assessment at time==0) --> Propensity score matching was performed using the *MatchIt* R package [@MatchIt2011] with exact matching on gender combined with Mahalanobis distance matching on the propensity score. In total, four matchings were performed; two per sample (LISS; HRS) and two per control group (parents but not grandparents; nonparents). We matched 1:4 with replacement because of the relatively small pools of available non-grandparent controls. This meant that each grandparent was matched with four control observations in each matching procedure, and that control observations were allowed to be used multiple times for matching (i.e., duplicated in the analysis samples[^f11]). We did not specify a caliper because our goal was to find matches for all grandparents, and because we achieved satisfactory covariate balance this way.  
We evaluated the matching procedure in terms of covariate balance and, graphically, in terms of overlap of the distributions of the propensity scores and (non-categorical) covariates [@stuartMatchingMethodsCausal2010]. Covariate balance as indicated by the standardized difference in means between the grandparent and the controls after matching was satisfactory (see Tables \@ref(tab:stddiffmeans-balance-liss) & \@ref(tab:stddiffmeans-balance-hrs)) lying below 0.25 as recommended in the literature [@stuartMatchingMethodsCausal2010], and below 0.10 with few exceptions [@austinIntroductionPropensityScore2011]. Graphically, differences between the distributions of the propensity score and the covariates were also small and indicated no missing overlap (see Fig. SX).  
After matching, each matched control observation received the same value as their matched grandparent in the *time* variable describing the temporal relation to treatment, and the control subject's other longitudinal observations were centered around this matched observation. Thereby, we coded a counterfactual transition time frame for each control subject. Due to left- and right-censored longitudinal data (i.e., panel entry or attrition), we restricted the final analysis samples to six years before and six years after the transition as shown in Table \@ref(tab:piecewise-coding-scheme). We analyzed unbalanced panel data where not every participant provided all person-year observations. The final LISS analysis samples, thus, contained `r liss_final_n_parents$n[2]` grandparents with `r liss_final_n_parents$obs[2]` longitudinal observations, matched with `r liss_final_n_parents$n[1]` control subjects with either `r liss_final_n_parents$obs[1]` (parent control group) or `r liss_final_n_nonparents$obs[1]` longitudinal observations (nonparent control group). The final HRS analysis samples contained `r hrs_final_n_parents$n[2]` grandparents with `r hrs_final_n_parents$obs[2]` longitudinal observations, matched with `r hrs_final_n_parents$n[1]` control subjects with either `r hrs_final_n_parents$obs[1]` (parent control group) or `r hrs_final_n_nonparents$obs[1]` longitudinal observations (nonparent control group; see Table \@ref(tab:piecewise-coding-scheme). In the HRS, there were a few additional missing values in the outcomes ranging from `r summary(hrsanalysis_nonparents$con)[7]` to `r summary(hrsanalysis_nonparents$neur)[7]` longitudinal observations which will be listwise deleted in the respective analyses.  

[^f8]: For the HRS subsample, we also excluded $N =$ 30 grandparents in a previous step who reported unrealistically high numbers of grandchildren ($>$ 10) in their first assessment following the transition to grandparenthood.

[^f9]: We opted not to use multiple imputation for these child-related variables such as number of children which defined the control groups and were also later used for computing the propensity scores.

[^f11]: In the LISS data, `r liss_sampleflow_gp[4,2]` grandparent observations were matched with `r liss_final_n_parents$n[1]` control observations (matching with replacement); these control observations corresponded to `r liss_replacement_controls[1, 2]` unique person-year observations stemming from `r liss_replacement_controls[1, 3]` unique participants for the parent control group, and to `r liss_replacement_controls[2, 2]` unique person-year observations stemming from `r liss_replacement_controls[2, 3]` unique participants for the nonparent control group. In the HRS data, `r hrs_sampleflow_gp[4,2]` grandparent observations were matched with `r hrs_final_n_parents$n[1]` control observations (matching with replacement); these control observations corresponded to `r hrs_replacement_controls[1, 2]` unique person-year observations stemming from `r hrs_replacement_controls[1, 3]` unique participants for the parent control group, and to `r hrs_replacement_controls[2, 2]` unique person-year observations stemming from `r hrs_replacement_controls[2, 3]` unique participants for the nonparent control group.

## Analytical Strategy

We used `r cite_r("references-r.bib", pkgs = c("lme4", "lmerTest"), withhold = FALSE)` for multilevel modeling, as well as *tidyverse* [@tidyverse2019] for data wrangling, and *papaja* [@R-papaja] for reproducible manuscript production. Additional modeling details and a list of all software we used is provided in the Supplemental Material. Scripts for data wrangling, analyses, and to reproduce this manuscript can be found on the OSF (https://osf.io/75a4r/?view_only=ac929a2c41fb4afd9d1a64a3909848d0) and on GitHub (https://github.com/ [blinded for review]). Following Benjamin et al. [-@benjaminRedefineStatisticalSignificance2018], we set the $\alpha$-level for all confirmatory analyses to $.005$.  
Our design can be referred to as an interrupted time-series with a "nonequivalent no-treatment control group" [@shadishExperimentalQuasiexperimentalDesigns2002, p. 182] where treatment, that is, the transition to grandparenthood, is not deliberately manipulated. First, to analyze mean-level changes, we used linear piecewise regression coefficients in multilevel regression models with person-year observations nested within participants and households [@hoffmanLongitudinalAnalysisModeling2015]. To model change over time in relation to the birth of the first grandchild, we coded three piecewise regression coefficients: a *before-slope* representing linear change in the years leading up to the transition to grandparenthood, an *after-slope* representing linear change in the years after the transition, and a *shift* coefficient shifting the intercept directly after the transition was first reported, thus representing sudden changes that go beyond changes already modeled by the *after-slope* [see Table \@ref(tab:piecewise-coding-scheme) for the coding scheme of these coefficients; @hoffmanLongitudinalAnalysisModeling2015]. Other studies of personality development have recently adopted similar piecewise growth-curve models [e.g., @bleidornRetirementAssociatedChange2018; @schwabaPersonalityTraitDevelopment2019; @vanscheppingenTrajectoriesLifeSatisfaction2020; @kramerImpactHavingChildren2020].  
All effects of the transition to grandparenthood on the Big Five and life satisfaction were modeled as deviations from patterns in the matched control groups by interacting the three piecewise coefficients with the binary treatment variable (0 = *control*, 1 = *grandparent*). In additional models, we interacted these coefficients with the binary moderator variables resulting in two- or three-way interactions. To test differences in the growth parameters between two groups in cases where these differences were represented by multiple fixed-effects coefficients, we defined linear contrasts using the *linearHypothesis* command from the *car* R package [@car2019]. All models of mean-level changes were estimated using maximum likelihood and included random intercepts but no random slopes of the piecewise regression coefficients. We included the propensity score as a level-2 covariate for a double-robust approach [@austinDoublePropensityscoreAdjustment2017]. The model equations of the basic model and the moderation models can be found in the *Supplemental Material*.  
Second, to assess interindividual differences in intraindividual change in the Big Five and life satisfaction we added random slopes to the models assessing mean-level changes [see @denissenTransactionsLifeEvents2019 for a similar approach]. In other words, we allowed for differences between individuals in their trajectories of change to be modeled, that is, differences in the *before-slope*, *after-slope*, and *shift* coefficients. Because multiple simultaneous random slopes are often not computationally feasible, we added random slopes one at a time and used likelihood ratio test to determine whether the addition of the respective random slope led to a significant improvement in model fit. We plotted distributions of random slopes [for a similar approach, see @denissenTransactionsLifeEvents2019; @dorePopulationIndividuallevelChanges2018]. To statistically test differences in the random slope variance between the grandparent group and each control group, we respecified the multilevel models as heterogeneous variance models using the *nlme* R package [@R-nlme], which allows for separate random slope variances to be estimated in the grandparent group and the control group within the same model. Model fit of these heterogeneous variance models was compared to the corresponding models with a homogeneous (single) random slope variance via likelihood ratio tests. This was also done separately for the parent and nonparent control groups.  
Third, to examine rank-order stability in the Big Five and life satisfaction over the transition to grandparenthood, we computed the test-retest correlation of measurements prior to the transition to grandparenthood (at the time of matching) with the first available measurement after the transition. To test the difference in test-retest stability between grandparents and either of the control groups, we then entered the pre-treatment measure as well as the treatment variable (0 = *control*, 1 = *grandparent*) and their interaction into multiple regression models predicting the Big Five and life satisfaction. These interactions test for significant differences in the test-retest stability between those who experienced the transition to grandparenthood and those who did not [for a similar approach, see @denissenTransactionsLifeEvents2019; @mccraeModeratedAnalysesLongitudinal1993].  

# Results

Throughout the results section, we referred to results of statistical tests with $.005 < p < .05$ as *suggestive evidence* as stated in our preregistration.  

```{r coding-variables, results="asis"}
# code piecewise regression coefficients (see Table S1)
lissanalysis_parents <- lissanalysis_parents %>% mutate(
  before = ifelse(time<0, time + 6, 5), 
  after = ifelse(time<0, 0, time + 1), 
  shift = ifelse(time<0, 0, 1)
)
lissanalysis_nonparents <- lissanalysis_nonparents %>% mutate(
  before = ifelse(time<0, time + 6, 5), 
  after = ifelse(time<0, 0, time + 1), 
  shift = ifelse(time<0, 0, 1)
)
hrsanalysis_parents <- hrsanalysis_parents %>% mutate(
  before = ifelse(time>=-2, 2, ifelse(time==-6, 0, 1)), 
  after = ifelse(time<0, 0, ifelse(time==2, 2, ifelse(time==4, 3, ifelse(time==6, 4, 1)))), 
  shift = ifelse(time<0, 0, 1)
)
hrsanalysis_nonparents <- hrsanalysis_nonparents %>% mutate(
  before = ifelse(time>=-2, 2, ifelse(time==-6, 0, 1)), 
  after = ifelse(time<0, 0, ifelse(time==2, 2, ifelse(time==4, 3, ifelse(time==6, 4, 1)))), 
  shift = ifelse(time<0, 0, 1)
)
# create hid for HRS (remove last three digits)
hrsanalysis_parents$hid <- as.numeric(gsub('.{3}$', '', hrsanalysis_parents$HHIDPN))
hrsanalysis_nonparents$hid <- as.numeric(gsub('.{3}$', '', hrsanalysis_nonparents$HHIDPN))

# harmonize variable names
hrsanalysis_parents <- hrsanalysis_parents %>% mutate(female = gender - 1) %>% 
  rename(pid = HHIDPN,  matchtime = time_match)
hrsanalysis_nonparents <- hrsanalysis_nonparents %>% mutate(female = gender - 1) %>% 
  rename(pid = HHIDPN, matchtime = time_match)
lissanalysis_parents <- lissanalysis_parents %>% rename(pid = nomem_encr, hid = nohouse_encr)
lissanalysis_nonparents <- lissanalysis_nonparents %>% rename(pid = nomem_encr, hid = nohouse_encr)

# code other moderators (only HRS)
# paid work
hrsanalysis_parents <- hrsanalysis_parents %>% 
  mutate(working = ifelse(paidwork %in% c(1,5), ifelse(paidwork==1, 1, 0), NA))
hrsanalysis_nonparents <- hrsanalysis_nonparents %>% 
  mutate(working = ifelse(paidwork %in% c(1,5), ifelse(paidwork==1, 1, 0), NA))

# grandchild care

# only post-event period -> new data objects
hrsanalysis_care_parents <- hrsanalysis_parents %>% filter(time %in% c(0:6))
hrsanalysis_care_nonparents <- hrsanalysis_nonparents %>% filter(time %in% c(0:6))

# transfer grandparents' values of grandchild care (grandkids100h) to their matched controls
# careful to regard temporal changes, too
hrsanalysis_care_parents <- hrsanalysis_care_parents %>% group_by(subclass, time) %>% 
  mutate(grandkids100h = max(grandkids100h, na.rm = T)) %>% ungroup() %>% 
  mutate(grandkids100h = replace(grandkids100h, grandkids100h==-Inf, NA)) # regular NA pls
hrsanalysis_care_nonparents <- hrsanalysis_care_nonparents %>% group_by(subclass, time) %>% 
  mutate(grandkids100h = max(grandkids100h, na.rm = T)) %>% ungroup() %>% 
  mutate(grandkids100h = replace(grandkids100h, grandkids100h==-Inf, NA)) # regular NA pls

hrsanalysis_care_parents <- hrsanalysis_care_parents %>% 
  mutate(caring = ifelse(grandkids100h %in% c(1,5), ifelse(grandkids100h==1, 1, 0), NA)) %>% 
  filter(!is.na(caring))
hrsanalysis_care_nonparents <- hrsanalysis_care_nonparents %>% 
  mutate(caring = ifelse(grandkids100h %in% c(1,5), ifelse(grandkids100h==1, 1, 0), NA)) %>% 
  filter(!is.na(caring))

outcomes <- c("agree", "con", "extra", "neur", "open", "swls")

df_outcomes <- rbind(cbind(maj="Agreeableness", min="agreeableness"),
                     cbind(maj="Conscientiousness", min="conscientiousness"),
                     cbind(maj="Extraversion", min="extraversion"),
                     cbind(maj="Neuroticism", min="neuroticism"),
                     cbind(maj="Openness", min="openness"),
                     cbind(maj="Life Satisfaction", min="life satisfaction"))
rownames(df_outcomes) <- c("agree", "con", "extra", "neur", "open", "swls")
```

```{r descriptive-plots, include=FALSE, cache=T}
# first, construct combined datasets with all 3 groups
lissanalysis_allgroups <- bind_rows(
  lissanalysis_nonparents %>% 
    filter(grandparent==0) %>% 
    mutate(group = factor(0, labels="Nonparent Controls")) %>% 
    select(-grandparent),
  lissanalysis_parents %>% 
    mutate(group = factor(grandparent, labels=c("Parent Controls","Grandparents"))) %>% 
    select(-grandparent)
    )
hrsanalysis_allgroups <- bind_rows(
  hrsanalysis_nonparents %>% 
    filter(grandparent==0) %>% 
    mutate(group = factor(0, labels="Nonparent Controls")) %>% 
    select(-grandparent),
  hrsanalysis_parents %>% 
    mutate(group = factor(grandparent, labels=c("Parent Controls","Grandparents"))) %>% 
    select(-grandparent)
)
# for-loop did not work for some reason
# LISS
loess_plot_agree_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(agree)), 
                                aes(factor(time), agree)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["agree", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_con_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(con)), 
                                aes(factor(time), con)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["con", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_extra_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(extra)), 
                                aes(factor(time), extra)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["extra", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_neur_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(neur)), 
                                aes(factor(time), neur)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["neur", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_open_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(open)), 
                                aes(factor(time), open)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["open", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_swls_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(swls)), 
                                aes(factor(time), swls)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["swls", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")

# HRS
loess_plot_agree_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(agree)), 
                                aes(factor(time), agree)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["agree", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_con_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(con)), 
                                aes(factor(time), con)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["con", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_extra_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(extra)), 
                                aes(factor(time), extra)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["extra", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_neur_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(neur)), 
                                aes(factor(time), neur)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["neur", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_open_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(open)), 
                                aes(factor(time), open)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["open", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_swls_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(swls)), 
                                aes(factor(time), swls)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["swls", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
```

```{r H1-run-models, include=FALSE, cache=T}
# This chunk runs all the models related to H1.
# Results tables are created in following chunks.

# run ICC models first (final 'icc_list' is also used in appendix for Table)

# ICCs = proportion of the total variation explained by the respective blocking factor
# https://stats.stackexchange.com/questions/18088/intraclass-correlation-icc-for-an-interaction
datasets <- c("lissanalysis_parents", "lissanalysis_nonparents", 
              "hrsanalysis_parents", "hrsanalysis_nonparents")
icc_list <- as.data.frame(rbind(icc_liss_parents_pid = rep(NA, 6), icc_liss_parents_hid = rep(NA, 6), 
                                icc_liss_parents_pidhid = rep(NA, 6), 
                                icc_liss_nonparents_pid = rep(NA, 6),
                                icc_liss_nonparents_hid = rep(NA, 6), 
                                icc_liss_nonparents_pidhid = rep(NA, 6), 
                                icc_hrs_parents_pid = rep(NA, 6), 
                                icc_hrs_parents_hid = rep(NA, 6), icc_hrs_parents_pidhid = rep(NA, 6), 
                                icc_hrs_nonparents_pid = rep(NA, 6), 
                                icc_hrs_nonparents_hid = rep(NA, 6),
                                icc_hrs_nonparents_pidhid = rep(NA, 6)))
colnames(icc_list) <- outcomes

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  for (j in 1:length(datasets)){
    dataset = datasets[j]
    pos = seq(from = 1, to = 10, by = 3)[j]
    model <- lme4::lmer(get(outcome) ~ 1 + (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
    var <- as.data.frame(summary(model)$varcor)
    icc_pid <- var[1,4] / (var[1,4] + var[2,4] + var[3,4])
    icc_hid <- var[2,4] / (var[1,4] + var[2,4] + var[3,4])
    icc_pidhid <- (var[1,4] + var[2,4]) / (var[1,4] + var[2,4] + var[3,4])
    icc_list[pos, i] <- icc_pid # rows = datasets, columns = outcomes
    icc_list[pos + 1, i] <- icc_hid
    icc_list[pos + 2, i] <- icc_pidhid
  }
}
# singular fir for two models where the icc_hid is estimated too close to zero
# For these models, the icc_pid is the same compared to the model with only 
# the (1 | pid) random effect (which fits without trouble)
# Plus, a few additional models with icc_hid below 0.05 (close to zero)

# H1: models for mean-level changes

#### basic models & moderation by gender ####
hid_icc_tbl <- c("icc_liss_parents_hid", "icc_liss_nonparents_hid",
                 "icc_hrs_parents_hid", "icc_hrs_nonparents_hid") # see table 'icc_list'
mod_summaries <- list() # create empty list objects that later contain the models
mod_summaries_test <- list()
mod_summaries_gender <- list()
mod_summaries_gender_test <- list()

# run models in a loop (save in list object)
for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 24, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = datasets[j]
    ### basic models
    if (icc_list[hid_icc_tbl[j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                              grandparent:before + grandparent:after + grandparent:shift + 
                              (1 | pid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                                  grandparent:before + grandparent:after + grandparent:shift + 
                                  (1 | pid), REML = FALSE, data = get(dataset))
    } else { # cross-nesting in pid & hid for all other models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                              grandparent:before + grandparent:after + grandparent:shift + 
                              (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                                  grandparent:before + grandparent:after + grandparent:shift + 
                                  (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
    }      
    mod_summaries[[pos + j]] <- model_1
    names(mod_summaries)[[pos + j]] <- paste0(outcome, "_", dataset)
    mod_summaries_test[[pos + j]] <- model_2
    names(mod_summaries_test)[[pos + j]] <- paste0(outcome, "_", dataset)
    ### moderation by gender models
    if (icc_list[hid_icc_tbl[j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
      model_3 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                              grandparent:before + grandparent:after + grandparent:shift)*female + 
                              (1 | pid), REML = FALSE, data = get(dataset))
      model_4 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                  grandparent:before + grandparent:after + grandparent:shift)*female + 
                                  (1 | pid), REML = FALSE, data = get(dataset))
    } else { # cross-nesting in pid & hid for all other models
      model_3 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                              grandparent:before + grandparent:after + grandparent:shift)*female + 
                              (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      model_4 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                  grandparent:before + grandparent:after + grandparent:shift)*female + 
                                  (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
    }      
    mod_summaries_gender[[pos + j]] <- model_3
    names(mod_summaries_gender)[[pos + j]] <- paste0(outcome, "_", dataset)
    mod_summaries_gender_test[[pos + j]] <- model_4
    names(mod_summaries_gender_test)[[pos + j]] <- paste0(outcome, "_", dataset)
  }
}

datasets_short <- c("liss_parents", "liss_nonparents", "hrs_parents", "hrs_nonparents")
# coefs: the way they are named in the 'papaja' objects
coefs <- c("Intercept", "pscore", "before", "after", "shift", "grandparent", 
           "before_grandparent", "after_grandparent", "shift_grandparent") 
gammas <- c("gamma}_{00", "gamma}_{02", "gamma}_{10", "gamma}_{20", "gamma}_{30", "gamma}_{01", 
            "gamma}_{11", "gamma}_{21", "gamma}_{31")
coefs_gender <- c("Intercept", "pscore", "before", "after", "shift", "grandparent", 
                  "female", "before_grandparent", "after_grandparent", "shift_grandparent",
                  "before_female", "after_female", "shift_female", "grandparent_female", 
                  "before_grandparent_female", "after_grandparent_female", "shift_grandparent_female")
gammas_gender <- c("gamma}_{00", "gamma}_{04", "gamma}_{10", "gamma}_{20", "gamma}_{30", "gamma}_{01", 
                   "gamma}_{02", "gamma}_{11", "gamma}_{21", "gamma}_{31",
                   "gamma}_{12", "gamma}_{22", "gamma}_{32", "gamma}_{03", 
                   "gamma}_{13", "gamma}_{23", "gamma}_{33")

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 24, by = 4)[i]
  for (j in 1:length(datasets_short)){
    ### basic models
    dataset = datasets_short[j]
    obj = apa_print(mod_summaries[[pos + j]]) # unfold list objects (lme4)
    obj_test = mod_summaries_test[[pos + j]] # unfold list objects (lmerTest)
    # reformatting: change beta^hat to gamma^hat (plus subscripts)
    for (k in 1:length(coefs)){ 
      coef <- coefs[k] # 9 coefficients for each model (object)
      gamma <- gammas[k]
      obj$estimate[coef] <- lapply(obj$estimate[coef], gsub, pattern="beta", replacement=gamma)
      obj$full_result[coef] <- lapply(obj$full_result[coef], gsub, pattern="beta", replacement=gamma)
    }
    obj_name <- paste0(outcome, "_", dataset, "_summary")
    eval(call("<-", as.name(obj_name), obj)) # save lme4 model
    obj_name_test <- paste0(outcome, "_", dataset, "_test")
    eval(call("<-", as.name(obj_name_test), obj_test)) # save lmerTest model
    # for better formatting in text: p-values
    obj_p <- as.data.frame(summary(mod_summaries_test[[pos + j]])$coefficients) %>% # unfold list
      rownames_to_column() %>% select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
      mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
    obj_p["p"] <- # remove "0" from the chr's 
      lapply(obj_p["p"], gsub, pattern="0\\.", replacement="\\.")
    obj_name_p <- paste0(outcome, "_", dataset, "_p")
    eval(call("<-", as.name(obj_name_p), obj_p)) # save objects
    ### moderation by gender models
    obj_gender = apa_print(mod_summaries_gender[[pos + j]]) # unfold list objects
    obj_gender_test = mod_summaries_gender_test[[pos + j]] # unfold list objects (lmerTest)
    # reformatting: change beta^hat to gamma^hat (plus subscripts)
    for (k in 1:length(coefs_gender)){ 
      coef <- coefs_gender[k] # 17 coefficients for each model (object)
      gamma <- gammas_gender[k]
      obj_gender$estimate[coef] <- lapply(obj_gender$estimate[coef], gsub, 
                                          pattern="beta", replacement=gamma)
      obj_gender$full_result[coef] <- lapply(obj_gender$full_result[coef], gsub, 
                                             pattern="beta", replacement=gamma)
    }
    obj_gender_name <- paste0(outcome, "_", dataset, "_gender_summary")
    eval(call("<-", as.name(obj_gender_name), obj_gender)) # save object
    obj_gender_test_name <- paste0(outcome, "_", dataset, "_gender_test")
    eval(call("<-", as.name(obj_gender_test_name), obj_gender_test)) # save object
    # for better formatting in text: p-values
    obj_gender_p <- as.data.frame(summary(mod_summaries_gender_test[[pos + j]])$coefficients) %>% # unfold
      rownames_to_column() %>% select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
      mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
    obj_gender_p["p"] <- # remove "0" from the chr's 
      lapply(obj_gender_p["p"], gsub, pattern="0\\.", replacement="\\.")
    obj_gender_name_p <- paste0(outcome, "_", dataset, "_gender_p")
    eval(call("<-", as.name(obj_gender_name_p), obj_gender_p)) # save objects  
    }
}

#### moderation by paid work ####

mod_summaries_work <- list()
mod_summaries_work_test <- list()

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = -2, to = 8, by = 2)[i] # changed this because we now only have the 2 HRS datasets
  for (j in 3:4){
    dataset = datasets[j]
    ### moderator: paid work (only HRS)
    if (icc_list[hid_icc_tbl[j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                             grandparent:before + grandparent:after + grandparent:shift)*working + 
                              (1 | pid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                  grandparent:before + grandparent:after + grandparent:shift)*working + 
                                  (1 | pid), REML = FALSE, data = get(dataset))
    } else { # cross-nesting in pid & hid for all other models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                              grandparent:before + grandparent:after + grandparent:shift)*working + 
                              (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                 grandparent:before + grandparent:after + grandparent:shift)*working + 
                                  (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
    }      
    mod_summaries_work[[pos + j]] <- model_1
    names(mod_summaries_work)[[pos + j]] <- paste0(outcome, "_", dataset)
    mod_summaries_work_test[[pos + j]] <- model_2
    names(mod_summaries_work_test)[[pos + j]] <- paste0(outcome, "_", dataset)
  }
}

coefs_work <- c("Intercept", "pscore", "before", "after", "shift", "grandparent", 
                  "working", "before_grandparent", "after_grandparent", "shift_grandparent",
                  "before_working", "after_working", "shift_working", "grandparent_working", 
                  "before_grandparent_working", "after_grandparent_working", "shift_grandparent_working")
gammas_work <- c("gamma}_{00", "gamma}_{02", "gamma}_{20", "gamma}_{40", "gamma}_{60", "gamma}_{01", 
                   "gamma}_{10", "gamma}_{21", "gamma}_{41", "gamma}_{61",
                   "gamma}_{30", "gamma}_{50", "gamma}_{70", "gamma}_{11", 
                   "gamma}_{31", "gamma}_{51", "gamma}_{71")

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = -2, to = 8, by = 2)[i] # changed this because we now only have the 2 HRS datasets
  for (j in 3:4){
    dataset = datasets_short[j]
    ### moderation by paid work models
    obj_work = apa_print(mod_summaries_work[[pos + j]]) # unfold list objects
    obj_work_test = mod_summaries_work_test[[pos + j]] # unfold list objects (lmerTest)
    # reformatting: change beta^hat to gamma^hat (plus subscripts)
    for (k in 1:length(coefs_work)){ 
      coef <- coefs_work[k] # 17 coefficients for each model (object)
      gamma <- gammas_work[k]
      obj_work$estimate[coef] <- lapply(obj_work$estimate[coef], gsub, 
                                          pattern="beta", replacement=gamma)
      obj_work$full_result[coef] <- lapply(obj_work$full_result[coef], gsub, 
                                             pattern="beta", replacement=gamma)
    }
    obj_work_name <- paste0(outcome, "_", dataset, "_work_summary")
    eval(call("<-", as.name(obj_work_name), obj_work)) # save object
    obj_work_test_name <- paste0(outcome, "_", dataset, "_work_test")
    eval(call("<-", as.name(obj_work_test_name), obj_work_test)) # save object
    # for better formatting in text: p-values
    obj_work_p <- as.data.frame(summary(mod_summaries_work_test[[pos + j]])$coefficients) %>% # unfold
      rownames_to_column() %>% select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
      mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
    obj_work_p["p"] <- # remove "0" from the chr's 
      lapply(obj_work_p["p"], gsub, pattern="0\\.", replacement="\\.")
    obj_work_name_p <- paste0(outcome, "_", dataset, "_work_p")
    eval(call("<-", as.name(obj_work_name_p), obj_work_p)) # save objects  
    }
}

#### moderation by grandchild care ####

mod_summaries_care <- list()
mod_summaries_care_test <- list()

datasets_care <- c("hrsanalysis_care_parents", "hrsanalysis_care_nonparents")
  
for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 10, by = 2)[i] 
  for (j in 1:length(datasets_care)){
    dataset = datasets_care[j]
    ### moderator: grandchild care (only HRS)
    if (icc_list[hid_icc_tbl[j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + (after + grandparent + 
                                                           grandparent:after)*caring + 
                              (1 | pid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (after + grandparent + 
                                                               grandparent:after)*caring + 
                                  (1 | pid), REML = FALSE, data = get(dataset))
    } else { # cross-nesting in pid & hid for all other models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + (after + grandparent + 
                                                           grandparent:after)*caring + 
                              (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (after + grandparent + 
                                                               grandparent:after)*caring + 
                                  (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
    }      
    mod_summaries_care[[pos + j]] <- model_1
    names(mod_summaries_care)[[pos + j]] <- paste0(outcome, "_", dataset)
    mod_summaries_care_test[[pos + j]] <- model_2
    names(mod_summaries_care_test)[[pos + j]] <- paste0(outcome, "_", dataset)
  }
}

coefs_care <- c("Intercept", "pscore", "after", "grandparent", 
                "caring", "after_grandparent", 
                "after_caring", "grandparent_caring", 
                "after_grandparent_caring")
gammas_care <- c("gamma}_{00", "gamma}_{02", "gamma}_{20", "gamma}_{01", 
                 "gamma}_{10", "gamma}_{21",
                 "gamma}_{30", "gamma}_{11", 
                 "gamma}_{31")

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = -2, to = 8, by = 2)[i] # changed this because we now only have the 2 HRS datasets
  for (j in 3:4){
    dataset = datasets_short[j]
    ### moderation by grandchild care
    obj_care = apa_print(mod_summaries_care[[pos + j]]) # unfold list objects
    obj_care_test = mod_summaries_care_test[[pos + j]] # unfold list objects (lmerTest)
    # reformatting: change beta^hat to gamma^hat (plus subscripts)
    for (k in 1:length(coefs_care)){ 
      coef <- coefs_care[k] # 17 coefficients for each model (object)
      gamma <- gammas_care[k]
      obj_care$estimate[coef] <- lapply(obj_care$estimate[coef], gsub, pattern="beta", replacement=gamma)
      obj_care$full_result[coef] <- lapply(obj_care$full_result[coef], gsub, 
                                           pattern="beta", replacement=gamma)
    }
    obj_care_name <- paste0(outcome, "_", dataset, "_care_summary")
    eval(call("<-", as.name(obj_care_name), obj_care)) # save object
    obj_care_test_name <- paste0(outcome, "_", dataset, "_care_test")
    eval(call("<-", as.name(obj_care_test_name), obj_care_test)) # save object
    # for better formatting in text: p-values
    obj_care_p <- as.data.frame(summary(mod_summaries_care_test[[pos + j]])$coefficients) %>% 
      rownames_to_column() %>% select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
      mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
    obj_care_p["p"] <- # remove "0" from the chr's 
      lapply(obj_care_p["p"], gsub, pattern="0\\.", replacement="\\.")
    obj_care_name_p <- paste0(outcome, "_", dataset, "_care_p")
    eval(call("<-", as.name(obj_care_name_p), obj_care_p)) # save objects  
  }
}
```

```{r H1-linear-contrasts, include=FALSE, cache=T}

#### basic models ####

# test linear contrasts in cases where estimates of interest are represented by multiple FE coefs
to_be_tested <- c("shift_control", # shift of controls vs. 0
                  "shift_gp", # shift of GPs vs. 0
                  "shift_gp_vs_control", # shift of GPs vs. controls
                  "before_gp", # before-slope of GPs vs. 0
                  "after_gp") # after-slope of GPs vs. 0
contrasts <- list(c("shift", "after"),
                 c("shift", "after", "shift:grandparent", "after:grandparent"),
                 c("shift:grandparent", "after:grandparent"), 
                 c("before", "before:grandparent"),
                 c("after", "after:grandparent"))

gamma_comb_basic <- c("[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$]", 
                  "[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]",
                  "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]", 
                  "[$\\hat{\\gamma}_{10}$ + $\\hat{\\gamma}_{11}$]",
                  "[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{21}$]")

for (i in 1:length(outcomes)){
  for (j in 1:length(datasets_short)){
    ### basic models
    model <- get(paste0(outcomes[i], "_", datasets_short[j], "_test"))
    for (k in 1:length(to_be_tested)){
      contrast <- as.data.frame(
        cbind(est = sum(fixef(model)[contrasts[[k]]]), # estimate is the sum of all involved FE coefs
              chi = linearHypothesis(model, paste(contrasts[[k]], collapse = " + "))[2, "Chisq"], 
              df = linearHypothesis(model, paste(contrasts[[k]], collapse = " + "))[2, "Df"], 
              p = linearHypothesis(model, paste(contrasts[[k]], collapse = " + "))[2, "Pr(>Chisq)"])
        )
      conf_itvl <- confint(summary(multcomp::glht(model, # confidence intervals
                           linfct = paste(paste(contrasts[[k]], collapse = " + "), "= 0"))))
      contrast <- cbind(contrast, 
                        lwr = conf_itvl$confint[, "lwr"], 
                        upr = conf_itvl$confint[, "upr"])
      contrast <- contrast %>% mutate( # reformat for reporting in text
        est_num = paste(gamma_comb_basic[k], "=", printnum(est)),
        chi_print = paste0("$\\chi^2$", " (", contrast$df, ") = ", printnum(contrast$chi)),
        p_print = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
        conf = paste0("95% CI [", printnum(contrast$lwr), ", ", printnum(contrast$upr), "]")
      )
      contrast["p_print"] <- # remove "0" from the p-value chr
        lapply(contrast["p_print"], gsub, pattern="0\\.", replacement="\\.")
      contrast <- contrast %>% 
        unite(all, c(est_num, conf, p_print), sep = ", ", remove = F) # combined string
      contrast_name <- paste0(to_be_tested[k], "_", outcomes[i], "_", datasets_short[j])
      eval(call("<-", as.name(contrast_name), contrast))
    }
    collect_contrasts <- do.call(rbind, lapply(paste0(to_be_tested, "_", 
                              outcomes[i], "_", datasets_short[j]), get)) # all k's
    rownames(collect_contrasts) <- to_be_tested
    collected_name <- paste0("contrasts_", outcomes[i], "_", datasets_short[j])
    eval(call("<-", as.name(collected_name), collect_contrasts))
  }
  listed_contrasts <- do.call(list, lapply(paste0("contrasts_", 
                           outcomes[i], "_", datasets_short), get)) # all j's
  names(listed_contrasts) <- datasets_short
  listed_name <- paste0("contrasts_", outcomes[i])
  eval(call("<-", as.name(listed_name), listed_contrasts))
}

#### moderation by gender ####

to_be_tested_gender <- c("shift_control_male", # shift of male controls vs. 0
                         "shift_control_female", # shift of female controls vs. 0
                         "shift_gp_male", # shift of male GPs vs. 0
                         "shift_gp_female", # shift of female GPs vs. 0
                         "shift_gp_vs_control_men", # shift of m. GPs vs. m. controls
                         "before_gp_vs_control_women", # before-slope of f. GPs vs. f. controls
                         "after_gp_vs_control_women", # after-slope of f. GPs vs. f. controls
                         "shift_gp_vs_control_women", # shift of f. GPs vs. f. controls
                         "shift_male_vs_female_control", # shift of m. vs. f. controls
                         "before_male_vs_female_gp", # before-slope of m. vs. f. GPs
                         "after_male_vs_female_gp", # after-slope of m. vs. f. GPs
                         "shift_male_vs_female_gp") # shift of m. vs. f. GPs
contrasts_gender <- list(c("shift", "after"),
                         c("shift", "after", "shift:female", "after:female"),
                         c("shift", "after", "shift:grandparent", "after:grandparent"),
                         c("shift", "after", "shift:female", "after:female", "shift:grandparent", 
                           "after:grandparent", "shift:grandparent:female", "after:grandparent:female"),
                         c("shift:grandparent", "after:grandparent"), 
                         c("before:grandparent", "before:grandparent:female"), 
                         c("after:grandparent", "after:grandparent:female"), 
                         c("shift:grandparent", "after:grandparent", 
                           "shift:grandparent:female", "after:grandparent:female"), 
                         c("shift:female", "after:female"),
                         c("before:female", "before:grandparent:female"),
                         c("after:female", "after:grandparent:female"),
                         c("shift:female", "after:female", 
                           "shift:grandparent:female", "after:grandparent:female"))

gamma_comb_gender <- c("[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$]",
                   "[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{22}$ + $\\hat{\\gamma}_{32}$]",
                   "[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]", 
                   "[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$ + $\\hat{\\gamma}_{22}$ + $\\hat{\\gamma}_{32}$ + $\\hat{\\gamma}_{23}$ + $\\hat{\\gamma}_{33}$]",
                   "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]",
                   "[$\\hat{\\gamma}_{11}$ + $\\hat{\\gamma}_{13}$]",
                   "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{23}$]",
                   "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$ + $\\hat{\\gamma}_{23}$ + $\\hat{\\gamma}_{33}$]",
                   "[$\\hat{\\gamma}_{22}$ + $\\hat{\\gamma}_{32}$]",
                   "[$\\hat{\\gamma}_{12}$ + $\\hat{\\gamma}_{13}$]",
                   "[$\\hat{\\gamma}_{22}$ + $\\hat{\\gamma}_{23}$]",
                   "[$\\hat{\\gamma}_{22}$ + $\\hat{\\gamma}_{32}$ + $\\hat{\\gamma}_{23}$ + $\\hat{\\gamma}_{33}$]")

for (i in 1:length(outcomes)){
  for (j in 1:length(datasets_short)){
    ### moderation by gender 
    model_gender <- get(paste0(outcomes[i], "_", datasets_short[j], "_gender_test"))
    for (k in 1:length(to_be_tested_gender)){
      contrast_gender <- as.data.frame(
        cbind(est = sum(fixef(model_gender)[contrasts_gender[[k]]]), 
              chi = linearHypothesis(model_gender, paste(contrasts_gender[[k]], 
                                                         collapse = " + "))[2, "Chisq"], 
              df = linearHypothesis(model_gender, paste(contrasts_gender[[k]], 
                                                        collapse = " + "))[2, "Df"], 
              p = linearHypothesis(model_gender, paste(contrasts_gender[[k]], 
                                                       collapse = " + "))[2, "Pr(>Chisq)"])
      )
      conf_itvl_gender <- confint(summary(multcomp::glht(model_gender, # confidence intervals
                           linfct = paste(paste(contrasts_gender[[k]], collapse = " + "), "= 0"))))
      contrast_gender <- cbind(contrast_gender, 
                        lwr = conf_itvl_gender$confint[, "lwr"], 
                        upr = conf_itvl_gender$confint[, "upr"])
      contrast_gender <- contrast_gender %>% mutate( # reformat for reporting in text
        est_num = paste(gamma_comb_gender[k], "=", printnum(est)),
        chi_print = paste0("$\\chi^2$", " (", contrast_gender$df, ") = ", printnum(contrast_gender$chi)),
        p_print = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
        conf = paste0("95% CI [", printnum(contrast_gender$lwr), ", ", printnum(contrast_gender$upr), "]")
      )
      contrast_gender["p_print"] <- # remove "0" from the chr
        lapply(contrast_gender["p_print"], gsub, pattern="0\\.", replacement="\\.")
      contrast_gender <- contrast_gender %>% 
        unite(all, c(est_num, conf, p_print), sep = ", ", remove = F) # combined string
      contrast_gender_name <- paste0(to_be_tested_gender[k], "_", outcomes[i], "_", datasets_short[j])
      eval(call("<-", as.name(contrast_gender_name), contrast_gender))
  }
    collect_contrasts_gender <- do.call(rbind, lapply(paste0(to_be_tested_gender, "_", 
                                        outcomes[i], "_", datasets_short[j]), get)) #all k's
    rownames(collect_contrasts_gender) <- to_be_tested_gender
    collected_gender_name <- paste0("contrasts_", outcomes[i], "_", datasets_short[j], "_gender")
    eval(call("<-", as.name(collected_gender_name), collect_contrasts_gender))
}
  listed_contrasts_gender <- do.call(list, lapply(paste0("contrasts_", outcomes[i], "_", 
                                                         datasets_short, "_gender"), get)) # all j's
  names(listed_contrasts_gender) <- datasets_short
  listed_gender_name <- paste0("contrasts_gender_", outcomes[i])
  eval(call("<-", as.name(listed_gender_name), listed_contrasts_gender))
}

#### moderation by paid work ####

to_be_tested_work <- c("shift_control_nowork", # shift of not-working controls vs. 0
                       "shift_control_work", # shift of working controls vs. 0
                       "shift_gp_nowork", # shift of not-working GPs vs. 0
                       "shift_gp_work", # shift of working GPs vs. 0
                       "shift_gp_vs_control_nowork", # shift of not-working GPs vs. not-working controls
                       "before_gp_vs_control_work", # before-slope of working GPs vs. working controls
                       "after_gp_vs_control_work", # after-slope of working GPs vs. working controls
                       "shift_gp_vs_control_work", # shift of working GPs vs. working controls
                       "shift_nowork_vs_work_control", # shift of not-working vs. working controls
                       "before_nowork_vs_work_gp", # before-slope of not-working vs. working GP
                       "after_nowork_vs_work_gp", # after-slope of not-working vs. working GPs
                       "shift_nowork_vs_work_gp") # shift of not-working vs. working GPs
contrasts_work <- list(c("shift", "after"),
                       c("shift", "after", "shift:working", "after:working"),
                       c("shift", "after", "shift:grandparent", "after:grandparent"),
                       c("shift", "after", "shift:working", "after:working", "shift:grandparent", 
                         "after:grandparent", "shift:grandparent:working", "after:grandparent:working"),
                       c("shift:grandparent", "after:grandparent"), 
                       c("before:grandparent", "before:grandparent:working"), 
                       c("after:grandparent", "after:grandparent:working"), 
                       c("shift:grandparent", "after:grandparent", 
                         "shift:grandparent:working", "after:grandparent:working"), 
                       c("shift:working", "after:working"),
                       c("before:working", "before:grandparent:working"),
                       c("after:working", "after:grandparent:working"),
                       c("shift:working", "after:working", 
                         "shift:grandparent:working", "after:grandparent:working"))

gamma_comb_work <- c("[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$]", 
                     "[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$ + $\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$]",
                     "[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$ + $\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$]",
                     "[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$ + $\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$ + $\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$ + $\\hat{\\gamma}_{51}$ + $\\hat{\\gamma}_{71}$]",
                     "[$\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$]",
                     "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]",
                     "[$\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{51}$]",
                     "[$\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$ + $\\hat{\\gamma}_{51}$ + $\\hat{\\gamma}_{71}$]",
                     "[$\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$]",
                     "[$\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{31}$]",
                     "[$\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{51}$]",
                     "[$\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$ + $\\hat{\\gamma}_{51}$ + $\\hat{\\gamma}_{71}$]")

datasets_short_hrs <- datasets_short[3:4]

for (i in 1:length(outcomes)){
  for (j in 1:length(datasets_short_hrs)){ # now only for the 2 HRS datasets
    ### moderation by paid work 
    model_work <- get(paste0(outcomes[i], "_", datasets_short_hrs[j], "_work_test"))
    for (k in 1:length(to_be_tested_work)){
      contrast_work <- as.data.frame(
        cbind(est = sum(fixef(model_work)[contrasts_work[[k]]]), 
              chi = linearHypothesis(model_work, paste(contrasts_work[[k]], 
                                                         collapse = " + "))[2, "Chisq"], 
              df = linearHypothesis(model_work, paste(contrasts_work[[k]], 
                                                        collapse = " + "))[2, "Df"], 
              p = linearHypothesis(model_work, paste(contrasts_work[[k]], 
                                                       collapse = " + "))[2, "Pr(>Chisq)"])
      )
      conf_itvl_work <- confint(summary(multcomp::glht(model_work, # confidence intervals
                           linfct = paste(paste(contrasts_work[[k]], collapse = " + "), "= 0"))))
      contrast_work <- cbind(contrast_work, 
                        lwr = conf_itvl_work$confint[, "lwr"], 
                        upr = conf_itvl_work$confint[, "upr"])
      contrast_work <- contrast_work %>% mutate( # reformat for reporting in text
        est_num = paste(gamma_comb_work[k], "=", printnum(est)),
        chi_print = paste0("$\\chi^2$", " (", contrast_work$df, ") = ", printnum(contrast_work$chi)),
        p_print = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
        conf = paste0("95% CI [", printnum(contrast_work$lwr), ", ", printnum(contrast_work$upr), "]")
      )
      contrast_work["p_print"] <- # remove "0" from the chr
        lapply(contrast_work["p_print"], gsub, pattern="0\\.", replacement="\\.")
      contrast_work <- contrast_work %>% 
        unite(all, c(est_num, conf, p_print), sep = ", ", remove = F) # combined string
      contrast_work_name <- paste0(to_be_tested_work[k], "_", outcomes[i], "_", datasets_short_hrs[j])
      eval(call("<-", as.name(contrast_work_name), contrast_work))
  }
    collect_contrasts_work <- do.call(rbind, lapply(paste0(to_be_tested_work, "_", 
                                        outcomes[i], "_", datasets_short_hrs[j]), get)) #all k's
    rownames(collect_contrasts_work) <- to_be_tested_work
    collected_work_name <- paste0("contrasts_", outcomes[i], "_", datasets_short_hrs[j], "_work")
    eval(call("<-", as.name(collected_work_name), collect_contrasts_work))
}
  listed_contrasts_work <- do.call(list, lapply(paste0("contrasts_", outcomes[i], "_", 
                                                         datasets_short_hrs, "_work"), get)) # all j's
  names(listed_contrasts_work) <- datasets_short_hrs
  listed_work_name <- paste0("contrasts_work_", outcomes[i])
  eval(call("<-", as.name(listed_work_name), listed_contrasts_work))
}

#### moderation by grandchild care ####

to_be_tested_care <- c("after_gp_vs_control_care", # after-slope of caring GPs vs. caring controls
                       "after_nocare_vs_care_gp") # after-slope of not-caring vs. caring GPs

contrasts_care <- list(c("after:grandparent", "after:grandparent:caring"),
                       c("after:caring", "after:grandparent:caring"))

gamma_comb_care <- c("[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]",
                     "[$\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{31}$]")

for (i in 1:length(outcomes)){
  for (j in 1:length(datasets_short_hrs)){ # now only for the 2 HRS datasets
    ### moderation by grandchild care
    model_care <- get(paste0(outcomes[i], "_", datasets_short_hrs[j], "_care_test"))
    for (k in 1:length(to_be_tested_care)){
      contrast_care <- as.data.frame(
        cbind(est = sum(fixef(model_care)[contrasts_care[[k]]]), 
              chi = linearHypothesis(model_care, paste(contrasts_care[[k]], 
                                                         collapse = " + "))[2, "Chisq"], 
              df = linearHypothesis(model_care, paste(contrasts_care[[k]], 
                                                        collapse = " + "))[2, "Df"], 
              p = linearHypothesis(model_care, paste(contrasts_care[[k]], 
                                                       collapse = " + "))[2, "Pr(>Chisq)"])
      )
      conf_itvl_care <- confint(summary(multcomp::glht(model_care, # confidence intervals
                           linfct = paste(paste(contrasts_care[[k]], collapse = " + "), "= 0"))))
      contrast_care <- cbind(contrast_care, 
                        lwr = conf_itvl_care$confint[, "lwr"], 
                        upr = conf_itvl_care$confint[, "upr"])
      contrast_care <- contrast_care %>% mutate( # reformat for reporting in text
        est_num = paste(gamma_comb_care[k], "=", printnum(est)),
        chi_print = paste0("$\\chi^2$", " (", contrast_care$df, ") = ", printnum(contrast_care$chi)),
        p_print = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
        conf = paste0("95% CI [", printnum(contrast_care$lwr), ", ", printnum(contrast_care$upr), "]")
      )
      contrast_care["p_print"] <- # remove "0" from the chr
        lapply(contrast_care["p_print"], gsub, pattern="0\\.", replacement="\\.")
      contrast_care <- contrast_care %>% 
        unite(all, c(est_num, conf, p_print), sep = ", ", remove = F) # combined string
      contrast_care_name <- paste0(to_be_tested_care[k], "_", outcomes[i], "_", datasets_short_hrs[j])
      eval(call("<-", as.name(contrast_care_name), contrast_care))
  }
    collect_contrasts_care <- do.call(rbind, lapply(paste0(to_be_tested_care, "_", 
                                        outcomes[i], "_", datasets_short_hrs[j]), get)) #all k's
    rownames(collect_contrasts_care) <- to_be_tested_care
    collected_care_name <- paste0("contrasts_", outcomes[i], "_", datasets_short_hrs[j], "_care")
    eval(call("<-", as.name(collected_care_name), collect_contrasts_care))
}
  listed_contrasts_care <- do.call(list, lapply(paste0("contrasts_", outcomes[i], "_", 
                                                         datasets_short_hrs, "_care"), get)) # all j's
  names(listed_contrasts_care) <- datasets_short_hrs
  listed_care_name <- paste0("contrasts_care_", outcomes[i])
  eval(call("<-", as.name(listed_care_name), listed_contrasts_care))
}

# remove unnecessary objects
rm(list = ls(pattern = paste0(c(to_be_tested, to_be_tested_gender, 
                                to_be_tested_work, to_be_tested_care), collapse="|")))
rm(list = ls(pattern = paste0("contrasts_", outcomes, "_", collapse = "|")))
```

```{r H1-dataframes-plots, include=FALSE, cache=T}
# create predicted values data.frames for plots
# sources: 
# http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#lme/
# https://stackoverflow.com/questions/14358811/extract-prediction-band-from-lme-fit/
# https://stats.stackexchange.com/questions/29690/getting-fixed-effect-only-predictions-from-mixed-model-on-new-data-in-r/

#### basic models & moderation by gender ####

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 24, by = 4)[i]
  for (j in 1:length(datasets_short)){
    ### basic models
    dataset = datasets[j]
    dataset_short = datasets_short[j]
    obj_test = mod_summaries_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & time==0) %>% 
                               group_by(grandparent) %>% summarise(pscore = mean(pscore))) # pscore mean
    # different time sequences for LISS/HRS
    if (dataset_short %in% c("liss_parents", "liss_nonparents")){ 
      dframe <- data.frame( # for LISS
        pscore = c(rep(ps_mean[1,2], 13),  # controls
                   rep(ps_mean[2,2], 13)), # grandparents
        before = rep(c(0:5, rep(5, 7)), 2),
        after = rep(c(rep(0, 6), 1:7), 2),
        shift = rep(c(rep(0, 6), rep(1, 7)), 2),
        grandparent = c(rep(0, 13), rep(1, 13)),
        x = rep(-6:6, 2)
      )
    } else { # for HRS
      dframe <- data.frame(
        pscore = c(rep(ps_mean[1,2], 7), 
                   rep(ps_mean[2,2], 7)),
        before = rep(c(0:2, rep(2, 4)), 2),
        after = rep(c(rep(0, 3), 1:4), 2),
        shift = rep(c(rep(0, 3), rep(1, 4)), 2),
        grandparent = c(rep(0, 7), rep(1, 7)),
        x = rep(seq(-6, 6, by=2), 2)
      )
    }      
    # predict response (again, same procedure for LISS & HRS)
    dframe$pred <- predict(obj_test, newdata = dframe, re.form=NA)
    # create design matrix
    designmat <- model.matrix(as.formula(lme4::nobars(formula(obj_test))[-2]), 
                              dframe) # [-2] drops response from formula
    # compute standard error
    predvar <- diag(designmat %*% vcov(obj_test) %*% t(designmat)) 
    dframe$SE <- sqrt(predvar) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short %in% c("liss_parents", "hrs_parents")){ 
      dframe$gpgroup <- factor(dframe$grandparent, labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe$gpgroup <- factor(dframe$grandparent, labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe$gpgroup <- fct_rev(dframe$gpgroup)
    dframe_name <- paste0("dframe_", outcome, "_", dataset_short)
    eval(call("<-", as.name(dframe_name), dframe)) # save data.frame for later ggplot use
    ### moderation by gender models
    obj_test_gender = mod_summaries_gender_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean_gender <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & time==0) %>% 
                               group_by(grandparent, female) %>% summarise(pscore = mean(pscore)))
    # different time sequences for LISS/HRS
    if (dataset_short %in% c("liss_parents", "liss_nonparents")){ 
      dframe_gender <- data.frame(
        pscore = c(rep(ps_mean_gender[1,3], 13),  # male controls
                   rep(ps_mean_gender[2,3], 13),  # female controls
                   rep(ps_mean_gender[3,3], 13),  # male grandparents
                   rep(ps_mean_gender[4,3], 13)), # female grandparents
        before = rep(c(0:5, rep(5, 7)), 4),
        after = rep(c(rep(0, 6), 1:7), 4),
        shift = rep(c(rep(0, 6), rep(1, 7)), 4),
        grandparent = c(rep(0, 26), rep(1, 26)),
        female = rep(c(rep(0, 13), rep(1, 13)), 2),
        x = rep(-6:6, 4)
      )
    } else { # for HRS
      dframe_gender <- data.frame(
        pscore = c(rep(ps_mean_gender[1,3], 7),  # male controls
                   rep(ps_mean_gender[2,3], 7),  # female controls
                   rep(ps_mean_gender[3,3], 7),  # male grandparents
                   rep(ps_mean_gender[4,3], 7)), # female grandparents
        before = rep(c(0:2, rep(2, 4)), 4),
        after = rep(c(rep(0, 3), 1:4), 4),
        shift = rep(c(rep(0, 3), rep(1, 4)), 4),
        grandparent = c(rep(0, 14), rep(1, 14)),
        female = rep(c(rep(0, 7), rep(1, 7)), 2),
        x = rep(seq(-6, 6, by=2), 4)
      )
    }      
    # predict response (again, same procedure for LISS & HRS)
    dframe_gender$pred <- predict(obj_test_gender, newdata = dframe_gender, re.form=NA)
    # create design matrix
    designmat_gender <- model.matrix(as.formula(lme4::nobars(formula(obj_test_gender))[-2]), 
                              dframe_gender) # [-2] drops response from formula
    # compute standard error
    predvar_gender <- diag(designmat_gender %*% vcov(obj_test_gender) %*% t(designmat_gender)) 
    dframe_gender$SE <- sqrt(predvar_gender) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short %in% c("liss_parents", "hrs_parents")){ 
      dframe_gender$gpgroup <- factor(dframe_gender$grandparent, 
                                      labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe_gender$gpgroup <- factor(dframe_gender$grandparent, 
                                      labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe_gender$gpgroup <- fct_rev(dframe_gender$gpgroup)
    # add female variable as a factor
    dframe_gender$gender <- factor(dframe_gender$female, labels=c("Men","Women"))
    dframe_gender$gender <- fct_rev(dframe_gender$gender)
    dframe_name_gender <- paste0("dframe_", outcome, "_", dataset_short, "_gender")
    eval(call("<-", as.name(dframe_name_gender), dframe_gender)) # save data.frame for later ggplot use
  }
}

#### moderation by paid work ####

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = -2, to = 8, by = 2)[i] # changed this because we now only have the 2 HRS datasets
  for (j in 3:4){
    dataset = datasets[j]
    dataset_short = datasets_short[j]
    ### moderation by paid work models
    obj_test_work = mod_summaries_work_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean_work <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & 
                                           !is.na(working) & time==0) %>% 
                               group_by(grandparent, working) %>% summarise(pscore = mean(pscore)))
    # only HRS
      dframe_work <- data.frame(
        pscore = c(rep(ps_mean_work[1,3], 7),  # non-working controls
                   rep(ps_mean_work[2,3], 7),  # working controls
                   rep(ps_mean_work[3,3], 7),  # non-working grandparents
                   rep(ps_mean_work[4,3], 7)), # working grandparents
        before = rep(c(0:2, rep(2, 4)), 4),
        after = rep(c(rep(0, 3), 1:4), 4),
        shift = rep(c(rep(0, 3), rep(1, 4)), 4),
        grandparent = c(rep(0, 14), rep(1, 14)),
        working = rep(c(rep(0, 7), rep(1, 7)), 2),
        x = rep(seq(-6, 6, by=2), 4)
      )
    # predict response (again, same procedure for LISS & HRS)
    dframe_work$pred <- predict(obj_test_work, newdata = dframe_work, re.form=NA)
    # create design matrix
    designmat_work <- model.matrix(as.formula(lme4::nobars(formula(obj_test_work))[-2]), 
                              dframe_work) # [-2] drops response from formula
    # compute standard error
    predvar_work <- diag(designmat_work %*% vcov(obj_test_work) %*% t(designmat_work)) 
    dframe_work$SE <- sqrt(predvar_work) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short=="hrs_parents"){ 
      dframe_work$gpgroup <- factor(dframe_work$grandparent, 
                                      labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe_work$gpgroup <- factor(dframe_work$grandparent, 
                                      labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe_work$gpgroup <- fct_rev(dframe_work$gpgroup)
    # add paid work as a factor
    dframe_work$work <- factor(dframe_work$working, labels=c("Not Working","Working"))
    dframe_work$work <- fct_rev(dframe_work$work)
    dframe_name_work <- paste0("dframe_", outcome, "_", dataset_short, "_work")
    eval(call("<-", as.name(dframe_name_work), dframe_work)) # save data.frame for later ggplot use
  }
}

#### moderation by grandchild care ####

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 10, by = 2)[i] 
  for (j in 1:length(datasets_care)){
    dataset = datasets_care[j]
    dataset_short = datasets_short[j+2] # only HRS
    ### moderation by grandchild care models
    obj_test_care = mod_summaries_care_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean_care <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & 
                                           !is.na(caring) & time==0) %>% 
                                    group_by(grandparent, caring) %>% summarise(pscore = mean(pscore)))
    # only HRS (simplified post-transition model)
    dframe_care <- data.frame(
      pscore = c(rep(ps_mean_care[1,3], 4),  # non-caring controls
                 rep(ps_mean_care[2,3], 4),  # caring controls
                 rep(ps_mean_care[3,3], 4),  # non-caring grandparents (>100 h)
                 rep(ps_mean_care[4,3], 4)), # caring grandparents
      after = rep(c(1:4), 4),
      grandparent = c(rep(0, 8), rep(1, 8)),
      caring = rep(c(rep(0, 4), rep(1, 4)), 2),
      x = rep(seq(0, 6, by=2), 4)
    )
    # predict response (again, same procedure for LISS & HRS)
    dframe_care$pred <- predict(obj_test_care, newdata = dframe_care, re.form=NA)
    # create design matrix
    designmat_care <- model.matrix(as.formula(lme4::nobars(formula(obj_test_care))[-2]), 
                                   dframe_care) # [-2] drops response from formula
    # compute standard error
    predvar_care <- diag(designmat_care %*% vcov(obj_test_care) %*% t(designmat_care)) 
    dframe_care$SE <- sqrt(predvar_care) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short=="hrs_parents"){ 
      dframe_care$gpgroup <- factor(dframe_care$grandparent, 
                                    labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe_care$gpgroup <- factor(dframe_care$grandparent, 
                                    labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe_care$gpgroup <- fct_rev(dframe_care$gpgroup)
    # add grandchild care as a factor
    dframe_care$care <- factor(dframe_care$caring, labels=c("Less than 100h",
                                                            "More than 100h"))
    dframe_care$care <- fct_rev(dframe_care$care)
    dframe_name_care <- paste0("dframe_", outcome, "_", dataset_short, "_care")
    eval(call("<-", as.name(dframe_name_care), dframe_care)) # save data.frame for later ggplot use
  }
}

# remove list objects from environment
rm(mod_summaries_test, mod_summaries_gender, mod_summaries_gender_test, #mod_summaries
   mod_summaries_work, mod_summaries_work_test, mod_summaries_care, mod_summaries_care_test)
```

```{r H1-build-plots, include=FALSE, cache=T}
outcomes_plots <- c(rep("Agreeableness", 4), rep("Conscientiousness", 4), rep("Extraversion", 4),  
                   rep("Neuroticism", 4), rep("Openness", 4), rep("Life Satisfaction", 4))
# y-axis limits (same span but different sections)
limits_lower <- c(rep(3, 4), rep(3, 4), rep(2.5, 4), rep(1.5, 4), rep(2.5, 4), rep(4.25, 4)) 
limits_upper <- c(rep(4.5, 4), rep(4.5, 4), rep(4, 4), rep(3, 4), rep(4, 4), rep(5.75, 4))
limits <- cbind(limits_lower, limits_upper)
rownames(limits) <- outcomes_plots

#### basic models & moderation by gender ####

# collect data frames in correct order (ACENO+LS -> LISS-p, LISS-np, HRS-p, HRS-np)
dframes <- c(sort(ls()[grep("^(?=.*dframe_agree)(?!.*gender)(?!.*work)(?!.*care)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_con)(?!.*gender)(?!.*work)(?!.*care)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_extra)(?!.*gender)(?!.*work)(?!.*care)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_neur)(?!.*gender)(?!.*work)(?!.*care)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_open)(?!.*gender)(?!.*work)(?!.*care)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_swls)(?!.*gender)(?!.*work)(?!.*care)", 
                            ls(), perl=T)], decreasing=T))
dframes_gender <- c(sort(ls()[grep("^(?=.*dframe_agree)(?=.*gender)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_con)(?=.*gender)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_extra)(?=.*gender)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_neur)(?=.*gender)", ls(), perl=T)], decreasing=T),    
                    sort(ls()[grep("^(?=.*dframe_open)(?=.*gender)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_swls)(?=.*gender)", ls(), perl=T)], decreasing=T))

for (i in 1:length(dframes)){
  ### basic
  plot <- ggplot(get(dframes[i]), aes(x=x,y=pred,colour=gpgroup))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i, 1], limits[i, 2]))+ # loop over limits as defined above
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          legend.position = "none",
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1))+
    scale_y_continuous(name=outcomes_plots[i]) 
  if (dframes[i] %in% dframes[grep("^(?=.*liss)", dframes, perl=T)]){ # filter LISS
    plot <- plot + scale_x_continuous(name="Time (in Years)",breaks=c(-6:6)) +
      geom_vline(xintercept=-0.5, colour="darkgrey") # LISS
  } else { 
    plot <- plot + scale_x_continuous(name="Time (in Years)",breaks=seq(-6,6,2)) + 
    geom_vline(xintercept=-1, colour="darkgrey") # HRS
  }      
  if (dframes[i] %in% dframes[grep("^(?=.*_parents)", dframes, perl=T)]){ # filter parent df's
    plot <- plot + theme(axis.title.x=element_blank())
  } 
  plot_name <- gsub("dframe", "plot", dframes[i])
  eval(call("<-", as.name(plot_name), plot)) # save plots for later assembly
  ### moderation by gender
  plot_gender <- ggplot(get(dframes_gender[i]), aes(x=x,y=pred,colour=gpgroup,linetype=gender))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    scale_linetype_discrete(name="Gender")+
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i, 1], limits[i, 2]))+ # loop over limits as defined above
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1),
          axis.title.y=element_blank())+
    guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 2))+ # legend element order
    scale_y_continuous() # name=outcomes_plots[i]
  if (dframes_gender[i] %in% dframes_gender[grep("^(?=.*liss)", dframes_gender, perl=T)]){ # filter LISS
    plot_gender <- plot_gender + scale_x_continuous(name="Time (in Years)",breaks=c(-6:6)) +
      geom_vline(xintercept=-0.5, colour="darkgrey") # LISS
  } else { 
    plot_gender <- plot_gender + scale_x_continuous(name="Time (in Years)",breaks=seq(-6,6,2)) + 
      geom_vline(xintercept=-1, colour="darkgrey") # HRS
  }      
  if (dframes_gender[i] %in% dframes_gender[grep("^(?=.*_parents_)", dframes_gender, perl=T)]){ 
    plot_gender <- plot_gender + theme(axis.title.x=element_blank()) # omit x-axis title for parent plots
  } 
  plot_name_gender <- gsub("dframe", "plot", dframes_gender[i])
  eval(call("<-", as.name(plot_name_gender), plot_gender)) # save plots for later assembly
}

#### moderation by paid work ####

dframes_work <- c(sort(ls()[grep("^(?=.*dframe_agree)(?=.*work)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_con)(?=.*work)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_extra)(?=.*work)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_neur)(?=.*work)", ls(), perl=T)], decreasing=T),    
                    sort(ls()[grep("^(?=.*dframe_open)(?=.*work)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_swls)(?=.*work)", ls(), perl=T)], decreasing=T))

for (i in 1:length(dframes_work)){
  ### moderation by paid work
  plot_work <- ggplot(get(dframes_work[i]), aes(x=x,y=pred,colour=gpgroup,linetype=work))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    scale_linetype_discrete(name="Work Status")+
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i*2, 1], limits[i*2, 2]))+ # loop over limits (but *2 because of length)
    scale_x_continuous(name="Time (in Years)",breaks=seq(-6,6,2))+ 
    geom_vline(xintercept=-1, colour="darkgrey")+
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1),
          axis.title.y=element_blank())+
    guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 2))+ # legend element order
    scale_y_continuous() # name=outcomes_plots[i]
  if (dframes_work[i] %in% dframes_work[grep("^(?=.*_parents_)", dframes_work, perl=T)]){ 
    plot_work <- plot_work + theme(axis.title.x=element_blank()) # omit x-axis title for parent plots
  } 
  plot_name_work <- gsub("dframe", "plot", dframes_work[i])
  eval(call("<-", as.name(plot_name_work), plot_work)) # save plots for later assembly
}

#### moderation by grandchild care ####

dframes_care <- c(sort(ls()[grep("^(?=.*dframe_agree)(?=.*care)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_con)(?=.*care)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_extra)(?=.*care)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_neur)(?=.*care)", ls(), perl=T)], decreasing=T),    
                    sort(ls()[grep("^(?=.*dframe_open)(?=.*care)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_swls)(?=.*care)", ls(), perl=T)], decreasing=T))

dframes_hrs <- dframes[grep("^(?=.*hrs)", dframes, perl=T)]

for (i in 1:length(dframes_hrs)){
  ### shortened version of basic plots for comparison (only post-transition)
  dframe_short = get(dframes_hrs[i]) %>% filter(x %in% 0:6)
  plot_short <- ggplot(dframe_short, aes(x=x,y=pred,colour=gpgroup))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i*2, 1], limits[i*2, 2]))+ # loop over limits (but *2 because of length)
    scale_x_continuous(name="Time (in Years)",breaks=seq(0,6,2))+ # starts at 0 now
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1),
          #axis.title.y=element_blank()
          )+
    scale_y_continuous(name=outcomes_plots[i*2])
  if (dframes_hrs[i] %in% dframes_hrs[grep("^(?=.*_parents)", dframes_hrs, perl=T)]){ 
    plot_short <- plot_short + theme(axis.title.x=element_blank()) # omit x-axis title for parent plots
  } 
  plot_name_short <- paste0(gsub("dframe", "plot", dframes_hrs[i]), "_short")
  eval(call("<-", as.name(plot_name_short), plot_short)) # save plots for later assembly
}
for (i in 1:length(dframes_care)){
  ### moderation by grandchild care
  plot_care <- ggplot(get(dframes_care[i]), aes(x=x,y=pred,colour=gpgroup,linetype=care))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    scale_linetype_discrete(name="Grandchild Care")+
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i*2, 1], limits[i*2, 2]))+ # loop over limits (but *2 because of length)
    scale_x_continuous(name="Time (in Years)",breaks=seq(0,6,2))+ # starts at 0 now
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1),
          axis.title.y=element_blank())+
    guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 2)) # legend element order
    #scale_y_continuous(name=outcomes_plots[i*2])
  if (dframes_care[i] %in% dframes_care[grep("^(?=.*_parents_)", dframes_care, perl=T)]){ 
    plot_care <- plot_care + theme(axis.title.x=element_blank()) # omit x-axis title for parent plots
  } 
  plot_name_care <- gsub("dframe", "plot", dframes_care[i])
  eval(call("<-", as.name(plot_name_care), plot_care)) # save plots for later assembly
}
```

```{r H2-test-random-slopes, include=FALSE, cache=T}
# H2: Individual differences in intraindividual change

anova_summaries <- list()

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 20, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = datasets[j]
    # update basic models with random slopes (one at a time) -> random slopes for pid (not hid)
    rs_before <- update(mod_summaries[[pos + j]], . ~ . -(1 | pid) + (1 + before | pid), 
                        control = lme4::lmerControl(optimizer="bobyqa")) # some nonconvergence with default opt
    rs_after <-  update(mod_summaries[[pos + j]], . ~ . -(1 | pid) + (1 + after | pid), 
                        control = lme4::lmerControl(optimizer="bobyqa"))
    rs_shift <-  update(mod_summaries[[pos + j]], . ~ . -(1 | pid) + (1 + shift | pid), 
                        control = lme4::lmerControl(optimizer="bobyqa"))
    # run anova() for model comparison
    before_anov <- as.numeric(anova(mod_summaries[[pos + j]], rs_before)[2, c("Chisq", "Pr(>Chisq)")])
    after_anov <-  as.numeric(anova(mod_summaries[[pos + j]], rs_after)[2, c("Chisq", "Pr(>Chisq)")])
    shift_anov <-  as.numeric(anova(mod_summaries[[pos + j]], rs_shift)[2, c("Chisq", "Pr(>Chisq)")])
    # together
    comp_anov <- as.data.frame(rbind(before_anov, after_anov, shift_anov))
    comp_anov <- comp_anov %>% mutate(
      chi2 = printnum(V1),
      p = scales::pvalue(V2, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
      ) %>% select(chi2, p)
    comp_anov["p"] <- # remove "0" from the chr's
      lapply(comp_anov["p"], gsub, pattern="0\\.", replacement="\\.")
    rownames(comp_anov) <- c("before", "after", "shift")
    # save in list object
    anova_summaries[[pos + j]] <- comp_anov
    names(anova_summaries)[[pos + j]] <- paste0(outcome, "_", dataset, "_comp")
  }
}
# all p < .001 -> no table needed?
```


```{r H2-heterogeneous-variance, include=FALSE, cache=T}
# H2: Individual differences in intraindividual change

hetvar_summaries <- list()

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 20, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = datasets[j]
    # test heterogeneous variance ('slopes' = model with separate random slope variances for each group)
    # heterogeneous variance models in 'nlme' (also possible in 'lme4' but we preregistered 'nlme')
    # same number of fixed effects just coded differently 
    dummyfixed <- formula(paste(outcome, '0 + pscore + dummy(grandparent,"0") + dummy(grandparent,"1") + 
                  before:dummy(grandparent,"0") + before:dummy(grandparent,"1") +
                  after:dummy(grandparent,"0") + after:dummy(grandparent,"1") +
                  shift:dummy(grandparent,"0") + shift:dummy(grandparent,"1")', sep = "~"))
    ### before-slope -> random slope
    before_mod_hetvar_slopes <- 
      nlme::lme(fixed = dummyfixed,
                random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0") +
                                                                  before:dummy(grandparent,"0")),
                                                       nlme::pdSymm(~ 0 + dummy(grandparent,"1") + 
                                                                  before:dummy(grandparent,"1"))))), 
                data = get(dataset), method = 'REML', na.action = 'na.omit')
    # base model with same FE specification but uniform random slope variance
    before_mod_hetvar_base <- 
      nlme::lme(fixed = dummyfixed,
                random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0")),
                                                       nlme::pdSymm(~ 0 + dummy(grandparent,"1")),
                                                       nlme::pdSymm(~ 0 + before)))), 
                data = get(dataset), method = 'REML', na.action = 'na.omit')
    ### after-slope -> random slope
    after_mod_hetvar_slopes <- 
      nlme::lme(fixed = dummyfixed,
                random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0") +
                                                                      after:dummy(grandparent,"0")),
                                                       nlme::pdSymm(~ 0 + dummy(grandparent,"1") + 
                                                                      after:dummy(grandparent,"1"))))), 
                data = get(dataset), method = 'REML', na.action = 'na.omit')
    # base model with same FE specification but uniform random slope variance
    after_mod_hetvar_base <- 
      nlme::lme(fixed = dummyfixed,
                random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0")),
                                                       nlme::pdSymm(~ 0 + dummy(grandparent,"1")),
                                                       nlme::pdSymm(~ 0 + after)))), 
                data = get(dataset), method = 'REML', na.action = 'na.omit')
    ### shift -> random slope
    shift_mod_hetvar_slopes <- 
      nlme::lme(fixed = dummyfixed,
                random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0") +
                                                                      shift:dummy(grandparent,"0")),
                                                       nlme::pdSymm(~ 0 + dummy(grandparent,"1") + 
                                                                      shift:dummy(grandparent,"1"))))), 
                data = get(dataset), method = 'REML', na.action = 'na.omit')
    # base model with same FE specification but uniform random slope variance
    shift_mod_hetvar_base <- 
      nlme::lme(fixed = dummyfixed,
                random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0")),
                                                       nlme::pdSymm(~ 0 + dummy(grandparent,"1")),
                                                       nlme::pdSymm(~ 0 + shift)))), 
                data = get(dataset), method = 'REML', na.action = 'na.omit')
    # variance estimates
    varest <- # row1 = single random slope var; row2 / row3 = het. random slope var (controls / GPs) etc.
      as.data.frame(rbind(
        cbind(as.numeric(VarCorr(before_mod_hetvar_base)[3, 1]),
              as.numeric(VarCorr(before_mod_hetvar_base)[3, 2])), 
        cbind(as.numeric(VarCorr(before_mod_hetvar_slopes)[c(2,4), 1]), 
              as.numeric(VarCorr(before_mod_hetvar_slopes)[c(2,4), 2])),
        cbind(as.numeric(VarCorr(after_mod_hetvar_base)[3, 1]), 
              as.numeric(VarCorr(after_mod_hetvar_base)[3, 2])), 
        cbind(as.numeric(VarCorr(after_mod_hetvar_slopes)[c(2,4), 1]), 
              as.numeric(VarCorr(after_mod_hetvar_slopes)[c(2,4), 2])),
        cbind(as.numeric(VarCorr(shift_mod_hetvar_base)[3, 1]), 
              as.numeric(VarCorr(shift_mod_hetvar_base)[3, 2])), 
        cbind(as.numeric(VarCorr(shift_mod_hetvar_slopes)[c(2,4), 1]), 
              as.numeric(VarCorr(shift_mod_hetvar_slopes)[c(2,4), 2]))))
    colnames(varest) <- c("var", "sd")
    varest_names <- c("before_uni_rand_slope", "before_control_rand_slope", "before_gp_rand_slope",
                      "after_uni_rand_slope", "after_control_rand_slope", "after_gp_rand_slope",
                      "shift_uni_rand_slope", "shift_control_rand_slope", "shift_gp_rand_slope")
    rownames(varest) <- varest_names
    # run anova() for model comparison
    before_hetvar_anov <- as.numeric(anova(before_mod_hetvar_base, 
                                           before_mod_hetvar_slopes)[2, c("L.Ratio", "p-value")])
    after_hetvar_anov <-  as.numeric(anova(after_mod_hetvar_base, 
                                           after_mod_hetvar_slopes)[2, c("L.Ratio", "p-value")])
    shift_hetvar_anov <-  as.numeric(anova(shift_mod_hetvar_base, 
                                           shift_mod_hetvar_slopes)[2, c("L.Ratio", "p-value")])
    before_hetvar_anov[3] <- ifelse(varest["before_control_rand_slope","var"] < 
                                      varest["before_gp_rand_slope","var"], "yes", "no")
    after_hetvar_anov[3] <- ifelse(varest["after_control_rand_slope","var"] < 
                                      varest["after_gp_rand_slope","var"], "yes", "no")
    shift_hetvar_anov[3] <- ifelse(varest["shift_control_rand_slope","var"] < 
                                      varest["shift_gp_rand_slope","var"], "yes", "no")
    # together
    comp_hetvar_anov <- as.data.frame(rbind(
      do.call("rbind", replicate(3, before_hetvar_anov, simplify = FALSE)), # three times for later cbind
      do.call("rbind", replicate(3, after_hetvar_anov, simplify = FALSE)),
      do.call("rbind", replicate(3, shift_hetvar_anov, simplify = FALSE))))
    comp_hetvar_anov <- comp_hetvar_anov %>% mutate(
      lratio = printnum(as.numeric(V1)),
      p = scales::pvalue(as.numeric(V2), prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
    ) %>% select(lratio, p, gp_greater = V3)
    comp_hetvar_anov["p"] <- # remove "0" from the chr's 
      lapply(comp_hetvar_anov["p"], gsub, pattern="0\\.", replacement="\\.")
    rownames(comp_hetvar_anov) <- varest_names
    # bind variance estimates + anova results
    varest <- cbind(varest, comp_hetvar_anov)
    # save in list object
    hetvar_summaries[[pos + j]] <- varest
    names(hetvar_summaries)[[pos + j]] <- paste0(outcome, "_", dataset, "_hetvar")
  }
}
# for supplemental tables 
```

```{r H3-rank-order-stab, include=FALSE, cache=T}
# H3: rank-order stability

# construct data sets with the time point of matching and the first post-transition assessment (within-person)
draw_below <- function(x) { 
  x %>% 
    filter(time==matchtime) %>% 
    select(match_number, grandparent, time_pre = time, # using match_number instead of pid
           agree_pre = agree, con_pre = con, extra_pre = extra, 
           neur_pre = neur, open_pre = open, swls_pre = swls) }
draw_above <- function(x) { 
  x %>% 
  filter(time>=0) %>% group_by(match_number) %>% slice_min(time) %>% ungroup() %>% 
  select(match_number, grandparent, time, all_of(outcomes)) }

list_below <- list(lissanalysis_parents, lissanalysis_nonparents,
                   hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_below)
list_above <- list(lissanalysis_parents, lissanalysis_nonparents,
                   hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_above)
names(list_below) <- paste0(datasets, "_rank_below")
names(list_above) <- paste0(datasets, "_rank_above")

list2env(c(list_below, list_above), .GlobalEnv)

# liss
lissanalysis_parents_rank <- left_join(lissanalysis_parents_rank_above, 
                                       lissanalysis_parents_rank_below) %>% 
  mutate(yr_lag = time - time_pre)
lissanalysis_nonparents_rank <- left_join(lissanalysis_nonparents_rank_above, 
                                          lissanalysis_nonparents_rank_below) %>% 
  mutate(yr_lag = time - time_pre)
# hrs
hrsanalysis_parents_rank <- left_join(hrsanalysis_parents_rank_above, 
                                      hrsanalysis_parents_rank_below) %>% 
  mutate(yr_lag = time - time_pre)
hrsanalysis_nonparents_rank <- left_join(hrsanalysis_nonparents_rank_above, 
                                         hrsanalysis_nonparents_rank_below) %>% 
  mutate(yr_lag = time - time_pre)

rm(list = ls(pattern = paste0(c("_below", "_above"), collapse="|")))

rank_order_df <- as.data.frame(
  cbind(cor_all = rep(NA, 24), cor_gp = rep(NA, 24), cor_con = rep(NA, 24), p = rep(NA, 24)))

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 20, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = paste0(datasets[j], "_rank")
    # simple correlations
    cor_all <- as.numeric(get(dataset) %>% 
      filter(!is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_gp <-  as.numeric(get(dataset) %>% 
      filter(grandparent==1 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_con <- as.numeric(get(dataset) %>% 
      filter(grandparent==0 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    # interaction model as significance test for group differences
    formula_rank <- formula(paste(outcome, paste0(outcome, "_pre*grandparent"), sep = "~"))
    rank_order_int <- lm(formula = formula_rank, data = get(dataset))
    # save in df
    rank_order_df[pos + j, ] <- 
      c(cor_all, cor_gp, cor_con, summary(rank_order_int)$coef[4, 4]) # interaction p-val. 
    rownames(rank_order_df)[pos + j] <- paste0(outcomes[i], "_", datasets_short[j], "_rank")
  }
}

# alternatively: 
# construct data sets with the first pre- and the last post-transition assessment (within-person)
# -> maximally large gap for retest
draw_below_max <- function(x) { 
  x %>% 
    filter(time<0) %>% group_by(match_number) %>% slice_min(time) %>% ungroup() %>%
    select(match_number, grandparent, time_pre = time, # using match_number instead of pid
           agree_pre = agree, con_pre = con, extra_pre = extra, 
           neur_pre = neur, open_pre = open, swls_pre = swls) }
draw_above_max <- function(x) { 
  x %>% 
  filter(time>=0) %>% group_by(match_number) %>% slice_max(time) %>% ungroup() %>% 
  select(match_number, grandparent, time, all_of(outcomes)) }

list_below_max <- list(lissanalysis_parents, lissanalysis_nonparents,
                       hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_below_max)
list_above_max <- list(lissanalysis_parents, lissanalysis_nonparents,
                       hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_above_max)
names(list_below_max) <- paste0(datasets, "_rank_below_max")
names(list_above_max) <- paste0(datasets, "_rank_above_max")

list2env(c(list_below_max, list_above_max), .GlobalEnv)

# liss
lissanalysis_parents_rank_max <- left_join(lissanalysis_parents_rank_above_max, 
                                           lissanalysis_parents_rank_below_max) %>% 
  mutate(yr_lag = time - time_pre)
lissanalysis_nonparents_rank_max <- left_join(lissanalysis_nonparents_rank_above_max, 
                                              lissanalysis_nonparents_rank_below_max) %>% 
  mutate(yr_lag = time - time_pre)
# hrs
hrsanalysis_parents_rank_max <- left_join(hrsanalysis_parents_rank_above_max, 
                                          hrsanalysis_parents_rank_below_max) %>% 
  mutate(yr_lag = time - time_pre)
hrsanalysis_nonparents_rank_max <- left_join(hrsanalysis_nonparents_rank_above_max, 
                                             hrsanalysis_nonparents_rank_below_max) %>% 
  mutate(yr_lag = time - time_pre)

rm(list = ls(pattern = paste0(c("_below_max", "_above_max"), collapse="|")))

rank_order_df_max <- as.data.frame(
  cbind(cor_all = rep(NA, 24), cor_gp = rep(NA, 24), cor_con = rep(NA, 24), p = rep(NA, 24)))

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 20, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = paste0(datasets[j], "_rank_max")
    # simple correlations
    cor_all <- as.numeric(get(dataset) %>% 
      filter(!is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_gp <-  as.numeric(get(dataset) %>% 
      filter(grandparent==1 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_con <- as.numeric(get(dataset) %>% 
      filter(grandparent==0 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    # interaction model as significance test for group differences
    formula_rank <- formula(paste(outcome, paste0(outcome, "_pre*grandparent"), sep = "~"))
    rank_order_int_max <- lm(formula = formula_rank, data = get(dataset))
    # save in df
    rank_order_df_max[pos + j, ] <- 
      c(cor_all, cor_gp, cor_con, summary(rank_order_int_max)$coef[4, 4]) # interaction p-val. 
    rownames(rank_order_df_max)[pos + j] <- paste0(outcomes[i], "_", datasets_short[j], "_rank")
  }
}

# third alternative: unique pid's
# remove pid duplicates resulting from matching with replacement 
# (might bias results towards greater stability in the controls)
draw_below_uni <- function(x) { 
  x %>% 
  group_by(pid) %>% 
  filter(time==matchtime) %>% arrange(desc(time)) %>% # match time closest to transition 
  slice(n=1) %>% ungroup() %>% # only 1 row per pid
  select(pid, grandparent, time_pre = time, 
         agree_pre = agree, con_pre = con, extra_pre = extra, 
         neur_pre = neur, open_pre = open, swls_pre = swls) }
draw_above_uni <- function(x) { 
  x %>% 
  filter(time>=0) %>% group_by(match_number) %>% slice_min(time) %>% ungroup() %>% 
  group_by(pid) %>% slice(n=1) %>% ungroup() %>% # 1 row per pid (closest to transition)
  select(pid, grandparent, time, all_of(outcomes)) }

list_below_uni <- list(lissanalysis_parents, lissanalysis_nonparents,
                       hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_below_uni)
list_above_uni <- list(lissanalysis_parents, lissanalysis_nonparents,
                       hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_above_uni)
names(list_below_uni) <- paste0(datasets, "_rank_below_uni")
names(list_above_uni) <- paste0(datasets, "_rank_above_uni")

list2env(c(list_below_uni, list_above_uni), .GlobalEnv)

# liss
lissanalysis_parents_rank_uni <- left_join(lissanalysis_parents_rank_above_uni, 
                                           lissanalysis_parents_rank_below_uni) %>% 
  mutate(yr_lag = time - time_pre)
lissanalysis_nonparents_rank_uni <- left_join(lissanalysis_nonparents_rank_above_uni, 
                                              lissanalysis_nonparents_rank_below_uni) %>% 
  mutate(yr_lag = time - time_pre)
# hrs
hrsanalysis_parents_rank_uni <- left_join(hrsanalysis_parents_rank_above_uni, 
                                          hrsanalysis_parents_rank_below_uni) %>% 
  mutate(yr_lag = time - time_pre)
hrsanalysis_nonparents_rank_uni <- left_join(hrsanalysis_nonparents_rank_above_uni, 
                                             hrsanalysis_nonparents_rank_below_uni) %>% 
  mutate(yr_lag = time - time_pre)

rm(list = ls(pattern = paste0(c("_below_uni", "_above_uni"), collapse="|")))

rank_order_df_uni <- as.data.frame(
  cbind(cor_all = rep(NA, 24), cor_gp = rep(NA, 24), cor_con = rep(NA, 24), p = rep(NA, 24)))

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 20, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = paste0(datasets[j], "_rank_uni")
    # simple correlations
    cor_all <- as.numeric(get(dataset) %>% 
      filter(!is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_gp <-  as.numeric(get(dataset) %>% 
      filter(grandparent==1 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_con <- as.numeric(get(dataset) %>% 
      filter(grandparent==0 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    # interaction model as significance test for group differences
    formula_rank <- formula(paste(outcome, paste0(outcome, "_pre*grandparent"), sep = "~"))
    rank_order_int_uni <- lm(formula = formula_rank, data = get(dataset))
    # save in df
    rank_order_df_uni[pos + j, ] <- 
      c(cor_all, cor_gp, cor_con, summary(rank_order_int_uni)$coef[4, 4]) # interaction p-val. 
    rownames(rank_order_df_uni)[pos + j] <- paste0(outcomes[i], "_", datasets_short[j], "_rank")
  }
}
```

## Descriptive Results

Means and standard deviations of the Big Five and life satisfaction over the analyzed time points are presented in Tables \@ref(tab:descriptives-liss) and \@ref(tab:descriptives-hrs). <!--Standard deviations for life satisfaction are considerably larger than those of the Big Five. -->Visually represented (see Fig. \@ref(fig:loess-agree)-\@ref(fig:loess-swls)), all six outcomes display marked stability over time in both LISS and HRS. Intra-class correlations (see Table \@ref(tab:icc-table)) show that large portions of the total variance in the Big Five could be explained by nesting in participants (*median* = `r median(c(icc_list[c(1,4,7,10), 1], icc_list[c(1,4,7,10), 2], icc_list[c(1,4,7,10), 3], icc_list[c(1,4,7,10), 4], icc_list[c(1,4,7,10), 5]))`), while nesting in households only accounted for minor portions (*median* = `r median(c(icc_list[c(2,5,8,11), 1], icc_list[c(2,5,8,11), 2], icc_list[c(2,5,8,11), 3], icc_list[c(2,5,8,11), 4], icc_list[c(2,5,8,11), 5]))`). For outcome--subsample combinations with an $ICC_{hid}$ below $.05$ we omitted the household nesting factor from all models because the nesting otherwise frequently lead to computational errors---a small deviation from our preregistration. For life satisfaction the nesting in households accounted for slightly larger portions of the total variance (*median* = `r median(icc_list[c(2,5,8,11), 6])`) than nesting in participants (*median* = `r median(icc_list[c(1,4,7,10), 6])`). Over all outcomes, the proportion of variance due to within-person factors was relatively low (*median* = `r 1 - median(c(icc_list[c(3,6,9,12), 1], icc_list[c(3,6,9,12), 2], icc_list[c(3,6,9,12), 3], icc_list[c(3,6,9,12), 4], icc_list[c(3,6,9,12), 5], icc_list[c(3,6,9,12), 6]))`).  

## Mean-Level Changes

### Agreeableness

In the basic models (see Tables \@ref(tab:H1-agree-tab) & \@ref(tab:H1-agree-contrasts) and Figure \@ref(fig:H1-agree-fig)), grandparents in the LISS increased slightly in agreeableness in the years after the transition to grandparenthood as compared to the parent controls, `r agree_liss_parents_summary$estimate$after_grandparent`, `r agree_liss_parents_p["after:grandparent",]`. However, this effect was quite small and not significant when compared against the nonparent controls, or against either control sample in the HRS sample (suggestive evidence in the HRS nonparents: `r agree_hrs_nonparents_summary$estimate$after_grandparent`, `r agree_hrs_nonparents_p["after:grandparent",]`). The models including the gender interaction (see Tables \@ref(tab:H1-agree-gender-tab) & \@ref(tab:H1-agree-gender-contrasts) and Figure \@ref(fig:H1-agree-fig)) indicate that grandfathers' post-transition increases in agreeableness were more pronounced as compared to parent (LISS: `r agree_liss_parents_gender_summary$estimate$after_grandparent`, `r agree_liss_parents_gender_p["after:grandparent",]`; HRS: `r agree_hrs_parents_gender_summary$estimate$after_grandparent`, `r agree_hrs_parents_gender_p["after:grandparent",]`) and nonparent controls (HRS: `r agree_hrs_nonparents_gender_summary$estimate$after_grandparent`, `r agree_hrs_nonparents_gender_p["after:grandparent",]`), whereas grandmothers did not differ from female controls.  
There is suggestive evidence for a moderation by paid work (see Tables \@ref(tab:H1-agree-work-tab) & \@ref(tab:H1-agree-work-contrasts) and Figure \@ref(fig:H1-agree-work-fig)): non-working grandparents increased more in agreeableness than working grandparents in anticipation of the transition to grandparenthood (difference in *before* parameter; parents: `r contrasts_work_agree$hrs_parents["before_nowork_vs_work_gp", "all"]`; nonparents: `r contrasts_work_agree$hrs_nonparents["before_nowork_vs_work_gp", "all"]`). Grandparents providing substantial grandchild care increased in agreeableness after the transition to grandparenthood compared to matched nonparent controls (difference in *after* parameter: `r contrasts_care_agree$hrs_nonparents["after_gp_vs_control_care", "all"]`; suggestive evidence in the parent sample: `r contrasts_care_agree$hrs_parents["after_gp_vs_control_care", "all"]`; see Tables \@ref(tab:H1-agree-care-tab) & \@ref(tab:H1-agree-care-contrasts) and Figure \@ref(fig:H1-agree-care-fig)). However, differences between caring and non-caring grandparents---as specified in hypothesis H1b---are not significant in either sample.  

### Conscientiousness

We found a slight post-transition increase in grandparents' conscientiousness in comparison to the controls in the HRS (parents: `r con_hrs_parents_summary$estimate$after_grandparent`, `r con_hrs_parents_p["after:grandparent",]`; nonparents: `r con_hrs_nonparents_summary$estimate$after_grandparent`, `r con_hrs_nonparents_p["after:grandparent",]`; suggestive evidence in the LISS parent sample: `r con_liss_parents_summary$estimate$after_grandparent`, `r con_liss_parents_p["after:grandparent",]`; see Tables \@ref(tab:H1-con-tab) & \@ref(tab:H1-con-contrasts) and Figure \@ref(fig:H1-con-fig)). Grandparents' conscientiousness trajectories were not significantly moderated by gender (see Tables \@ref(tab:H1-con-gender-tab) & \@ref(tab:H1-con-gender-contrasts) and Figure \@ref(fig:H1-con-fig)).  
However, there were significant differences in conscientiousness depending on grandparents' work status (see Tables \@ref(tab:H1-con-work-tab) & \@ref(tab:H1-con-work-contrasts) and Figure \@ref(fig:H1-con-work-fig)): non-working grandparents saw more pronounced increases in conscientiousness in the years before the transition to grandparenthood compared to non-working parent, `r con_hrs_parents_work_summary$estimate$before_grandparent`, `r con_hrs_parents_work_p["before:grandparent",]`, and nonparent controls, `r con_hrs_nonparents_work_summary$estimate$before_grandparent`, `r con_hrs_nonparents_work_p["before:grandparent",]`, and compared to working grandparents (difference in *before* parameter; parents: `r contrasts_work_con$hrs_parents["before_nowork_vs_work_gp", "all"]`; nonparents: `r contrasts_work_con$hrs_nonparents["before_nowork_vs_work_gp", "all"]`). There is suggestive evidence that grandparents who provided substantial grandchild care increased more strongly in conscientiousness after the transition compared to grandparents who did not (difference in *after* parameter; parents: `r contrasts_care_con$hrs_parents["after_nocare_vs_care_gp", "all"]`; nonparents: `r contrasts_care_con$hrs_nonparents["after_nocare_vs_care_gp", "all"]`; see Tables \@ref(tab:H1-con-care-tab) & \@ref(tab:H1-con-care-contrasts) and Figure \@ref(fig:H1-con-care-fig)).  

### Extraversion

The trajectories of grandparents' extraversion closely followed those of the matched controls. There were no significant effects indicating differences between grandparents and controls in the basic models (see Tables \@ref(tab:H1-extra-tab) & \@ref(tab:H1-extra-contrasts) and Figure \@ref(fig:H1-extra-fig)), the models including the gender interaction (see Tables \@ref(tab:H1-extra-gender-tab) & \@ref(tab:H1-extra-gender-contrasts) and Figure \@ref(fig:H1-extra-fig)), or the models of moderation by paid work (see Tables \@ref(tab:H1-extra-work-tab) & \@ref(tab:H1-extra-work-contrasts) and Figure \@ref(fig:H1-extra-work-fig)). The only significant effect for extraversion is found in the analysis of moderation by grandchild care (see Tables \@ref(tab:H1-extra-care-tab) & \@ref(tab:H1-extra-care-contrasts) and Figure \@ref(fig:H1-extra-care-fig)): compared to matched parent controls grandparents providing substantial grandchild care increased slightly more strongly in extraversion after the transition to grandparenthood (difference in *after* parameter: `r contrasts_care_extra$hrs_parents["after_gp_vs_control_care", "all"]`; suggestive evidence in the nonparent sample: `r contrasts_care_extra$hrs_nonparents["after_gp_vs_control_care", "all"]`).  

### Neuroticism

The basic models for neuroticism (see Tables \@ref(tab:H1-neur-tab) & \@ref(tab:H1-neur-contrasts) and Figure \@ref(fig:H1-neur-fig)) show only minor differences between grandparents and matched controls: Compared to the parent controls, grandparents in the HRS shifted slightly downward in their neuroticism immediately after the transition to grandparenthood (difference in *shift* parameter: `r contrasts_neur$hrs_parents["shift_gp_vs_control", "all"]`), which was not the case in the three other samples (HRS nonparents, LISS parents, and LISS nonparents). Further, in the HRS there is suggestive evidence that grandparents increased in neuroticism before the transition to grandparenthood compared to the nonparent controls, `r neur_hrs_nonparents_summary$estimate$before_grandparent`, `r neur_hrs_nonparents_p["before:grandparent",]`. The models including the gender interaction (see Tables \@ref(tab:H1-neur-gender-tab) & \@ref(tab:H1-neur-gender-contrasts) and Figure \@ref(fig:H1-neur-fig)) show one significant effect in the comparison of grandparents and controls: In the HRS, grandfathers, as compared to male parent controls, shifted downward in neuroticism directly after the transition to grandparenthood (difference in *shift* parameter: `r contrasts_gender_neur$hrs_parents["shift_gp_vs_control_men", "all"]`; suggestive evidence in the nonparent sample: `r contrasts_gender_neur$hrs_nonparents["shift_gp_vs_control_men", "all"]`). There is suggestive evidence that grandfathers in the HRS increased more strongly in neuroticism before the transition than the male controls (parent controls: `r neur_hrs_parents_gender_summary$estimate$before_grandparent`, `r neur_hrs_parents_gender_p["before:grandparent",]`; nonparent controls: `r neur_hrs_nonparents_gender_summary$estimate$before_grandparent`, `r neur_hrs_nonparents_gender_p["before:grandparent",]`). Thus, effects present in the basic models seem to be mostly due to differences in the grandfathers (vs. male controls).   
Grandparents' trajectories of neuroticism as compared to the controls were significantly moderated by paid work (see Tables \@ref(tab:H1-neur-work-tab) & \@ref(tab:H1-neur-work-contrasts) and Figure \@ref(fig:H1-neur-work-fig)): Compared to working nonparent controls, working grandparents increased more strongly in neuroticism in the years before the transition to grandparenthood (difference in *before* parameter: `r contrasts_work_neur$hrs_nonparents["before_gp_vs_control_work", "all"]`; suggestive evidence in the parent sample: `r contrasts_work_neur$hrs_parents["before_gp_vs_control_work", "all"]`). At the first post-transition assessment, working grandparents shifted downward in neuroticism compared to working parent controls (difference in *shift* parameter: `r contrasts_work_neur$hrs_parents["shift_gp_vs_control_work", "all"]`; suggestive evidence in the nonparent sample: `r contrasts_work_neur$hrs_nonparents["shift_gp_vs_control_work", "all"]`). There is suggestive evidence that grandparents providing substantial grandchild care decreased more strongly in neuroticism after the transition to grandparenthood than grandparents who did not (difference in *after* parameter; parents: `r contrasts_care_neur$hrs_parents["after_nocare_vs_care_gp", "all"]`; nonparents: `r contrasts_care_neur$hrs_nonparents["after_nocare_vs_care_gp", "all"]`; see Tables \@ref(tab:H1-neur-care-tab) & \@ref(tab:H1-neur-care-contrasts) and Figure \@ref(fig:H1-neur-care-fig)).  

### Openness

For openness, we also found a high degree of similarity between the grandparents and the matched control subjects in their trajectories based on the basic models (see Tables \@ref(tab:H1-open-tab) & \@ref(tab:H1-open-contrasts) and Figure \@ref(fig:H1-open-fig)) and models including the gender interaction (see Tables \@ref(tab:H1-open-gender-tab) & \@ref(tab:H1-open-gender-contrasts) and Figure \@ref(fig:H1-open-fig)). Grandparents in the HRS shifted downward in openness in the first assessment after the transition to grandparenthood compared to the parent controls (difference in *shift* parameter: `r contrasts_open$hrs_parents["shift_gp_vs_control", "all"]`; suggestive evidence in the nonparent sample: `r contrasts_open$hrs_nonparents["shift_gp_vs_control", "all"]`), which is due to significant differences between grandfathers and male parent controls (difference in *shift* parameter: `r contrasts_gender_open$hrs_parents["shift_gp_vs_control_men", "all"]`). There is suggestive evidence that grandmothers in the LISS increased more strongly in openness before the transition to grandparenthood than female controls (difference in *before* parameter; parents: `r contrasts_gender_open$liss_parents["before_gp_vs_control_women", "all"]`; nonparents: `r contrasts_gender_open$liss_nonparents["before_gp_vs_control_women", "all"]`).  
Performing paid work moderated grandparents' trajectories in subtle ways (see Tables \@ref(tab:H1-open-work-tab) & \@ref(tab:H1-open-work-contrasts) and Figure \@ref(fig:H1-open-work-fig)): Non-working grandparents increased more strongly in openness post-transition than non-working controls (parents: `r open_hrs_parents_work_summary$estimate$after_grandparent`, `r open_hrs_parents_work_p["after:grandparent",]`; nonparents: `r open_hrs_nonparents_work_summary$estimate$after_grandparent`, `r open_hrs_nonparents_work_p["after:grandparent",]`). Further, there is suggestive evidence that openness of non-working grandparents shifted downward directly after the transition compared to non-working controls (difference in *shift* parameter; parents: `r contrasts_work_open$hrs_parents["shift_gp_vs_control_nowork", "all"]`; nonparents: `r contrasts_work_open$hrs_nonparents["shift_gp_vs_control_nowork", "all"]`). However, compared to non-working grandparents, working grandparents shifted upward in openness directly after the transition (suggestive evidence for difference in *shift* parameter; parents: `r contrasts_work_open$hrs_parents["shift_nowork_vs_work_gp", "all"]`; nonparents: `r contrasts_work_open$hrs_nonparents["shift_nowork_vs_work_gp", "all"]`) and decreased afterwards (suggestive evidence for difference in *after* parameter; parents: `r contrasts_work_open$hrs_parents["after_nowork_vs_work_gp", "all"]`; nonparents: `r contrasts_work_open$hrs_nonparents["after_nowork_vs_work_gp", "all"]`). The analysis of moderation by grandchild care (see Tables \@ref(tab:H1-open-care-tab) & \@ref(tab:H1-open-care-contrasts) and Figure \@ref(fig:H1-open-care-fig)) reveals that grandparents providing substantial grandchild care increased more strongly in openness after the transition to grandparenthood than the matched nonparent controls (difference in *after* parameter: `r contrasts_care_open$hrs_nonparents["after_gp_vs_control_care", "all"]`; suggestive evidence in the parent sample: `r contrasts_care_open$hrs_parents["after_gp_vs_control_care", "all"]`). At the same time, the plotted trajectories demonstrate that the described moderation effects for openness were all quite small.  

### Life Satisfaction

The basic models for life satisfaction (see Tables \@ref(tab:H1-swls-tab) & \@ref(tab:H1-swls-contrasts) and Figure \@ref(fig:H1-swls-fig)) show that grandparents in the LISS increased more strongly in life satisfaction directly following the transition compared to nonparent controls (difference in *shift* parameter: `r contrasts_swls$liss_nonparents["shift_gp_vs_control", "all"]`). In the HRS, there is suggestive evidence that grandparents increased more strongly in life satisfaction before the transition to grandparenthood than matched parent controls, `r swls_hrs_parents_summary$estimate$before_grandparent`, `r swls_hrs_parents_p["before:grandparent",]`. There is evidence in the models including the gender interaction (see Tables \@ref(tab:H1-swls-gender-tab) & \@ref(tab:H1-swls-gender-contrasts) and Figure \@ref(fig:H1-swls-fig)) that these differences were due to grandmothers, who increased more strongly in life satisfaction directly following the transition to grandparenthood than female nonparent controls in the LISS (difference in *shift* parameter: `r contrasts_gender_swls$liss_nonparents["shift_gp_vs_control_women", "all"]`) and increased more strongly before the transition to grandparenthood compared to female parent controls in the HRS (difference in *before* parameter: `r contrasts_gender_swls$hrs_parents["before_gp_vs_control_women", "all"]`).  
The models of moderation by paid work give suggestive evidence that working grandparents increased in life satisfaction before the transition to grandparenthood compared to working parent controls (difference in *before* parameter: `r contrasts_work_swls$hrs_parents["before_gp_vs_control_work", "all"]`; see Tables \@ref(tab:H1-swls-work-tab) & \@ref(tab:H1-swls-work-contrasts) and Figure \@ref(fig:H1-swls-work-fig)). There is no evidence for a moderation by grandchild care (see Tables \@ref(tab:H1-swls-care-tab) & \@ref(tab:H1-swls-care-contrasts) and Figure \@ref(fig:H1-swls-care-fig)).  

## Interindividual Differences in Change

First, we conducted comparisons of model fit between the random-intercept models reported previously and models where a random slope variance was estimated, separately for each change parameter. These comparisons showed a substantial amount of interindividual differences in change for all random slopes in all models as indicated by increases in model fit significant at `r anova_summaries$agree_lissanalysis_parents_comp$p[1]`.  
Second, we estimated models with heterogeneous random slope variances between the grandparents and each control group in order to test whether interindividual differences in change were significantly larger in the grandparents. Contrary to hypothesis H2, for agreeableness, conscientiousness, and extraversion, interindividual differences in intraindividual change were greater in the control group for all tested effects (see Tables \@ref(tab:H2-hetvar-tab-agree), \@ref(tab:H2-hetvar-tab-con), & \@ref(tab:H2-hetvar-tab-extra)). In the two HRS samples, assuming group heterogeneity in the random slope variances lead to significant improvements in model fit in all model comparisons. In the two LISS samples, this was the case for around half the tests.  
Interindividual differences in changes in neuroticism before the transition to grandparenthood were significantly greater in the HRS grandparents than the nonparent controls (random slope variance of the *before* parameter), *likelihood ratio* = `r hetvar_summaries$neur_hrsanalysis_nonparents_hetvar$lratio[1]`, `r hetvar_summaries$neur_hrsanalysis_nonparents_hetvar$p[1]`. However, this was not the case in the comparison of grandparents with parent controls in the HRS or either control group in the LISS (see Table \@ref(tab:H2-hetvar-tab-neur)). The other parameters of change in neuroticism did not differ significantly between groups in their random slope variances or---in the HRS---displayed significantly larger random slope variances in the respective control group.  
For openness, interindividual differences in changes before the transition to grandparenthood were significantly greater in the LISS grandparents than the nonparent controls (random slope variance of the *before* parameter), *likelihood ratio* = `r hetvar_summaries$open_lissanalysis_nonparents_hetvar$lratio[1]`, `r hetvar_summaries$open_lissanalysis_nonparents_hetvar$p[1]`. Again, this result could not be replicated in the other three samples, and the other parameters of change did either not differ between groups in their random slope variances or had significantly larger random slope variances in the respective control group (see Table \@ref(tab:H2-hetvar-tab-open)).  
We found partial evidence for larger interindividual differences in grandparents' changes in life satisfaction (see Table \@ref(tab:H2-hetvar-tab-swls)): In the LISS, grandparents' changes before the transition to grandparenthood varied interindividually to a larger extent compared to the parent controls (random slope variance of the *before* parameter), *likelihood ratio* = `r hetvar_summaries$swls_lissanalysis_parents_hetvar$lratio[1]`, `r hetvar_summaries$swls_lissanalysis_parents_hetvar$p[1]`, and in the HRS compared to the nonparent controls, *likelihood ratio* = `r hetvar_summaries$swls_hrsanalysis_nonparents_hetvar$lratio[1]`, `r hetvar_summaries$swls_hrsanalysis_nonparents_hetvar$p[1]`. We found suggestive evidence for larger interindividual differences in grandparents' linear post-transition changes compared to the parent controls (random slope variance of the *after* parameter), *likelihood ratio* = `r hetvar_summaries$swls_lissanalysis_parents_hetvar$lratio[4]`, `r hetvar_summaries$swls_lissanalysis_parents_hetvar$p[4]`, and in sudden shifts directly after the transition was first reported (random slope variance of the *shift* parameter), *likelihood ratio* = `r hetvar_summaries$swls_lissanalysis_parents_hetvar$lratio[7]`, `r hetvar_summaries$swls_lissanalysis_parents_hetvar$p[7]`. Still, the majority of tests for heterogeneous random slope variance in life satisfaction indicated either non-significant differences or significantly larger random slope variances in the control sample.  

## Rank-Order Stability 

As indicators of rank-order stability, we computed test-retest correlations for the Big Five and life satisfaction for the matched sample, as well as separately for grandparents only and controls only (see Table \@ref(tab:H3-rankorder-tab)). In `r rank_order_df %>% filter(cor_gp<cor_con) %>% summarise(n())` out of `r rank_order_df %>% summarise(n())` comparisons grandparents' test-retest correlation was lower than that of the respective control group. However, differences in rank-order stability between the grandparents and control participants did not reach significance in any of these comparisons. We found suggestive evidence that rank-order stability in the HRS was higher in the grandparents for extraversion than in either parent, `r gsub(scales::pvalue(rank_order_df["extra_hrs_parents_rank", "p"], prefix = c("$p$ < ", "$p$ = ", "$p$ > ")), pattern="0\\.", replacement="\\.")`, or nonparent controls, `r gsub(scales::pvalue(rank_order_df["extra_hrs_nonparents_rank", "p"], prefix = c("$p$ < ", "$p$ = ", "$p$ > ")), pattern="0\\.", replacement="\\.")`, and that for openness it was larger in the grandparents than in the parent controls, `r gsub(scales::pvalue(rank_order_df["open_hrs_parents_rank", "p"], prefix = c("$p$ < ", "$p$ = ", "$p$ > ")), pattern="0\\.", replacement="\\.")`. In the LISS, there was suggestive evidence that grandparents' rank-order stability in agreeableness was higher than that of the nonparent controls, `r gsub(scales::pvalue(rank_order_df["agree_liss_nonparents_rank", "p"], prefix = c("$p$ < ", "$p$ = ", "$p$ > ")), pattern="0\\.", replacement="\\.")`.  
Overall, we found no confirmatory evidence in support of hypothesis H3.[^f14]  

[^f14]: In addition to the preregistered retest interval, we have also computed a maximally large retest interval between the first available pre-transition assessment and the last available post-transition assessment within the observation period. Here, `r rank_order_df_max %>% filter(cor_gp<cor_con) %>% summarise(n())` out of `r rank_order_df_max %>% summarise(n())` comparisons indicated that rank-order stability was lower in the grandparents, and we found one significant difference in rank-order stability in accordance with our hypothesis: in the HRS, grandparents' rank-order stability in openness was lower than that of the nonparents, `r gsub(scales::pvalue(rank_order_df_max["open_hrs_nonparents_rank", "p"], prefix = c("$p$ < ", "$p$ = ", "$p$ > ")), pattern="0\\.", replacement="\\.")` (see Table \@ref(tab:H3-rankordermax-tab)). In another analysis, we followed the preregistered approach but excluded any duplicate control participants resulting from matching with replacement who might bias results towards greater stability in the controls: `r rank_order_df_uni %>% filter(cor_gp<cor_con) %>% summarise(n())` out of `r rank_order_df_uni %>% summarise(n())` comparisons showed lower rank-order stability in the grandparents compared to either control group (see Table \@ref(tab:H3-rankorderuni-tab)). However, differences between the groups were nonsignificant throughout.  

<!-- whats going on with the within-person variation? maybe look at Dore & Bolger again? -->
<!-- compare within-person variation in the before-slope with the after-slope (only GPs) -->

# Discussion

In an analysis of first-time grandparents in comparison with both parent and nonparent matched control subjects we found pronounced stability in the Big Five and life satisfaction over the transition to grandparenthood. Although there were a few isolated effects in line with our hypotheses on mean-level changes (H1), they were too small in size to be practically meaningful and also not consistent over the two analyzed panel studies---LISS and HRS. We found partial evidence for moderation of the mean-level trajectories of conscientiousness, neuroticism, and openness by performing paid work, and of extraversion and openness by providing substantial grandchild care (contrary to H1b). While interindividual differences in change were present for all parameters of change, they were only greater in the grandparents in a stark minority of conducted model comparisons (H2). Lastly, rank-order stability did not differ between grandparents and either controls group, or was larger in the control group---contrary to expectations (H3).  

## Social Investment Principle

We conducted a robust, multi-comparison, and cross-study test <!-- edit -->of the social investment principle [@robertsPersonalityDevelopmentContext2006; @lodi-smithSocialInvestmentPersonality2007] in middle adulthood and old age where the transition to grandparenthood has been put forward as an important developmental task driving lifespan personality development of the Big Five [@huttemanDevelopmentalTasksFramework2014]. Across all analyzed traits, we found ... . In total, evidence in favor of the social investment principle is thin. This is in line with other recent tests of the principle in the context of parenthood and ?? [@asselmannTestingSocialInvestment2020; @vanscheppingenPersonalityTraitDevelopment2016]. asselmann -> romantic??

Big Five
Social investment / grandparent role / role conflict
- average -> not enough investment -> sub-group analysis in larger dataset (not enough waves of pers?)

LS
In contrast to earlier research

## Interindividual Differences in Change

## Rank-Order Stability

meaningfulness of small effects in psychology (citation?)

agreeableness: compare with literature on generativity (Erikson)  

strength: internal cross-study replication

Further avenues / follow-ups (?)  
- personality maturation cross-culturally: [@bleidornPersonalityMaturationWorld2013; @chopikPersonalityChangeLife2018]  
- other countries with different childcare systems: [@bordonePatternsGrandparentalChild2017]; "in countries with scarce publicly funded daycare services and parental leave grandparental care is often provided on a daily basis"; [@hankGrandparentsCaringTheir2009]  
- facets / nuances [@mottusDevelopmentDetailsAge2021]  

related grandparenthood research  
- arrival of grandchild associated with retirement decisions [@lumsdaineRetirementTimingWomen2015]; pers X WB interaction over retirement [@henningRolePersonalitySubjective2017];  
- Does the Transition to Grandparenthood Deter Gray Divorce? A Test of the Braking Hypothesis [@brownDoesTransitionGrandparenthood2021]  
- prolonged period of grandparenthood? [@margolisHealthyGrandparenthoodHow2017]  
- subjective experience of aging [@bordoneGrandchildrenInfluenceHow2015]  

grandparent role / grandparental investment  
- "refutes the central claim of role theory according to which salient roles are more beneficial to the psychological well-being of the individual than are other roles, especially in old age. It also questions the theoretical framework of grandparent role meaning that is commonly cited in the literature" [@mullerGrandparentingWellbeingHow2011]  
--> see also [@condonFirstTimeGrandparentsRole2019]: First-Time Grandparentsâ Role Satisfaction and Its Determinants  
- "Older grandparents tended to provide financial assistance and more strongly identified with the role. When their grandchildren were younger, grandparents tended to interact more with them, share more activities, provide baby-sitting, and receive more symbolic rewards from the grandparent role." [@silversteinHowAmericansEnact2001]  
- âmaternal grandmothers tend to invest the most in their grandchildren, followed by maternal grandfathers, then paternal grandmothers, with paternal grandfathers investing the leastâ -> also: call for causally informed designs! [@coallGrandparentalInvestmentRelic2011] --> discusses grandparental role investment from an evolutionary perspective --> see also [@danielsbackaGrandparentalChildCare2011]  
- factors determining grandparental investement: [@coallPredictorsGrandparentalInvestment2014]  
- relation to well-being: [@danielsbackaAssociationGrandparentalInvestment2016]  

demographic changes  
- âOver the last two decades, the share of U.S. children under age 18 who live in a multigenerational household (with a grandparent and parent) has increased dramaticallyâ   [@pilkauskasHistoricalTrendsChildren2020] --> for Germany: "on the basis of the DEAS data, the share of grandparents who take care of their grandchildren increased between 2008 and 2014" [@mahneZwischenEnkelgluckUnd2017]  

why is personality important?  
- policy relevance of personality [@bleidornPolicyRelevancePersonality2019], e.g., health outcomes [@turianoPersonalityTraitLevel2012], but not really evidence for healthy neuroticism [@turianoHealthyNeuroticismAssociated2020]  

- mortality & grandparenthood [@christiansenAssociationGrandparenthoodMortality2014]; moderated by race? [@choiGrandparentingMortalityHow2020]; but see HRS -> âGrandparenthood overall was unassociated with mortality risk in both women and menâ [@ellwardtGrandparenthoodRiskMortality2021]  
--> [@hilbrandCaregivingFamilyAssociated2017]: "Survival analyses based on data from the Berlin Aging Study revealed that mortality hazards for grandparents who provided non-custodial childcare were 37% lower than for grandparents who did not provide childcare and for non-grandparents. These associations held after controlling for physical health, age, socioeconomic status and various characteristics of the children and grandchildren."  

## Limitations

Despite  

- Were we able to capture truly socially invested grandparents? a) subjective meaning of life events (Luhmann), b) constraints on investment (physical distance, role conflict (time demands), relationship quality)
-> follow-up: latent class analysis / mixture models 

- differences in Big Five assessment: HRS adjectives vs. LISS statements 

## Conclusions
Our  

## Acknowledgements
We thank X for valuable feedback.  

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup

