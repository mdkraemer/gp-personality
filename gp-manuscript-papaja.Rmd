---
title             : "The Transition to Grandparenthood: No Consistent Evidence for Change in the Big Five Personality Traits and Life Satisfaction"
shorttitle        : "Grandparenthood, Big Five, and Life Satisfaction"



author: 
  - name          : "Author1" 
    affiliation   : "1,2,3"
    corresponding : yes    # Define only one corresponding author
    address       : "Address1"
    email         : "Email1"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Data Curation
      - Formal Analysis
      - Methodology
      - Visualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "Author2"
    affiliation   : "4"
    role:
      - Methodology
      - Writing - Review & Editing
  - name          : "Author3"
    affiliation   : "5"
    role:
      - Methodology
      - Writing - Review & Editing
  - name          : "Author4"
    affiliation   : "1,3"
    role:
      - Supervision
      - Methodology
      - Writing - Review & Editing
      
affiliation:
  - id            : "1"
    institution   : "Institution1"
  - id            : "2"
    institution   : "Institution2"
  - id            : "3"
    institution   : "Institution3"
  - id            : "4"
    institution   : "Institution4"
  - id            : "5"
    institution   : "Institution5"

note: "\\clearpage"

authornote: |
  Authornote1  
  Authornote2  
  Authornote3  
  Authornote4  

abstract: |
 Intergenerational relations have received close attention in the context of population aging and increased childcare provision by grandparents. However, few studies have investigated the psychological consequences of becoming a grandparent. In a preregistered test of grandparenthood as a developmental task in middle and older adulthood, we used representative panel data from the Netherlands (*N* = 563) and the United States (*N* = 2,210) to analyze first-time grandparents' personality and life satisfaction development. We tested gender, employment, and grandchild care as moderators. To address confounding, we employed propensity score matching using two procedures: matching grandparents with parents and nonparents to achieve balance in different sets of carefully selected covariates. Multilevel models demonstrated mean-level stability of the Big Five personality traits and life satisfaction over the transition to grandparenthood, and no consistent moderation effects---contrary to the social investment principle. The few small effects of grandparenthood on personality development did not replicate across samples. We found no evidence of larger interindividual differences in change in grandparents compared to the controls or of lower rank-order stability. Our findings add to recent critical re-examinations of the social investment principle and are discussed in light of characteristics that might moderate grandparents' personality development.  

keywords          : "grandparenthood, Big Five, life satisfaction, personality development, propensity score matching"
# wordcount         : "abc"

bibliography      : ["references-zotero.bib", "references-r.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

csl               : "apa.csl"
documentclass     : "apa7"
classoption       : "man"
output            : papaja::apa6_pdf

header-includes:
  - \usepackage{setspace}
  - \usepackage{amsmath}
#  - \usepackage{float} # these two prevent some weird floating behavior of the figures
#  - \floatplacement{figure}{H}
  - \AtBeginEnvironment{tabular}{\singlespacing}
  - \AtBeginEnvironment{lltable}{\singlespacing}
  - \AtBeginEnvironment{tablenotes}{\doublespacing}
  - \captionsetup[table]{font={stretch=1.5}}
  - \captionsetup[figure]{font={stretch=1.5}}
#  - \renewcommand\author[1]{} # these four lines are to prevent "and &" on title page -> leads to error when knitting on Windows for some reason -> deactivate for now
#  - \renewcommand\affiliation[1]{}
#  - \authorsnames[{1,2,3}, 4, 5, {1,3}]{Author1, Author2, Author3, Author4}
#  - \authorsaffiliations{{Institution1}, {Institution2}, {Institution3}, {Institution4}, {Institution5}}
  - \raggedbottom # prevents LaTeX from varying the spacing between paragraphs to minimise empty space on pages
#  - \usepackage{floatrow}  # https://github.com/crsh/papaja/issues/342
#  - \floatsetup[figure]{capposition=top}

appendix: gp-manuscript-papaja-appendix.Rmd

---

```{r setup, include = FALSE}
library("papaja") # not on CRAN, see https://github.com/crsh/papaja & "Instructions to Reproduce" on OSF
library("citr") # not on CRAN, see https://github.com/crsh/citr
library("multcomp") # for confint of linearHypothesis
library("Hmisc")
library("tidyverse")
library("psych") # for 'describe' demographics
library("GPArotation") # needed for omega function in psych
library("lme4")
library("lmerTest")
library("nlme")
library("cowplot") # for plot grid
library("scales")
library("car") # for linearHypothesis
library("magick") # needed for figure cropping
library("png") # appendix: external png file
library("grid") # also needed for external png file because knitr::include_graphics() is buggy

r_refs("references-r.bib") # has to be deleted to update list in appendix
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

# Set default chunk options (can be overridden in later chunks)
knitr::opts_chunk$set(echo = FALSE, 
                      eval = TRUE,
                      message = FALSE, 
                      fig.path='Figs/',
                      fig.width = 7, 
                      fig.height = 7,
                      results = "hide",
                      error = FALSE,
                      warning = FALSE,
                      include = TRUE,
                      cache = FALSE)
```

```{r load data, include=FALSE}
# load final analyses samples
load(file = "data/processed/LISS/lissanalysis_parents.rda")
load(file = "data/processed/LISS/lissanalysis_nonparents.rda")
load(file = "data/processed/HRS/hrsanalysis_parents.rda")
load(file = "data/processed/HRS/hrsanalysis_nonparents.rda")

# these are for sample size numbers (not contained in the final analysis files, anymore)
load(file = "data/processed/LISS/liss_sampleflow_gp.rda")
load(file = "data/processed/LISS/liss_sampleflow_nongp.rda")
load(file = "data/processed/LISS/liss_replacement_controls.rda")
load(file = "data/processed/HRS/hrs_sampleflow_gp.rda")
load(file = "data/processed/HRS/hrs_sampleflow_nongp.rda")
load(file = "data/processed/HRS/hrs_replacement_controls.rda")

# PSM balance tables
load(file = "data/processed/LISS/liss_balance_df.rda")
load(file = "data/processed/HRS/hrs_balance_df.rda")
```
Becoming a grandparent is an important life event for many people in midlife or old age [@infurnaMidlife2020sOpportunities2020]. In an era of population aging, the time that grandparents are alive and in good health is prolonged compared to previous generations [@margolisHealthyGrandparenthoodHow2017; @leopoldDemographyGrandparenthoodInternational2015; @bengtsonNuclearFamilyIncreasing2001]. In addition, grandparents fulfill an increased share of childcare responsibilities [@hayslipGrandparentsRaisingGrandchildren2019; @pilkauskasHistoricalTrendsChildren2020]. In recent years, intergenerational relations have received heightened attention from psychological and sociological research [@bengtsonNuclearFamilyIncreasing2001; @coallGrandparentalInvestmentRelic2011; @fingermanDecadeResearchIntergenerational2020]. In research on personality development, the transition to grandparenthood has been proposed as an important developmental task arising in old age [@huttemanDevelopmentalTasksFramework2014]. However, empirical research on the psychological consequences of grandparenthood remains sparse. Using data from two nationally representative panel studies, we investigate whether the transition to grandparenthood affects the Big Five personality traits and life satisfaction. We test hypotheses derived from neo-socioanalytic theory [@robertsPersonalityDevelopmentContext2006] in a prospective matched control-group design [see @luhmannStudyingChangesLife2014].  

## Personality Development in Middle and Older Adulthood

The life span perspective conceptualizes aging as a lifelong process of development and adaptation [@baltesLifeSpanTheory2006]. Research embedded in this perspective has found personality traits to be subject to change across the entire life span [@spechtWhatDrivesAdult2014; @spechtPersonalityDevelopmentAdulthood2017; @costaPersonalityLifeSpan2019; @grahamTrajectoriesBigFive2020; for recent reviews, see @bleidornPersonalityTraitStability2021; @robertsPersonalityPsychology2021]. Although a majority of personality development takes place in adolescence and emerging adulthood [@schwabaIndividualDifferencesPersonality2018; @bleidornPersonalityDevelopmentEmerging2017; @puschPersonalityDevelopmentEmerging2019], personality traits also change in middle and older adulthood [e.g., @allemandLongtermCorrelatedChange2008a; @damianSixteenGoingSixtysix2019; @kandlerPatternsSourcesPersonality2015a; @lucasPersonalityDevelopmentLife2011; @mottusPersonalityTraitsOld2012; @muellerPersonalityDevelopmentOld2016; @seifertDevelopmentRankOrderStability2021; @wagnerPersonalityTraitDevelopment2016; for a review, see @spechtPersonalityDevelopmentAdulthood2017].  
Here, we examine the Big Five personality traits---agreeableness, conscientiousness, extraversion, neuroticism, and openness to experience---which constitute a broad categorization of universal patterns of thought, affect, and behavior [@johnParadigmShiftIntegrative2008; @johnBigFiveTrait1999]. Changes over time in the Big Five occur both in mean trait levels [i.e., mean-level change; @robertsPatternsMeanlevelChange2006a] and in the ordering of people relative to each other on trait dimensions [i.e., rank-order stability; @anusicStabilityChangePersonality2016; @robertsRankorderConsistencyPersonality2000]. A lack of observed changes in mean trait levels does not necessarily mean that individual trait levels are stable over time, and perfect rank-order stability does not preclude mean-level changes. Mean-level changes in early to middle adulthood [circa 30--60 years old; @huttemanDevelopmentalTasksFramework2014] are typically characterized by greater maturity, as evidenced by increased agreeableness and conscientiousness and decreased neuroticism [@robertsPatternsMeanlevelChange2006a; @damianSixteenGoingSixtysix2019]. In old age [circa 60 years and older; @huttemanDevelopmentalTasksFramework2014], research is generally more sparse. But there is some evidence of a *reversal* of the maturity effect following retirement [sometimes termed *la dolce vita* effect; @asselmannPersonalityMaturationPersonality2021; @marshMeasurementInvarianceBigfive2013; cf. @schwabaPersonalityTraitDevelopment2019] and at the end of life when health problems arise [@wagnerPersonalityTraitDevelopment2016].  
In terms of rank-order stability, most prior studies have shown support for an inverted U-shape trajectory [@ardeltStillStableAll2000; @lucasPersonalityDevelopmentLife2011; @spechtStabilityChangePersonality2011; @wortmanStabilityChangeBig2012; @seifertDevelopmentRankOrderStability2021]: Rank-order stability rises until it reaches a plateau in midlife, and decreases in old age. However, evidence is mixed on whether rank-order stability decreases again in old age [see @costaPersonalityLifeSpan2019; @wagnerDoesPersonalityBecome2019]. We are not aware of any study investigating trait rank-order stability over the transition to grandparenthood. Other life events are associated with rank-order stability of personality and well-being, although only certain events and traits [e.g., @denissenTransactionsLifeEvents2019; @hentschelInfluenceMajorLife2017; @spechtStabilityChangePersonality2011]. Still, the previously held view that personality is stable or "set like plaster" [@spechtPersonalityDevelopmentAdulthood2017, p. 64] after one reaches adulthood [or leaves emerging adulthood behind; @bleidornPersonalityDevelopmentEmerging2017] has been largely abandoned [@spechtWhatDrivesAdult2014].  
Theories explaining the mechanisms of personality development in middle and older adulthood emphasize genetic influences and life experiences as interdependent sources of stability and change [@wagnerIntegrativeModelSources2020; @spechtWhatDrivesAdult2014; @bleidornPersonalityTraitStability2021]. We conceptualize the transition to grandparenthood as adopting a new social role according to the social investment principle of neo-socioanalytic theory [@robertsPersonalityDevelopmentContext2006; @lodi-smithSocialInvestmentPersonality2007]. The social investment principle states that normative life events or transitions such as entering the work force or becoming a parent lead to personality maturation through adopting new social roles [@robertsEvaluatingFiveFactor2005]. These new roles encourage or compel people to act in a more agreeable, conscientious, and emotionally stable (i.e., less neurotic) way. People's experiences in these roles as well as societal expectations towards them are hypothesized to drive long-term personality development [@lodi-smithSocialInvestmentPersonality2007; @wrzusProcessesPersonalityDevelopment2017].  
Empirical research on life events entailing new social roles has focused on young adulthood: A first romantic relationship [@wagnerFirstPartnershipExperience2015], the transition from high school to university, or a first job [@ludtkeRandomWalkUniversity2011; @asselmannPersonalityMaturationPersonality2021; @golleSchoolWorkChoice2019] co-occur with mean-level changes that are (partly) consistent with the social investment principle [for a review, see @bleidornLifeEventsPersonality2018]. However, recent findings on the transition to parenthood fail to support the social investment principle [@asselmannTestingSocialInvestment2020; @vanscheppingenPersonalityTraitDevelopment2016]. An analysis of trajectories of the Big Five before and after different life events produced limited support for the social investment principle: Small increases in emotional stability occurred following the transition to employment but not in the other traits or following marriage or childbirth [@denissenTransactionsLifeEvents2019].  
Age-graded, normative role transitions may drive personality development across the entire lifespan but they are understudied in middle and older adulthood. Recent research indicates that retirement contributes to personality change following a period of relative stability in midlife [@bleidornRetirementAssociatedChange2018; @schwabaPersonalityTraitDevelopment2019]. These results are only partly in line with the social investment principle regarding mean-level changes and display substantial interindividual differences in change trajectories. Schwaba and Bleidorn described retirement as a "divestment" of social roles [-@schwabaPersonalityTraitDevelopment2019, p. 660; *personality relaxation*, see @asselmannPersonalityMaturationPersonality2021] that functions differently than *social investment*, which adds a role. The grandparent role is one of only a few new normative roles available in middle and older adulthood. It is perceived as highly important and represents a psychologically meaningful role investment [@mahneImportanceGrandparentRole2012; @thieleNatureDimensionsGrandparent2006a]---given that grandparents have regular contact with grandchildren and take part in childcare [@lodi-smithSocialInvestmentPersonality2007]. Mechanisms of grandparents' personality change remain unexplored. However, grandparental role investment may not be linearly related to changes in well-being and health (see section *Life Satisfaction and Grandparenthood*). Instead, moderate levels of grandchild care and contact appear most beneficial. At the same time, even if grandparents do not provide substantial grandchild care, grandparenthood might alter their everyday lives and activities considerably by changing the social structure imposed by kinship bonds [@muellerFamilyContingenciesGenerations2003; @tanskanenIntergenerationalRelationsOffspring2017]. For example, grandchildren might bring about frequent family gatherings, which eventually contribute to grandparents' personality development in a bottom-up fashion.  

## Grandparenthood

The transition to grandparenthood is a time-discrete life event---the beginning of one's status as a grandparent [@luhmannSubjectiveWellbeingAdaptation2012]. In terms of characteristics of major life events [@luhmannDimensionalTaxonomyPerceived2020], the transition to grandparenthood stands out in that it is externally caused [by one's children; see also @arpinoFamilyHistoriesDemography2018; @margolisCohortPerspectiveDemography2019], but also predictable as soon as children reveal their family planning or pregnancy. The transition to grandparenthood has been labeled a countertransition due to this lack of direct control over its timing [@hagestadAgeLifeCourse1985; as cited in @arpinoFamilyHistoriesDemography2018]. Grandparenthood is also generally positive in valence and emotionally significant if the grandparent maintains a good relationship with their child. Grandparents' investments in their grandchildren are beneficial in terms of the evolutionary, economic, and sociological advantages they provide [@coallGrandparentalInvestmentRelic2011; @coallInterdisciplinaryPerspectivesGrandparental2018].  
Grandparenthood is a developmental task [@huttemanDevelopmentalTasksFramework2014] that generally takes place in (early) old age, although this varies considerably both within and between cultures [@leopoldDemographyGrandparenthoodInternational2015; @skopekWhoBecomesGrandparent2017]. Still, the period in which parents experience the birth of their first grandchild coincides with the end of (relative) personality stability in midlife [@spechtPersonalityDevelopmentAdulthood2017], when retirement, shifting social roles, and initial cognitive and health declines can disrupt life circumstances, setting processes of personality development in motion [e.g., @muellerPersonalityDevelopmentOld2016; @stephanPhysicalActivityPersonality2014]. As a developmental task, grandparenthood is considered part of a normative sequence of aging that is subject to societal expectations and values that differ across cultures and historical time [@huttemanDevelopmentalTasksFramework2014; @baltesLifeSpanTheory2006]. Mastering developmental tasks (i.e., fulfilling roles and expectations) is hypothesized to drive positive personality development similarly to propositions of the social investment principle, that is, leading to higher levels of agreeableness and conscientiousness, and lower levels of neuroticism [@robertsEvaluatingFiveFactor2005; @robertsPersonalityDevelopmentContext2006].  
In comparison to the transition to parenthood, which is ambivalent in terms of both personality maturation and changes in life satisfaction [@kramerImpactHavingChildren2020; @vanscheppingenPersonalityTraitDevelopment2016; @aassveFirstGlanceBlack2021; @johnsonImpactHavingChildren2006], Hutteman et al. [-@huttemanDevelopmentalTasksFramework2014] hypothesized that the transition to grandparenthood is positive because it (usually) does not impose the stressful demands of daily childcare on grandparents. However, societal expectations about how grandparents should behave are less clearly defined than expectations around parenthood. There is considerable heterogeneity in how intensely grandparents are involved in their grandchildren's lives and care [@meyerGrandparentingUnitedStates2017]. The degree of possible grandparental investment differs depending on a variety of factors: how close grandparents live to their children, the quality of their relationship, and sociodemographic factors that create conflicting role demands such as paid work or other caregiving responsibilities [@lumsdaineRetirementTimingWomen2015; @silversteinHowAmericansEnact2001; @arpinoConsequencesDepressionCombining2020; @arpinoJugglingGrandchildCare2022]. In the entire population of first-time grandparents, this diversity of possible and desired role investments could generate role conflicts for some grandparents [according to role strain theory; @goodeTheoryRoleStrain1960]. Subsequently, pronounced interindividual differences in intraindividual personality change might then emerge.  

### Life Satisfaction and Grandparenthood 

Although few studies on the Big Five and grandparenthood exist, there is some evidence for life satisfaction, which we define as the general, cognitive appraisal of one's well-being in life based on subjective criteria [@eidScienceSubjectiveWellbeing2008]. Life satisfaction is generally considered less stable than the Big Five and more prone to changes due to environmental influences but still trait-like in its characteristics [@anusicStabilityChangePersonality2016; @kandlerCoreSurfaceCharacteristics2014; @luhmannSubjectiveWellbeingAdaptation2012], and robustly related to the Big Five [@anglimPredictingPsychologicalSubjective2020].  
Longitudinal studies on grandparents' life satisfaction have produced conflicting conclusions: Studies using data from the Survey of Health, Ageing and Retirement in Europe (SHARE) showed that the birth of a grandchild was followed by improvements in quality of life and life satisfaction, but only among women [@tanskanenTransitionGrandparenthoodSubjective2019] and only in first-time grandmothers via their daughters [@digessaBecomingGrandparentIts2019]. Several studies demonstrated that grandparents who were actively involved in childcare experienced larger increases in life satisfaction [@arpinoGrandparentingEducationSubjective2018; @danielsbackaAssociationGrandparentalInvestment2016; @danielsbackaGrandparentalChildcareHealth2019]. On the other hand, fixed effects regression models[^f2] using SHARE data did not find any effects of first-time grandparenthood on life satisfaction regardless of grandparental investment and only minor decreases in depressive symptoms in grandmothers [@sheppardBecomingFirstTimeGrandparent2019; see also @atesDoesGrandchildCare2017, who came to a similar conclusion for self-rated health using data from the German Aging Survey].  
Studies of grandparents' life satisfaction, and well-being and health more generally, have often contrasted role strain theory and role enhancement theory [e.g., @digessaHealthImpactIntensive2016; @xuGrandparentCaregivingPsychological2017; see also @kimPsychologicalWellbeingGrandparents2017]. Role strain theory [@goodeTheoryRoleStrain1960] predicts that investing in grandparenthood alongside other existing roles can produce role conflicts and psychological demands exceeding one's resources. Altogether, these factors prevent adaptive development and lower life satisfaction. Role enhancement theory [@sieberTheoryRoleAccumulation1974], conversely, anticipates adaptive development and well-being benefits because the added social role provides grandparents with status security, social support, and psychological meaning. Empirically, providing substantial grandchild care is, on the one hand, associated with decreased marital satisfaction [@wangImplicationsProvidingGrandchild2020] and increased depressive symptoms if grandparents perceive caregiving as burdensome [@xuGrandparentCaregivingPsychological2017]. On the other hand, it is associated with increased social contact [@quirkeWhatAreSocial2021; @tanskanenIntergenerationalRelationsOffspring2017; cf. @arpinoRegularProvisionGrandchild2017] and a higher quantity (but not quality) of leisure activities [@atesDoesGrandparentalChildcare2021], whereby social engagement serves as a buffer for mental health decreases [@notterGrandchildCareWellBeing2021].  
Research on well-being and health has found evidence for both role strain theory and role enhancement theory depending on the degree of grandparental role investment [@danielsbackaGrandparentingHealthWellbeing2022; @kimPsychologicalWellbeingGrandparents2017]. Whereas no investment or being a grandchild's primary caregiver are associated with adverse effects in most studies, there is evidence that moderate levels of grandchild care have beneficial life satisfaction and health effects for non-coresiding grandparents. This provides preliminary support for the inverted U-shape between investment and utility proposed by Coall and Hertwig [-@coallGrandparentalInvestmentRelic2011]. However, multiple authors have recently emphasized that the literature is still at an early stage and that prior studies often lack representativeness, longitudinal data, and appropriate control for selection effects [@coallInterdisciplinaryPerspectivesGrandparental2018; @danielsbackaGrandparentingHealthWellbeing2022; @kimPsychologicalWellbeingGrandparents2017].  
In summary, evidence is lacking on the Big Five and inconclusive on life satisfaction (and related measures) which is partly due to different methodological approaches that do not account for confounding (i.e., selection effects).  

[^f2]: Fixed effects regression models rely exclusively on within-person variance [see @bruderlFixedEffectsPanelRegression2015; @mcneishFixedEffectsModels2019].  

## Methodological Considerations

Effects of life events on psychological traits tend to be small and need to be analyzed using robust, prospective designs and appropriate control groups [@bleidornLifeEventsPersonality2018; @luhmannStudyingChangesLife2014]. This is necessary because pre-existing differences between prospective grandparents and non-grandparents in variables related to the development of the Big Five or life satisfaction introduce confounding bias when estimating the effects of the transition to grandparenthood [@vanderweeleOutcomeWideLongitudinalDesigns2020]. The impact of adjusting for pre-existing differences was recently emphasized in predicting life outcomes from personality [@beckMegaAnalysisPersonalityPrediction2021]. Propensity score matching is one technique to account for confounding bias by equating groups in their estimated propensity to experience the event [@thoemmesSystematicReviewPropensity2011]. This propensity is calculated from regressing the so-called treatment variable (whether someone experienced the event) on covariates related to the likelihood of experiencing the event and to the outcomes. This approach addresses confounding bias by creating balance between groups in the covariates used to calculate the propensity score [@stuartMatchingMethodsCausal2010].  
We adopt a prospective design that tests the effects of becoming first-time grandparents against two propensity-score-matched control groups separately: first, parents (but not grandparents) with at least one child of reproductive age, and, second, nonparents. This allows us to disentangle potential effects of becoming a grandparent from effects of already being a parent (i.e., parents who eventually become grandparents might share additional similarities with parents who do not). Thus, we can address selection effects into grandparenthood more comprehensively than previous research. We cover the first two of three causal pathways to not experiencing grandparenthood pointed out in demographic research [@margolisCohortPerspectiveDemography2019]: childlessness, childlessness of one's children, and not living long enough to become a grandparent. Our comparative design controls for average age-related and historical trends in the Big Five traits and life satisfaction [@luhmannStudyingChangesLife2014]. The design also enables us to report effects of the transition to grandparenthood unconfounded by instrumentation effects, which describe the tendency of reporting lower well-being scores with each repeated measurement [@bairdLifeSatisfactionLifespan2010].  
We match at a specific time point before the transition to grandparenthood (i.e., at least two years beforehand) and not based on individual survey years. This design choice ensures that the covariates involved in the matching procedure are not already influenced by the event or anticipation of it [@greenlandQuantifyingBiasesCausal2003; @rosenbaumConsquencesAdjustmentConcomitant1984; @vanderweeleOutcomeWideLongitudinalDesigns2020; @vanderweelePrinciplesConfounderSelection2019], thereby reducing the risk of introducing confounding through collider bias [@elwertEndogenousSelectionBias2014]. Similar approaches in the study of life events have been adopted recently [@balboRoleFamilyOrientations2016; @vanscheppingenTrajectoriesLifeSatisfaction2020; @kramerImpactHavingChildren2020].  

## Current Study

In the current study, we examine the development of the Big Five personality traits across the transition to grandparenthood in a prospective, quasi-experimental design, thereby extending previous research on the effects of this transition on well-being to psychological development in a more general sense. We also revisit life satisfaction development, which allows us to anchor our model results. With the literature on grandparenthood and well-being in mind, the current results for life satisfaction constitute a benchmark for the Big Five outcomes. Three research questions motivate the current study which---to our knowledge---is the first to analyze Big Five personality development over the transition to grandparenthood:

1. What are the effects of the transition to grandparenthood on mean-level trajectories of the Big Five traits and life satisfaction?
2. How large are interindividual differences in intraindividual change for the Big Five traits and life satisfaction over the transition to grandparenthood?
3. How does the transition to grandparenthood affect rank-order stability of the Big Five traits and life satisfaction?

To address these questions, we used two nationally representative panel data sets and compared grandparents' development over the transition to grandparenthood with that of matched respondents who did not become grandparents during the study period [@luhmannStudyingChangesLife2014]. Informed by the social investment principle, previous research on personality development in middle and older adulthood, and the literature on grandparenthood and well-being, we preregistered the following hypotheses (see blinded file *Preregistration.pdf* on https://osf.io/75a4r/?view_only=ac929a2c41fb4afd9d1a64a3909848d0):

* H1a: Following the birth of their first grandchild, grandparents increase in agreeableness and conscientiousness, and decrease in neuroticism compared to the matched control groups of parents (but not grandparents) and nonparents. We do not expect the groups to differ in their trajectories of extraversion and openness to experience.
* H1b: Grandparents' post-transition increases in agreeableness and conscientiousness, and decreases in neuroticism are more pronounced among those who provide substantial grandchild care.
* H1c: Grandmothers increase in life satisfaction following the transition to grandparenthood compared to the matched control groups but grandfathers do not.

The heterogeneity in the degree of possible and desired grandparental investment in our samples leads us to expect pronounced interindividual differences in intraindividual change (i.e., deviations from the average trajectories).

* H2: Individual differences in intraindividual change in the Big Five and life satisfaction are larger in the grandparent group than the control groups.

Consequently, assuming that grandparents' personality is rearranged through the experience of the event, we also expect decreases in rank-order stability over the transition to grandparenthood.

* H3: Compared to the matched control groups, grandparents' rank-order stability of the Big Five and life satisfaction over the transition to grandparenthood is smaller.

Finally, commitments to other institutions and roles possibly constrain the amount of possible grandparental investment in line with role strain theory. Alternatively, the added grandparental role could complement existing roles inducing positive psychological development according to role enhancement theory. Thus, exploratorily, we probe the moderator *performing paid work*, which could constitute a role conflict among grandparents. In another exploratory analysis, suggested by an anonymous reviewer, we examine *race/ethnicity* as a moderator, which is associated with differences in the demography of grandparenthood [@margolisCohortPerspectiveDemography2019; @hayslipGrandparentsRaisingGrandchildren2019] and in grandparents' well-being [@goodmanGrandmothersRaisingGrandchildren2006].  

# Methods

## Samples

We used data from two population-representative panel studies: the Longitudinal Internet Studies for the Social Sciences (LISS) panel from the Netherlands, and the Health and Retirement Study (HRS) from the United States.  
The LISS panel is a representative sample of the Dutch population initiated in 2008 with data collection still ongoing [@scherpenzeelDataCollectionProbabilityBased2011; @vanderlaanRepresentativityLISSPanel2009]. It is administered by Centerdata (Tilburg University). The survey population is a true probability sample of households drawn from the population register [@scherpenzeelTrueLongitudinalProbabilitybased2010]. Data collection was carried out online, and respondents were provided technical equipment if needed. We included yearly assessments from 2008 to 2021 as well as basic demographics assessed monthly. For later coding of covariates from these monthly demographic data we used the first available assessment each year.  
The HRS is an ongoing population-representative study of older adults in the United States [@sonnegaCohortProfileHealth2014] administered by the Survey Research Center (University of Michigan). Initiated in 1992 with a first cohort of individuals aged 51-61 and their spouses, the study has since been expanded through additional cohorts (see https://hrs.isr.umich.edu/documentation/survey-design/). In addition to the biennial in-person or telephone interview, since 2006 the study has included a leave-behind questionnaire covering psychosocial topics including personality traits. These topics, however, were only administered every four years starting in 2006 for one half of the sample and in 2008 for the other half. We included personality data from 2006 to 2018, all available data for the coding of the transition to grandparenthood from 1996 to 2018, as well as covariate data from 2006 to 2018 including variables drawn from the Imputations File and the Family Data (only available up to 2014).  
These two panel studies provided the advantage that they contained several waves of personality data as well as information on grandparent status and a broad range of covariates. While the HRS provided a large sample with a wider age range, the LISS was smaller and younger but provided more frequent personality assessments spaced every one to two years. Included grandparents from the LISS were younger because grandparenthood questions were part of the Work and Schooling module and---for reasons unknown to us---filtered to respondents performing paid work. Thus, older, retired first-time grandparents from the LISS could not be identified. 
Even though we have published using the LISS and HRS data before (see preregistration, https://osf.io/75a4r/?view_only=ac929a2c41fb4afd9d1a64a3909848d0), these publications do not overlap with the current study on grandparenthood. The present study used de-identified archival data available in the public domain, which meant that it was not necessary to obtain ethical approval from an IRB.

```{r internal consistency, results="asis", warning=FALSE, message=FALSE}
# internal consistencies at the time of matching

# life satisfaction
alpha_swls_liss_p <- lissanalysis_parents %>% # LISS
  dplyr::select(starts_with("swls"), -swls) %>%
  psych::alpha(check.keys = TRUE)
alpha_swls_liss_np <- lissanalysis_nonparents %>%
  dplyr::select(starts_with("swls"), -swls) %>%
  psych::alpha(check.keys = TRUE)
omega_swls_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  dplyr::select(starts_with("swls"), -swls) %>% 
  psych::omega(m = ., keys = alpha_swls_liss_p$keys, plot = FALSE, nfactors=3)
omega_swls_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  dplyr::select(starts_with("swls"), -swls) %>% 
  psych::omega(m = ., keys = alpha_swls_liss_np$keys, plot = FALSE, nfactors=3)

alpha_swls_hrs_p <- hrsanalysis_parents %>% # HRS
  dplyr::select(starts_with("swls"), -swls) %>%
  psych::alpha(check.keys = TRUE)
alpha_swls_hrs_np <- hrsanalysis_nonparents %>%
  dplyr::select(starts_with("swls"), -swls) %>%
  psych::alpha(check.keys = TRUE)
omega_swls_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  dplyr::select(starts_with("swls"), -swls) %>% 
  psych::omega(m = ., keys = alpha_swls_hrs_p$keys, plot = FALSE, nfactors=3)
omega_swls_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  dplyr::select(starts_with("swls"), -swls) %>% 
  psych::omega(m = ., keys = alpha_swls_hrs_np$keys, plot = FALSE, nfactors=3)

# Big Five: openness to experience
alpha_open_liss_p <- lissanalysis_parents %>% # LISS
  dplyr::select(starts_with("open"), -open) %>%
  psych::alpha(check.keys = TRUE)
alpha_open_liss_np <- lissanalysis_nonparents %>%
  dplyr::select(starts_with("open"), -open) %>%
  psych::alpha(check.keys = TRUE)
omega_open_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  dplyr::select(starts_with("open"), -open) %>% 
  psych::omega(m = ., keys = alpha_open_liss_p$keys, plot = FALSE, nfactors=6)
omega_open_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  dplyr::select(starts_with("open"), -open) %>% 
  psych::omega(m = ., keys = alpha_open_liss_np$keys, plot = FALSE, nfactors=6)

alpha_open_hrs_p <- hrsanalysis_parents %>% # HRS
  dplyr::select(starts_with("open"), -open) %>%
  psych::alpha(check.keys = TRUE)
alpha_open_hrs_np <- hrsanalysis_nonparents %>% 
  dplyr::select(starts_with("open"), -open) %>%
  psych::alpha(check.keys = TRUE)
omega_open_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  dplyr::select(starts_with("open"), -open) %>% 
  psych::omega(m = ., keys = alpha_open_hrs_p$keys, plot = FALSE, nfactors=3)
omega_open_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  dplyr::select(starts_with("open"), -open) %>% 
  psych::omega(m = ., keys = alpha_open_hrs_np$keys, plot = FALSE, nfactors=3)

# Big Five: conscientiousness
alpha_con_liss_p <- lissanalysis_parents %>% # LISS
  dplyr::select(starts_with("con"), -con) %>%
  psych::alpha(check.keys = TRUE)
alpha_con_liss_np <- lissanalysis_nonparents %>% 
  dplyr::select(starts_with("con"), -con) %>%
  psych::alpha(check.keys = TRUE)
omega_con_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  dplyr::select(starts_with("con"), -con) %>% 
  psych::omega(m = ., keys = alpha_con_liss_p$keys, plot = FALSE, nfactors=5)
omega_con_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  dplyr::select(starts_with("con"), -con) %>% 
  psych::omega(m = ., keys = alpha_con_liss_np$keys, plot = FALSE, nfactors=5)

alpha_con_hrs_p <- hrsanalysis_parents %>% # HRS
  dplyr::select(starts_with("con"), -con) %>%
  psych::alpha(check.keys = TRUE)
alpha_con_hrs_np <- hrsanalysis_nonparents %>% 
  dplyr::select(starts_with("con"), -con) %>%
  psych::alpha(check.keys = TRUE)
omega_con_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  dplyr::select(starts_with("con"), -con) %>% 
  psych::omega(m = ., keys = alpha_con_hrs_p$keys, plot = FALSE, nfactors=3)
omega_con_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  dplyr::select(starts_with("con"), -con) %>% 
  psych::omega(m = ., keys = alpha_con_hrs_np$keys, plot = FALSE, nfactors=3)

# Big Five: extraversion
alpha_extra_liss_p <- lissanalysis_parents %>% # LISS
  dplyr::select(starts_with("extra"), -extra) %>%
  psych::alpha(check.keys = TRUE)
alpha_extra_liss_np <- lissanalysis_nonparents %>% 
  dplyr::select(starts_with("extra"), -extra) %>%
  psych::alpha(check.keys = TRUE)
omega_extra_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  dplyr::select(starts_with("extra"), -extra) %>% 
  psych::omega(m = ., keys = alpha_extra_liss_p$keys, plot = FALSE, nfactors=4)
omega_extra_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  dplyr::select(starts_with("extra"), -extra) %>% 
  psych::omega(m = ., keys = alpha_extra_liss_np$keys, plot = FALSE, nfactors=4)

alpha_extra_hrs_p <- hrsanalysis_parents %>% # HRS
  dplyr::select(starts_with("extra"), -extra) %>%
  psych::alpha(check.keys = TRUE)
alpha_extra_hrs_np <- hrsanalysis_nonparents %>% 
  dplyr::select(starts_with("extra"), -extra) %>%
  psych::alpha(check.keys = TRUE)
omega_extra_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  dplyr::select(starts_with("extra"), -extra) %>% 
  psych::omega(m = ., keys = alpha_extra_hrs_p$keys, plot = FALSE, nfactors=3)
omega_extra_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  dplyr::select(starts_with("extra"), -extra) %>% 
  psych::omega(m = ., keys = alpha_extra_hrs_np$keys, plot = FALSE, nfactors=3)

# Big Five: agreeableness
alpha_agree_liss_p <- lissanalysis_parents %>% # LISS
  dplyr::select(starts_with("agree"), -agree) %>%
  psych::alpha(check.keys = TRUE)
alpha_agree_liss_np <- lissanalysis_nonparents %>% 
  dplyr::select(starts_with("agree"), -agree) %>%
  psych::alpha(check.keys = TRUE)
omega_agree_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  dplyr::select(starts_with("agree"), -agree) %>% 
  psych::omega(m = ., keys = alpha_agree_liss_p$keys, plot = FALSE, nfactors=4)
omega_agree_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  dplyr::select(starts_with("agree"), -agree) %>% 
  psych::omega(m = ., keys = alpha_agree_liss_np$keys, plot = FALSE, nfactors=4)

alpha_agree_hrs_p <- hrsanalysis_parents %>% # HRS
  dplyr::select(starts_with("agree"), -agree) %>%
  psych::alpha(check.keys = TRUE)
alpha_agree_hrs_np <- hrsanalysis_nonparents %>% 
  dplyr::select(starts_with("agree"), -agree) %>%
  psych::alpha(check.keys = TRUE)
omega_agree_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  dplyr::select(starts_with("agree"), -agree) %>% 
  psych::omega(m = ., keys = alpha_agree_hrs_p$keys, plot = FALSE, nfactors=3)
omega_agree_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  dplyr::select(starts_with("agree"), -agree) %>% 
  psych::omega(m = ., keys = alpha_agree_hrs_np$keys, plot = FALSE, nfactors=3)

# Big Five: neuroticism
alpha_neur_liss_p <- lissanalysis_parents %>% # LISS
  dplyr::select(starts_with("neur"), -neur) %>%
  psych::alpha(check.keys = TRUE)
alpha_neur_liss_np <- lissanalysis_nonparents %>%
  dplyr::select(starts_with("neur"), -neur) %>%
  psych::alpha(check.keys = TRUE)
omega_neur_liss_p <- lissanalysis_parents %>% filter(matchtime==time) %>% # parents
  dplyr::select(starts_with("neur"), -neur) %>% 
  psych::omega(m = ., keys = alpha_neur_liss_p$keys, plot = FALSE, nfactors=4)
omega_neur_liss_np <- lissanalysis_nonparents %>% filter(matchtime==time) %>% # nonparents
  dplyr::select(starts_with("neur"), -neur) %>% 
  psych::omega(m = ., keys = alpha_neur_liss_np$keys, plot = FALSE, nfactors=4)

alpha_neur_hrs_p <- hrsanalysis_parents %>% # HRS
  dplyr::select(starts_with("neur"), -neur) %>%
  psych::alpha(check.keys = TRUE)
alpha_neur_hrs_np <- hrsanalysis_nonparents %>% 
  dplyr::select(starts_with("neur"), -neur) %>%
  psych::alpha(check.keys = TRUE)
omega_neur_hrs_p <- hrsanalysis_parents %>% filter(time_match==time) %>% # parents
  dplyr::select(starts_with("neur"), -neur) %>% 
  psych::omega(m = ., keys = alpha_neur_hrs_p$keys, plot = FALSE, nfactors=3)
omega_neur_hrs_np <- hrsanalysis_nonparents %>% filter(time_match==time) %>% # nonparents
  dplyr::select(starts_with("neur"), -neur) %>% 
  psych::omega(m = ., keys = alpha_neur_hrs_np$keys, plot = FALSE, nfactors=3)

# put all measures in one table (for supplement)
int_consist <- as.data.frame(rbind(
  rel_liss_parents_om_t = c(omega_agree_liss_p$omega.tot, omega_con_liss_p$omega.tot, 
                            omega_extra_liss_p$omega.tot, omega_neur_liss_p$omega.tot, 
                            omega_open_liss_p$omega.tot, omega_swls_liss_p$omega.tot), 
  rel_liss_parents_om_h = c(omega_agree_liss_p$omega_h, omega_con_liss_p$omega_h, 
                            omega_extra_liss_p$omega_h, omega_neur_liss_p$omega_h, 
                            omega_open_liss_p$omega_h, omega_swls_liss_p$omega_h),
  rel_liss_parents_alph = c(alpha_agree_liss_p$total$raw_alpha, alpha_con_liss_p$total$raw_alpha, 
                            alpha_extra_liss_p$total$raw_alpha, alpha_neur_liss_p$total$raw_alpha, 
                            alpha_open_liss_p$total$raw_alpha, alpha_swls_liss_p$total$raw_alpha), 
  rel_liss_nonparents_om_t = c(omega_agree_liss_np$omega.tot, omega_con_liss_np$omega.tot, 
                               omega_extra_liss_np$omega.tot, omega_neur_liss_np$omega.tot, 
                               omega_open_liss_np$omega.tot, omega_swls_liss_np$omega.tot),
  rel_liss_nonparents_om_h = c(omega_agree_liss_np$omega_h, omega_con_liss_np$omega_h, 
                               omega_extra_liss_np$omega_h, omega_neur_liss_np$omega_h, 
                               omega_open_liss_np$omega_h, omega_swls_liss_np$omega_h),
  rel_liss_nonparents_alph = c(alpha_agree_liss_np$total$raw_alpha, alpha_con_liss_np$total$raw_alpha, 
                               alpha_extra_liss_np$total$raw_alpha, alpha_neur_liss_np$total$raw_alpha, 
                               alpha_open_liss_np$total$raw_alpha, alpha_swls_liss_np$total$raw_alpha), 
  rel_hrs_parents_om_t = c(omega_agree_hrs_p$omega.tot, omega_con_hrs_p$omega.tot, 
                            omega_extra_hrs_p$omega.tot, omega_neur_hrs_p$omega.tot, 
                            omega_open_hrs_p$omega.tot, omega_swls_hrs_p$omega.tot), 
  rel_hrs_parents_om_h = c(omega_agree_hrs_p$omega_h, omega_con_hrs_p$omega_h, 
                            omega_extra_hrs_p$omega_h, omega_neur_hrs_p$omega_h, 
                            omega_open_hrs_p$omega_h, omega_swls_hrs_p$omega_h),
  rel_hrs_parents_alph = c(alpha_agree_hrs_p$total$raw_alpha, alpha_con_hrs_p$total$raw_alpha, 
                            alpha_extra_hrs_p$total$raw_alpha, alpha_neur_hrs_p$total$raw_alpha, 
                            alpha_open_hrs_p$total$raw_alpha, alpha_swls_hrs_p$total$raw_alpha), 
  rel_hrs_nonparents_om_t = c(omega_agree_hrs_np$omega.tot, omega_con_hrs_np$omega.tot, 
                               omega_extra_hrs_np$omega.tot, omega_neur_hrs_np$omega.tot, 
                               omega_open_hrs_np$omega.tot, omega_swls_hrs_np$omega.tot),
  rel_hrs_nonparents_om_h = c(omega_agree_hrs_np$omega_h, omega_con_hrs_np$omega_h, 
                               omega_extra_hrs_np$omega_h, omega_neur_hrs_np$omega_h, 
                               omega_open_hrs_np$omega_h, omega_swls_hrs_np$omega_h),
  rel_hrs_nonparents_alph = c(alpha_agree_hrs_np$total$raw_alpha, alpha_con_hrs_np$total$raw_alpha, 
                               alpha_extra_hrs_np$total$raw_alpha, alpha_neur_hrs_np$total$raw_alpha, 
                               alpha_open_hrs_np$total$raw_alpha, alpha_swls_hrs_np$total$raw_alpha)))
colnames(int_consist) <- c("agree", "con", "extra", "neur", "open", "swls")
```

## Measures

### Personality 

In the LISS, the Big Five personality traits were assessed using the 50-item version of the IPIP Big Five Inventory scales [@goldbergDevelopmentMarkersBigFive1992]. For each trait, respondents answered ten 5-point Likert-scale items (1 = *very inaccurate*, 2 = *moderately inaccurate*, 3 = *neither inaccurate nor accurate*, 4 = *moderately accurate*, 5 = *very accurate*). Example items included "like order" (conscientiousness), "sympathize with others' feelings" (agreeableness), "worry about things" (neuroticism), "have a vivid imagination" (openness), and "start conversations" (extraversion). In each wave, we took a respondent's mean of each subscale as their trait score. Internal consistencies at the time of matching, as indicated by $\omega_h$ [@mcneishThanksCoefficientAlpha2018], averaged $\omega_h =$ `r printnum((rowMeans(int_consist["rel_liss_parents_om_h", 1:5]) + rowMeans(int_consist["rel_liss_nonparents_om_h", 1:5]))/2)` over all traits ($\omega_t =$ `r printnum((rowMeans(int_consist["rel_liss_parents_om_t", 1:5]) + rowMeans(int_consist["rel_liss_nonparents_om_t", 1:5]))/2)`; $\alpha =$ `r printnum((rowMeans(int_consist["rel_liss_parents_alph", 1:5]) + rowMeans(int_consist["rel_liss_nonparents_alph", 1:5]))/2)`; see Table \@ref(tab:int-consist)). Other studies have shown measurement invariance for these scales across time and age groups, and convergent validity with the Big Five Inventory [BFI-2; @schwabaIndividualDifferencesPersonality2018; @denissenBigFiveInventory2020]. The Big Five and life satisfaction were administered yearly but with planned missingness in some years for certain cohorts [see @denissenTransactionsLifeEvents2019]. <!-- Thus, there are one to two years between included assessments, given no other sources of missingness.-->  
In the HRS, the Midlife Development Inventory (MIDI) scales measured the Big Five [@lachmanMidlifeDevelopmentInventory1997] with 26 adjectives (five each for conscientiousness, agreeableness, and extraversion; four for neuroticism; seven for openness). Respondents were asked to rate on a 4-point scale how well each item described them (1 = *a lot*, 2 = *some*, 3 = *a little*, 4 = *not at all*). Example adjectives included "organized" (conscientiousness), "sympathetic" (agreeableness), "worrying" (neuroticism), "imaginative" (openness), and "talkative" (extraversion). For better comparability with the LISS panel, we reverse-scored all items so that higher values corresponded to higher trait levels and, in each wave, took the mean of each subscale as the trait score. Big Five trait scores showed satisfactory internal consistencies at the time of matching that averaged $\omega_h =$ `r printnum((rowMeans(int_consist["rel_hrs_parents_om_h", 1:5]) + rowMeans(int_consist["rel_hrs_nonparents_om_h", 1:5]))/2)` over all traits ($\omega_t =$ `r printnum((rowMeans(int_consist["rel_hrs_parents_om_t", 1:5]) + rowMeans(int_consist["rel_hrs_nonparents_om_t", 1:5]))/2)`; $\alpha =$ `r printnum((rowMeans(int_consist["rel_hrs_parents_alph", 1:5]) + rowMeans(int_consist["rel_hrs_nonparents_alph", 1:5]))/2)`; see Table \@ref(tab:int-consist)).   

### Life Satisfaction 

In both samples, life satisfaction was assessed using the 5-item Satisfaction with Life Scale [SWLS; @dienerSatisfactionLifeScale1985] which respondents answered on a 7-point Likert scale (1 = *strongly disagree*, 2 = *somewhat disagree*, 3 = *slightly disagree*, 4 = *neither agree or disagree*, 5 = *slightly agree*, 6 = *somewhat agree*, 7 = *strongly agree*). An example item was "I am satisfied with my life". Internal consistency at the time of matching was between $\alpha =$ `r printnum(min(c(int_consist["rel_liss_parents_alph", "swls"], int_consist["rel_liss_nonparents_alph", "swls"], int_consist["rel_hrs_parents_alph", "swls"], int_consist["rel_hrs_nonparents_alph", "swls"])))` and $\alpha =$ `r printnum(max(c(int_consist["rel_liss_parents_alph", "swls"], int_consist["rel_liss_nonparents_alph", "swls"], int_consist["rel_hrs_parents_alph", "swls"], int_consist["rel_hrs_nonparents_alph", "swls"])))` in the four analysis samples (see Table \@ref(tab:int-consist)).  

### Transition to Grandparenthood

The procedure to obtain information on the transition to grandparenthood generally followed the same steps in both samples. This coding was based on items that differed slightly, however: In the LISS, respondents performing paid work were asked "Do you have children and/or grandchildren?" and were offered the answer categories "children", "grandchildren", and "no children or grandchildren". In the HRS, all respondents were asked to state their total number of grandchildren: "Altogether, how many grandchildren do you (or your husband / wife / partner, or your late husband / wife / partner) have? Include as grandchildren any children of your (or your [late] husband's / wife's / partner's) biological, step- or adopted children".  
In both samples, we tracked grandparenthood status over time. Due to longitudinally inconsistent data in some cases, we included in the grandparent group only respondents with one transition from 0 (*no grandchildren*) to 1 (*at least one grandchild*) in this status variable, and no transitions backwards (see Figure \@ref(fig:flowchart-participant)). We marked respondents who consistently indicated that they had no grandchildren as potential members of the control groups.  

(ref:flowchart-fig-cap) Participant flowchart demonstrating the composition of the four analysis samples via matching (1:4 matching ratio with replacement). *obs.* = longitudinal observations.

```{r flowchart-participant, fig.align = "center", out.width = "100%", fig.cap="(ref:flowchart-fig-cap)"}
#knitr::include_graphics(".../images/swans.png") 
# this function in combination with papaja or PDF rendering is very buggy
# this was a solution: https://stackoverflow.com/questions/53580306/using-include-graphics-in-r-markdown-does-not-reproduce-the-image-in-html-file
img <- readPNG("gp-participant-flowchart.png")
grid.raster(img)
```

### Moderators

We tested four variables as potential moderators of the mean-level trajectories of the Big Five and life satisfaction over the transition to grandparenthood: First, we analyzed whether female gender (0 = *male*, 1 = *female*) acted as a moderator as indicated by research on life satisfaction [@tanskanenTransitionGrandparenthoodSubjective2019; @digessaBecomingGrandparentIts2019].  
Second, we tested whether performing paid work (0 = *no*, 1 = *yes*) was associated with divergent trajectories of the Big Five and life satisfaction [@schwabaPersonalityTraitDevelopment2019]. Since the LISS subsample consisted solely of respondents performing paid work, we performed these analyses only in the HRS. This served two purposes. On the one hand, it allowed us to test how respondents in the workforce differed from those not working, which might shed light on role conflict and have implications for social investment mechanisms. On the other hand, these moderation analyses allowed us to assess whether potential differences in results between the LISS and HRS samples could be accounted for by including performing paid work as a moderator in HRS analyses. In other words, perhaps HRS respondents performing paid work were similar to those in the LISS sample---those conditioned on this variable through questionnaire filtering.  
Third, we examined how involvement in grandchild care moderated trajectories of the Big Five and life satisfaction [@arpinoGrandparentingEducationSubjective2018; @danielsbackaAssociationGrandparentalInvestment2016; @danielsbackaGrandparentalChildcareHealth2019]. We coded a moderator variable (0 = *provided less than 100 hours of grandchild care*, 1 = *provided 100 or more hours of grandchild care*) based on the question "Did you (or your [late] husband / wife / partner) spend 100 or more hours in total since the last interview / in the last two years taking care of grand- or great grandchildren?". [^f7] This information was only available for grandparents in the HRS; in the LISS, too few respondents answered respective follow-up questions to be included in analyses<!--  (<50 in the final analysis sample)-->.  
Fourth, in the HRS, we compared Black/African American respondents with White respondents.  

[^f7]: Dichotomization of a continuous construct (hours of care) is not ideal for moderation analysis [@maccallumPracticeDichotomizationQuantitative2002]. However, there were too many missing values in the variable assessing hours of care continuously (variables *E063).

```{r descriptive-stats, results="asis", warning=FALSE, message=FALSE}
# age at transition
liss_descriptive1 <- lissanalysis_parents %>% filter(grandparent==1 & matchtime==time) %>%
  mutate(age_transition = age-matchtime) %>% 
  summarise(age_m=mean(age_transition), age_sd=sd(age_transition), gender_m=mean(female), n=n())
hrs_descriptive1 <- hrsanalysis_parents %>% filter(grandparent==1 & last==time) %>% 
  mutate(age_transition = year-birthyr-last) %>% 
  summarise(age_m=mean(age_transition), age_sd=sd(age_transition), gender_m=mean(gender-1), n=n())

# final n
liss_final_n_parents <- lissanalysis_parents %>% group_by(grandparent) %>% 
  summarise(obs = n(), n = n_distinct(match_number))
liss_final_n_nonparents <- lissanalysis_nonparents %>% group_by(grandparent) %>% 
  summarise(obs = n(), n = n_distinct(match_number))
hrs_final_n_parents <- hrsanalysis_parents %>% group_by(grandparent) %>% 
  summarise(obs = n(), n = n_distinct(match_number))
hrs_final_n_nonparents <- hrsanalysis_nonparents %>% group_by(grandparent) %>% 
  summarise(obs = n(), n = n_distinct(match_number))
```

## Procedure

Drawing on all available data, three main restrictions defined the analysis samples of grandparents (see Figure \@ref(fig:flowchart-participant)): First, we identified respondents who indicated having grandchildren for the first time during study participation ($N_{LISS} =$ `r liss_sampleflow_gp[1,2]`; $N_{HRS} =$ `r hrs_sampleflow_gp[1,2]`, including HRS waves 1996-2004 before personality assessments were introduced). Second, we restricted the sample to respondents with at least one valid personality assessment (valid in the sense that at least one of the six outcomes was non-missing; $N_{LISS} =$ `r liss_sampleflow_gp[2,2]`; $N_{HRS} =$ `r hrs_sampleflow_gp[2,2]`). [^f8] Third, we included only respondents with both one valid personality assessment before and one after the transition to grandparenthood ($N_{LISS} =$ `r liss_sampleflow_gp[3,2]`; $N_{HRS} =$ `r hrs_sampleflow_gp[3,2]`). Finally, a few respondents were excluded because of inconsistent or missing information regarding their children resulting in the final analysis samples of first-time grandparents, $N_{LISS} =$ `r liss_sampleflow_gp[4,2]` (`r printnum(liss_descriptive1$gender_m*100)`$\%$ female; age at transition to grandparenthood $M =$ `r printnum(liss_descriptive1$age_m)`, $SD =$ `r printnum(liss_descriptive1$age_sd)`) and $N_{HRS} =$ `r hrs_sampleflow_gp[4,2]` (`r printnum(hrs_descriptive1$gender_m*100)`$\%$ female; age at transition to grandparenthood $M =$ `r printnum(hrs_descriptive1$age_m)`, $SD =$ `r printnum(hrs_descriptive1$age_sd)`).  
We defined two mutually exclusive pools of potential control subjects for matching: The first comprised parents who had at least one child of reproductive age (defined as $15 \leq age_{firstborn}\leq65$) but no grandchildren during the observation period ($N_{LISS} =$ `r liss_sampleflow_nongp[1, 3]` with `r liss_sampleflow_nongp[1, 2]` longitudinal observations; $N_{HRS} =$ `r hrs_sampleflow_nongp[1, 3]` with `r hrs_sampleflow_nongp[1, 2]` longitudinal observations). The second comprised respondents who reported being childless throughout the observation period ($N_{LISS} =$ `r liss_sampleflow_nongp[2, 3]` with `r liss_sampleflow_nongp[2, 2]` longitudinal observations; $N_{HRS} =$ `r hrs_sampleflow_nongp[2, 3]` with `r hrs_sampleflow_nongp[2, 2]` longitudinal observations).  

### Covariates
We used propensity score matching to match each grandparent with a control respondent from each pool of potential controls who was most similar in terms of the included covariates.  
Although critical to the design, covariate selection is seldom explicitly discussed in studies estimating effects of life events (e.g., in matching designs). We see two (in part conflicting) traditions that address covariate selection: First, classic recommendations from psychology are to include all available variables that are associated with both the treatment assignment process (i.e., selection into treatment) and the outcome [e.g., @steinerImportanceCovariateSelection2010; @stuartMatchingMethodsCausal2010]. Second, recommendations from a structural causal modeling perspective [@elwertEndogenousSelectionBias2014; @rohrerThinkingClearlyCorrelations2018] are more cautious, aiming to avoid pitfalls such as conditioning on a pre-treatment collider (collider bias) or a mediator (overcontrol bias). However, structural causal modeling requires advanced knowledge of the causal structures underlying the involved variables [@pearlCausalInferenceStatistics2009].  
In selecting covariates, we followed the guidelines of VanderWeele et al. [-@vanderweeleOutcomeWideLongitudinalDesigns2020; -@vanderweelePrinciplesConfounderSelection2019], which reconcile both views and offer practical guidance when the underlying causal structures are not completely understood and when using large archival datasets. The "modified disjunctive cause criterion" [@vanderweelePrinciplesConfounderSelection2019, p. 218] recommends selecting all available covariates which are assumed to be causes of the outcomes, treatment exposure (i.e., the transition to grandparenthood), or both, as well as any proxies for an unmeasured common cause of the outcomes and treatment exposure. Variables that are assumed to be instrumental variables (i.e., assumed causes of treatment exposure that are unrelated to the outcomes except through the exposure) and collider variables [@elwertEndogenousSelectionBias2014] should be excluded from this selection. Because all covariates we used for matching were measured at least two years before the first grandchild's birth, we judge the risk of introducing collider bias or overcontrol bias to be relatively small. In addition, as mentioned above, the transition to grandparenthood is not planned by or under the direct control of the grandparents, which further reduces the risk of these biases.  
Following these guidelines, we selected covariates covering respondents' demographics (e.g., age, education), economic situation (e.g., income), and health (e.g., mobility difficulties). We also included the pre-transition outcome variables as covariates---as recommended in the literature [@cookHowMuchBias2020; @hallbergPretestMeasuresStudy2018; @steinerImportanceCovariateSelection2010; @vanderweeleOutcomeWideLongitudinalDesigns2020], as well as wave participation count and assessment year in order to control for instrumentation effects and historical trends [e.g., 2008/2009 financial crisis; @bairdLifeSatisfactionLifespan2010; @luhmannStudyingChangesLife2014]. To match grandparents with the parent control group, we additionally selected covariates containing information on fertility and family history (e.g., number of children, age of first three children) which were causally related to the timing of the transition to grandparenthood [@arpinoFamilyHistoriesDemography2018; @margolisCohortPerspectiveDemography2019].  
An overview of all covariates can be found in the supplemental materials (see Tables \@ref(tab:stddiffmeans-balance-liss) & \@ref(tab:stddiffmeans-balance-hrs)). Importantly, as part of our preregistration we justified each covariate, explaining whether we assumed it to be related to the treatment assignment, the outcomes, or both (see *gp-covariates-overview.xlsx* on https://osf.io/75a4r/?view_only=ac929a2c41fb4afd9d1a64a3909848d0). We tried to find substantively equivalent covariates in both samples but had to compromise in a few cases.  
Estimating propensity scores required complete covariate data. Therefore, we performed multiple imputations to address missingness in the covariates [@greenlandCriticalLookMethods1995]. Using five imputed data sets computed by classification and regression trees [CART; @burgetteMultipleImputationMissing2010] in the *mice* R package [@mice2011], we predicted treatment assignment (i.e., the transition to grandparenthood) five times per observation in logistic regressions with a logit link function.[^f10] We averaged these five scores per observation to compute the final propensity score used for matching [@mitraComparisonTwoMethods2016]. We used imputed data only for propensity score computation and not in later analyses because nonresponse in the outcome variables was negligible.  

[^f10]: In these logistic regressions, we included all covariates listed above as predictors except for *female*, which was later used for exact matching, and health-related covariates in LISS wave 2014, which were not assessed in that wave.

### Propensity Score Matching

The time of matching preceded the survey year in which the transition to grandparenthood was first reported by at least two years (aside from that choosing the smallest available gap between matching and transition). This ensured that the covariates were not affected by the event itself or anticipation thereof [i.e., matching occurred well before children would have announced that they were expecting their first child; @greenlandQuantifyingBiasesCausal2003; @rosenbaumConsquencesAdjustmentConcomitant1984; @vanderweeleOutcomeWideLongitudinalDesigns2020]. Propensity score matching was performed using the *MatchIt* R package [@MatchIt2011] with exact matching on gender combined with Mahalanobis distance matching on the propensity score. Four matchings were performed; two per sample (LISS; HRS) and two per control group (parents; nonparents). We matched 1:4 with replacement because of the relatively small pools of available controls.[^f11] We did not specify a caliper because our goal was to find matches for all grandparents, and because we achieved good covariate balance this way.  
We evaluated the matching procedure in terms of covariate balance and graphically [@stuartMatchingMethodsCausal2010]. Covariate balance as indicated by the standardized difference in means between grandparents and controls after matching was good (see Tables \@ref(tab:stddiffmeans-balance-liss) & \@ref(tab:stddiffmeans-balance-hrs)), lying below 0.25 as recommended in the literature [@stuartMatchingMethodsCausal2010], and below 0.10 with few exceptions [@austinIntroductionPropensityScore2011]. Graphically, group differences in the propensity score distributions were small and indicated no substantial missing overlap (see Figure \@ref(fig:pscore-overlap)).  
After matching, each matched control observation was assigned the same value as the matched grandparent in the *time* variable describing the temporal relation to treatment, and the control respondent's other longitudinal observations were centered around this matched observation. We thus coded a counterfactual transition time frame for each control respondent. Due to left- and right-censored longitudinal data (i.e., panel entry or attrition), we restricted the final analysis samples to six years before and six years after the transition, as shown in Table \@ref(tab:piecewise-coding-scheme).  
The final LISS analysis samples (see Figure \@ref(fig:flowchart-participant)) contained `r liss_final_n_parents$n[2]` grandparents with `r liss_final_n_parents$obs[2]` longitudinal observations, matched with `r liss_final_n_parents$n[1]` control respondents with either `r liss_final_n_parents$obs[1]` (parent control group) or `r liss_final_n_nonparents$obs[1]` longitudinal observations (nonparent control group). The final HRS analysis samples contained `r hrs_final_n_parents$n[2]` grandparents with `r hrs_final_n_parents$obs[2]` longitudinal observations, matched with `r hrs_final_n_parents$n[1]` control respondents with either `r hrs_final_n_parents$obs[1]` (parent control group) or `r hrs_final_n_nonparents$obs[1]` longitudinal observations (nonparent control group). In the HRS, there were a few additional missing values in the outcomes ranging from `r summary(hrsanalysis_nonparents$con)[7]` to `r summary(hrsanalysis_nonparents$neur)[7]` longitudinal observations, which were listwise deleted in the respective analyses.  

[^f8]: We also excluded $N =$ 30 HRS grandparents in a previous step who reported unrealistically high numbers of grandchildren ($>$ 10) in their first assessment following the transition to grandparenthood.

[^f11]: In the LISS, `r liss_sampleflow_gp[4,2]` grandparent observations were matched with `r liss_final_n_parents$n[1]` control observations; these control observations corresponded to `r liss_replacement_controls[1, 2]` unique person-year observations stemming from `r liss_replacement_controls[1, 3]` unique respondents for the parent control group, and to `r liss_replacement_controls[2, 2]` unique person-year observations stemming from `r liss_replacement_controls[2, 3]` unique respondents for the nonparent control group. In the HRS, `r hrs_sampleflow_gp[4,2]` grandparent observations were matched with `r hrs_final_n_parents$n[1]` control observations; these control observations corresponded to `r hrs_replacement_controls[1, 2]` unique person-year observations stemming from `r hrs_replacement_controls[1, 3]` unique respondents for the parent control group, and to `r hrs_replacement_controls[2, 2]` unique person-year observations stemming from `r hrs_replacement_controls[2, 3]` unique respondents for the nonparent control group.

## Transparency and Openness

We used `r cite_r("references-r.bib", pkgs = c("lme4", "lmerTest"), withhold = FALSE)` for multilevel modeling, as well as *tidyverse* [@tidyverse2019] for data wrangling, and *papaja* [@R-papaja] for reproducible manuscript production (see supplement for complete package information). The preregistration and scripts for data wrangling, analyses, and to reproduce this manuscript[^f17] can be found on the OSF (https://osf.io/75a4r/?view_only=ac929a2c41fb4afd9d1a64a3909848d0) and GitHub (https://github.com/ [blinded]). LISS and HRS data are available after registering  

[^f17]: We also provide instructions to aid reproducing the manuscript.  

```{r coding-variables, results="asis"}
# code piecewise regression coefficients (see Table S1)
lissanalysis_parents <- lissanalysis_parents %>% mutate(
  before = ifelse(time<0, time + 6, 5), 
  after = ifelse(time<0, 0, time + 1), 
  shift = ifelse(time<0, 0, 1)
)
lissanalysis_nonparents <- lissanalysis_nonparents %>% mutate(
  before = ifelse(time<0, time + 6, 5), 
  after = ifelse(time<0, 0, time + 1), 
  shift = ifelse(time<0, 0, 1)
)
hrsanalysis_parents <- hrsanalysis_parents %>% mutate(
  before = ifelse(time>=-2, 2, ifelse(time==-6, 0, 1)), 
  after = ifelse(time<0, 0, ifelse(time==2, 2, ifelse(time==4, 3, ifelse(time==6, 4, 1)))), 
  shift = ifelse(time<0, 0, 1)
)
hrsanalysis_nonparents <- hrsanalysis_nonparents %>% mutate(
  before = ifelse(time>=-2, 2, ifelse(time==-6, 0, 1)), 
  after = ifelse(time<0, 0, ifelse(time==2, 2, ifelse(time==4, 3, ifelse(time==6, 4, 1)))), 
  shift = ifelse(time<0, 0, 1)
)
# create hid for HRS (remove last three digits)
hrsanalysis_parents$hid <- as.numeric(gsub('.{3}$', '', hrsanalysis_parents$HHIDPN))
hrsanalysis_nonparents$hid <- as.numeric(gsub('.{3}$', '', hrsanalysis_nonparents$HHIDPN))

# harmonize variable names
hrsanalysis_parents <- hrsanalysis_parents %>% mutate(female = gender - 1) %>% 
  rename(pid = HHIDPN,  matchtime = time_match)
hrsanalysis_nonparents <- hrsanalysis_nonparents %>% mutate(female = gender - 1) %>% 
  rename(pid = HHIDPN, matchtime = time_match)
lissanalysis_parents <- lissanalysis_parents %>% rename(pid = nomem_encr, hid = nohouse_encr)
lissanalysis_nonparents <- lissanalysis_nonparents %>% rename(pid = nomem_encr, hid = nohouse_encr)

# code other moderators (only HRS)
# paid work
hrsanalysis_parents <- hrsanalysis_parents %>% 
  mutate(working = ifelse(paidwork %in% c(1,5), ifelse(paidwork==1, 1, 0), NA))
hrsanalysis_nonparents <- hrsanalysis_nonparents %>% 
  mutate(working = ifelse(paidwork %in% c(1,5), ifelse(paidwork==1, 1, 0), NA))

# grandchild care

# only post-event period -> new data objects
hrsanalysis_care_parents <- hrsanalysis_parents %>% filter(time %in% c(0:6))
hrsanalysis_care_nonparents <- hrsanalysis_nonparents %>% filter(time %in% c(0:6))

# transfer grandparents' values of grandchild care (grandkids100h) to their matched controls
# careful to regard temporal changes, too
hrsanalysis_care_parents <- hrsanalysis_care_parents %>% group_by(subclass, time) %>% 
  mutate(grandkids100h = max(grandkids100h, na.rm = T)) %>% ungroup() %>% 
  mutate(grandkids100h = replace(grandkids100h, grandkids100h==-Inf, NA)) # regular NA pls
hrsanalysis_care_nonparents <- hrsanalysis_care_nonparents %>% group_by(subclass, time) %>% 
  mutate(grandkids100h = max(grandkids100h, na.rm = T)) %>% ungroup() %>% 
  mutate(grandkids100h = replace(grandkids100h, grandkids100h==-Inf, NA)) # regular NA pls

hrsanalysis_care_parents <- hrsanalysis_care_parents %>% 
  mutate(caring = ifelse(grandkids100h %in% c(1,5), ifelse(grandkids100h==1, 1, 0), NA)) %>% 
  filter(!is.na(caring))
hrsanalysis_care_nonparents <- hrsanalysis_care_nonparents %>% 
  mutate(caring = ifelse(grandkids100h %in% c(1,5), ifelse(grandkids100h==1, 1, 0), NA)) %>% 
  filter(!is.na(caring))

# race as moderator (Reviewer suggestion)

# only in the HRS (=US) sample based on 'RARACEM' variable:
# 1 = White/Caucasian
# 2 = Black/African American
# 3 = Other

# code contrasts
hrsanalysis_race_parents <- hrsanalysis_parents %>% mutate(
  black = ifelse(race %in% c(1,2), ifelse(race==2, 1, 0), NA)
) %>% filter(!is.na(black)) # only white vs. black contrast

hrsanalysis_race_nonparents <- hrsanalysis_nonparents %>% mutate(
  black = ifelse(race %in% c(1,2), ifelse(race==2, 1, 0), NA)
) %>%   filter(!is.na(black))

outcomes <- c("agree", "con", "extra", "neur", "open", "swls")

df_outcomes <- rbind(cbind(maj="Agreeableness", min="agreeableness"),
                     cbind(maj="Conscientiousness", min="conscientiousness"),
                     cbind(maj="Extraversion", min="extraversion"),
                     cbind(maj="Neuroticism", min="neuroticism"),
                     cbind(maj="Openness", min="openness"),
                     cbind(maj="Life Satisfaction", min="life satisfaction"))
rownames(df_outcomes) <- c("agree", "con", "extra", "neur", "open", "swls")
```

```{r draw-longitudinal-obs-info, include=FALSE}
# show overview of sample size over time in the final analysis samples

sample_time_draw <- function(x) { 
  x %>% 
    group_by(grandparent, time) %>% summarise(n=n(), f = mean(female)*100) %>%
    mutate(f = format(round(f, digits=2), nsmall = 2)) %>% # fix at 2 decimal places
    pivot_wider(names_from = time, values_from = -c(time, grandparent)) %>% 
    mutate_if(is.numeric, as.character) %>% # transform num to chr
    pivot_longer(cols = -grandparent, names_to = c("var", ".value"), names_pattern = "(.)_(.*)") }
  
list_sample_time <- list(lissanalysis_parents, lissanalysis_nonparents, 
                         hrsanalysis_parents, hrsanalysis_nonparents) %>%
  lapply(sample_time_draw)
names(list_sample_time) <- c("sample_time_liss_p", "sample_time_liss_np", 
                             "sample_time_hrs_p", "sample_time_hrs_np")
list2env(list_sample_time, .GlobalEnv)
rm(list_sample_time)

# we need grandparent obs only once per sample
sample_time_liss_p <- sample_time_liss_p %>% arrange(desc(grandparent))
sample_time_liss_np <- sample_time_liss_np %>% filter(grandparent==0)
sample_time_hrs_p <- sample_time_hrs_p %>% arrange(desc(grandparent))
sample_time_hrs_np <- sample_time_hrs_np %>% filter(grandparent==0)
```

(ref:piecewise-coding-scheme-cap) Longitudinal Sample Size in the Analysis Samples and Coding Scheme for the Piecewise Regression Coefficients.

(ref:piecewise-coding-scheme-note) obs. = observations. $time=0$ marks the first year where the transition to grandparenthood has been reported. The number of grandparent respondents included in the final samples is $N_{LISS}=$ 282 and $N_{HRS}=$ 847. 

```{r piecewise-coding-scheme, results="asis", warning=FALSE, message=FALSE}
sample_time_liss <- as.data.frame(rbind(sample_time_liss_p, sample_time_liss_np))
sample_time_liss <- sample_time_liss[,-c(1,2)]
sample_time_hrs <- as.data.frame(rbind(sample_time_hrs_p, sample_time_hrs_np))
sample_time_hrs <- sample_time_hrs[,-c(1,2)]
sample_time_hrs <- sample_time_hrs %>% add_column(`-5` = "", `-3` = "", `-1` = "", 
                                                  `1` = "", `3` = "", `5` = "")

# Visualize the coding scheme for the piecewise regression coefficients
coding_scheme_liss <- rbind(c("0", "1", "2", "3", "4", "5", "5", "5", "5", "5", "5", "5", "5"),
                       c("0", "0", "0", "0", "0", "0", "1", "2", "3", "4", "5", "6", "7"),
                       c("0", "0", "0", "0", "0", "0", "1", "1", "1", "1", "1", "1", "1"))
colnames(coding_scheme_liss) <- c("-6", "-5", "-4", "-3", "-2", "-1", "0", "1", "2", "3", "4", "5", "6")

coding_scheme_hrs <- rbind(c("0", "", "1", "", "2", "", "2", "", "2", "", "2", "", "2"),
                           c("0", "", "0", "", "0", "", "1", "", "2", "", "3", "", "4"),
                           c("0", "", "0", "", "0", "", "1", "", "1", "", "1", "", "1"))
colnames(coding_scheme_hrs) <- c("-6", "-5", "-4", "-3", "-2", "-1", "0", "1", "2", "3", "4", "5", "6")

# combine both
sample_time_and_coding <- rbind(sample_time_liss, coding_scheme_liss,
                                sample_time_hrs, coding_scheme_hrs)

# no duplicate rownames allowed :(
rownames(sample_time_and_coding) <- c("Grandparents: obs. \\textcolor{white}{L}",
                          "Grandparents: \\% women \\textcolor{white}{L}", 
                          "Parent controls: obs. \\textcolor{white}{L}", 
                          "Parent controls: \\% women \\textcolor{white}{L}", 
                          "Nonparent controls: obs. \\textcolor{white}{L}", 
                          "Nonparent controls: \\% women \\textcolor{white}{L}", 
                          "Before-slope \\textcolor{white}{L}", "After-slope \\textcolor{white}{L}",
                          "Shift \\textcolor{white}{L}", 
                          "Grandparents: obs. \\textcolor{white}{H}",
                          "Grandparents: \\% women \\textcolor{white}{H}", 
                          "Parent controls: obs. \\textcolor{white}{H}", 
                          "Parent controls: \\% women \\textcolor{white}{H}", 
                          "Nonparent controls: obs. \\textcolor{white}{H}", 
                          "Nonparent controls: \\% women \\textcolor{white}{H}",
                          "Before-slope \\textcolor{white}{H}", "After-slope \\textcolor{white}{H}",
                          "Shift \\textcolor{white}{H}")

apa_table(
  sample_time_and_coding
  , caption = "(ref:piecewise-coding-scheme-cap)"
  , note = "(ref:piecewise-coding-scheme-note)"
  , align = c("l", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c")
  , col.names = c("", "-6", "-5", "-4", "-3", "-2", "-1", "0", "1", "2", "3", "4", "5", "6")
  , col_spanners = list("Pre-transition years" = c(2,7), "Post-transition years" = c(8,14))
  , stub_indents = list("LISS: Analysis samples" = 1:6, "LISS: Coding scheme" = 7:9, 
                        "HRS: Analysis samples" = 10:15, "HRS: Coding scheme" = 16:18)
  , format.args = list(gt1 = c(T, T, T, T, T, T, T, T, T, T, T, T, T, T),
                       digits = c(0,0,0,0,0,0,0,0,0,0,0,0,0),
                       zero = c(T, T, T, T, T, T, T, T, T, T, T, T, T, T))
  , escape = F
  , landscape = T
  , placement = "ht"
  , font_size = "small"
)
```

\noindent
accounts. We deviate from the preregistration in using new waves of data released in the meantime (2020/2021 LISS) as well as updated datasets (HRS). Following Benjamin et al. [-@benjaminRedefineStatisticalSignificance2018], we set the $\alpha$-level for confirmatory analyses to $.005$.  

## Analytical Strategy

Our design can be referred to as an interrupted time series with a "nonequivalent no-treatment control group" [@shadishExperimentalQuasiexperimentalDesigns2002, p. 182] where treatment, that is, the transition to grandparenthood, is not deliberately manipulated. First, to analyze mean-level changes (research question 1), we used linear piecewise regression coefficients in multilevel models with person-year observations nested within respondents and households [@hoffmanLongitudinalAnalysisModeling2015]. To model change over time in relation to the transition to grandparenthood, we coded three piecewise regression coefficients: a *before-slope* representing linear change in the years leading up to the transition to grandparenthood, an *after-slope* representing linear change in the years after the transition, and a *shift* coefficient, shifting the intercept directly after the transition was first reported, thus representing sudden changes that go beyond changes already modeled by the *after-slope* (see Table \@ref(tab:piecewise-coding-scheme) for the coding scheme of these coefficients).[^f16] Other studies of personality development have recently adopted similar piecewise coefficients [e.g., @schwabaPersonalityTraitDevelopment2019; @vanscheppingenTrajectoriesLifeSatisfaction2020; @kramerImpactHavingChildren2020].  
All effects of the transition to grandparenthood on the Big Five and life satisfaction were modeled as deviations from the matched control groups by interacting the three piecewise coefficients with the treatment variable (0 = *control*, 1 = *grandparent*). In additional models, we interacted these coefficients with the moderator variables, resulting in two- and three-way interactions. To test differences in the growth parameters between two groups in cases where these differences were represented by multiple fixed-effects coefficients, we defined linear contrasts using the *linearHypothesis* command from the *car* package [@car2019]. All models of mean-level changes were estimated using maximum likelihood and included random intercepts but no random slopes. Simultaneous random slopes of change parameters frequently lead to convergence issues. Fixed slopes models are appropriate to model average trajectories, which vary systematically with the person-level treatment variable [@hoffmanCatchingMultilevelModeling2022]. We included the propensity score as a level-2 covariate for a double-robust approach [@austinDoublePropensityscoreAdjustment2017]. The equation for the basic (i.e., unmoderated) model reads: 
\begin{equation}
\begin{split}
y_{ti} =& \beta_{0i} + \beta_{1i}before_{ti} + \beta_{2i}after_{ti} + \beta_{3i}shift_{ti} + e_{ti} \\
 & \beta_{0i} = \gamma_{00} + \gamma_{01}grandparent_i + \gamma_{02}pscore_i + \upsilon_{0i} \\
 & \beta_{1i} = \gamma_{10} + \gamma_{11}grandparent_i \\
 & \beta_{2i} = \gamma_{20} + \gamma_{21}grandparent_i \\
 & \beta_{3i} = \gamma_{30} + \gamma_{31}grandparent_i\ ,
\end{split}
(\#eq:mlm)
\end{equation}
where at time $t$ for person $i$ $e_{ti} \sim N(0, \sigma_e^2)$ and $\upsilon_{0i} \sim N(0, \tau_{00})$ (ignoring the additional nesting in households applied to the majority of models). $y_{ti}$ represented one of the Big Five or life satisfaction. Separate models were computed for each analysis sample. The other model equations can be found in the supplemental materials.  
Second, to assess interindividual differences in change (research question 2), we added random slopes. In other words, we allowed for differences between individuals in their trajectories of change to be modeled, that is, differences in the *before-slope*, *after-slope*, and *shift* coefficients. Because simultaneous random slopes are often not computationally feasible, we added random slopes one at a time and used likelihood ratio tests to determine whether the addition of the respective random slope led to a significant improvement in model fit. To test differences in the random slope variance between the grandparent group and each control group, we respecified the models as heterogeneous variance models using the *nlme* R package [@R-nlme]. This allowed for separate random slope variances to be estimated in the grandparent group and the control group within the same model. We compared the fit of these heterogeneous variance models to corresponding models with a homogeneous (single) random slope variance using likelihood ratio tests.   
Third, to examine rank-order stability in the Big Five and life satisfaction over the transition to grandparenthood (research question 3), we computed the test-retest correlation of measurements prior to the transition to grandparenthood (at the time of matching) and the first available measurement afterward. To test differences in test-retest correlations between grandparents and either of the control groups, we entered the pre-treatment measure, the treatment variable (0 = *control*, 1 = *grandparent*), and their interaction into regression models predicting the Big Five and life satisfaction. The interaction tests for significant differences in the rank-order stability between those who experienced the transition to grandparenthood and those who did not [see @denissenTransactionsLifeEvents2019; @mccraeModeratedAnalysesLongitudinal1993].  

[^f16]: As a robustness check, we re-estimated the mean-level trajectories after further restricting the time frame by excluding time points earlier than two years before the transition (i.e., before the latest time of matching). This served the purpose of assessing whether including time points from before matching (as preregistered) would distort the trajectories in any way. However, results were highly similar (see *gp_restricted_models.pdf* on https://osf.io/75a4r/?view_only=ac929a2c41fb4afd9d1a64a3909848d0).  

# Results

Throughout the results section, we referred to statistical tests with $.005 < p < .05$ as *suggestive evidence* as stated in our preregistration.  

```{r descriptive-plots, include=FALSE, cache=T}
# first, construct combined datasets with all 3 groups
lissanalysis_allgroups <- bind_rows(
  lissanalysis_nonparents %>% 
    filter(grandparent==0) %>% 
    mutate(group = factor(0, labels="Nonparent Controls")) %>% 
    dplyr::select(-grandparent),
  lissanalysis_parents %>% 
    mutate(group = factor(grandparent, labels=c("Parent Controls","Grandparents"))) %>% 
    dplyr::select(-grandparent)
    )
hrsanalysis_allgroups <- bind_rows(
  hrsanalysis_nonparents %>% 
    filter(grandparent==0) %>% 
    mutate(group = factor(0, labels="Nonparent Controls")) %>% 
    dplyr::select(-grandparent),
  hrsanalysis_parents %>% 
    mutate(group = factor(grandparent, labels=c("Parent Controls","Grandparents"))) %>% 
    dplyr::select(-grandparent)
)
# for-loop did not work for some reason
# LISS
loess_plot_agree_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(agree)), 
                                aes(factor(time), agree)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["agree", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_con_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(con)), 
                                aes(factor(time), con)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["con", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_extra_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(extra)), 
                                aes(factor(time), extra)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["extra", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_neur_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(neur)), 
                                aes(factor(time), neur)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["neur", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_open_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(open)), 
                                aes(factor(time), open)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["open", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_swls_liss <- ggplot(subset(lissanalysis_allgroups, !is.na(swls)), 
                                aes(factor(time), swls)) +
  geom_violin() +
  geom_smooth(span = 0.7, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["swls", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")

# HRS
loess_plot_agree_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(agree)), 
                                aes(factor(time), agree)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["agree", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_con_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(con)), 
                                aes(factor(time), con)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["con", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_extra_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(extra)), 
                                aes(factor(time), extra)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["extra", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_neur_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(neur)), 
                                aes(factor(time), neur)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["neur", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_open_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(open)), 
                                aes(factor(time), open)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["open", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
loess_plot_swls_hrs <- ggplot(subset(hrsanalysis_allgroups, !is.na(swls)), 
                                aes(factor(time), swls)) +
  geom_violin() +
  geom_smooth(span = 0.9, aes(group=1), method="loess") +
  facet_wrap(~group) + 
  ylab(df_outcomes["swls", "maj"]) +
  scale_x_discrete(name = "Time (in Years)") +
  theme(strip.text = element_text(size = 12)) +
  stat_summary(fun=mean, geom="point", shape=23, size=1.5, color="blue")
```

```{r H1-run-models, include=FALSE, cache=T}
# This chunk runs all the models related to H1.
# Results tables are created in following chunks.

# run ICC models first (final 'icc_list' is also used in appendix for Table)

# ICCs = proportion of the total variation explained by the respective blocking factor
# https://stats.stackexchange.com/questions/18088/intraclass-correlation-icc-for-an-interaction
datasets <- c("lissanalysis_parents", "lissanalysis_nonparents", 
              "hrsanalysis_parents", "hrsanalysis_nonparents")
icc_list <- as.data.frame(rbind(icc_liss_parents_pid = rep(NA, 6), icc_liss_parents_hid = rep(NA, 6), 
                                icc_liss_parents_pidhid = rep(NA, 6), 
                                icc_liss_nonparents_pid = rep(NA, 6),
                                icc_liss_nonparents_hid = rep(NA, 6), 
                                icc_liss_nonparents_pidhid = rep(NA, 6), 
                                icc_hrs_parents_pid = rep(NA, 6), 
                                icc_hrs_parents_hid = rep(NA, 6), icc_hrs_parents_pidhid = rep(NA, 6), 
                                icc_hrs_nonparents_pid = rep(NA, 6), 
                                icc_hrs_nonparents_hid = rep(NA, 6),
                                icc_hrs_nonparents_pidhid = rep(NA, 6)))
colnames(icc_list) <- outcomes

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  for (j in 1:length(datasets)){
    dataset = datasets[j]
    pos = seq(from = 1, to = 10, by = 3)[j]
    model <- lme4::lmer(get(outcome) ~ 1 + (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
    var <- as.data.frame(summary(model)$varcor)
    icc_pid <- var[1,4] / (var[1,4] + var[2,4] + var[3,4])
    icc_hid <- var[2,4] / (var[1,4] + var[2,4] + var[3,4])
    icc_pidhid <- (var[1,4] + var[2,4]) / (var[1,4] + var[2,4] + var[3,4])
    icc_list[pos, i] <- icc_pid # rows = datasets, columns = outcomes
    icc_list[pos + 1, i] <- icc_hid
    icc_list[pos + 2, i] <- icc_pidhid
  }
}
# singular fir for two models where the icc_hid is estimated too close to zero
# For these models, the icc_pid is the same compared to the model with only 
# the (1 | pid) random effect (which fits without trouble)
# Plus, a few additional models with icc_hid below 0.05 (close to zero)

# H1: models for mean-level changes

#### basic models & moderation by gender ####
hid_icc_tbl <- c("icc_liss_parents_hid", "icc_liss_nonparents_hid",
                 "icc_hrs_parents_hid", "icc_hrs_nonparents_hid") # see table 'icc_list'
mod_summaries <- list() # create empty list objects that later contain the models
mod_summaries_test <- list()
mod_summaries_gender <- list()
mod_summaries_gender_test <- list()

# run models in a loop (save in list object)
for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 24, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = datasets[j]
    ### basic models
    if (icc_list[hid_icc_tbl[j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                              grandparent:before + grandparent:after + grandparent:shift + 
                              (1 | pid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                                  grandparent:before + grandparent:after + grandparent:shift + 
                                  (1 | pid), REML = FALSE, data = get(dataset))
    } else { # cross-nesting in pid & hid for all other models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                              grandparent:before + grandparent:after + grandparent:shift + 
                              (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                                  grandparent:before + grandparent:after + grandparent:shift + 
                                  (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
    }      
    mod_summaries[[pos + j]] <- model_1
    names(mod_summaries)[[pos + j]] <- paste0(outcome, "_", dataset)
    mod_summaries_test[[pos + j]] <- model_2
    names(mod_summaries_test)[[pos + j]] <- paste0(outcome, "_", dataset)
    ### moderation by gender models
    if (icc_list[hid_icc_tbl[j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
      model_3 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                              grandparent:before + grandparent:after + grandparent:shift)*female + 
                              (1 | pid), REML = FALSE, data = get(dataset))
      model_4 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                  grandparent:before + grandparent:after + grandparent:shift)*female + 
                                  (1 | pid), REML = FALSE, data = get(dataset))
    } else { # cross-nesting in pid & hid for all other models
      model_3 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                              grandparent:before + grandparent:after + grandparent:shift)*female + 
                              (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      model_4 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                  grandparent:before + grandparent:after + grandparent:shift)*female + 
                                  (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
    }      
    mod_summaries_gender[[pos + j]] <- model_3
    names(mod_summaries_gender)[[pos + j]] <- paste0(outcome, "_", dataset)
    mod_summaries_gender_test[[pos + j]] <- model_4
    names(mod_summaries_gender_test)[[pos + j]] <- paste0(outcome, "_", dataset)
  }
}

datasets_short <- c("liss_parents", "liss_nonparents", "hrs_parents", "hrs_nonparents")
# coefs: the way they are named in the 'papaja' objects
coefs <- c("Intercept", "pscore", "before", "after", "shift", "grandparent", 
           "before_grandparent", "after_grandparent", "shift_grandparent") 
gammas <- c("gamma}_{00", "gamma}_{02", "gamma}_{10", "gamma}_{20", "gamma}_{30", "gamma}_{01", 
            "gamma}_{11", "gamma}_{21", "gamma}_{31")
coefs_gender <- c("Intercept", "pscore", "before", "after", "shift", "grandparent", 
                  "female", "before_grandparent", "after_grandparent", "shift_grandparent",
                  "before_female", "after_female", "shift_female", "grandparent_female", 
                  "before_grandparent_female", "after_grandparent_female", "shift_grandparent_female")
gammas_gender <- c("gamma}_{00", "gamma}_{04", "gamma}_{10", "gamma}_{20", "gamma}_{30", "gamma}_{01", 
                   "gamma}_{02", "gamma}_{11", "gamma}_{21", "gamma}_{31",
                   "gamma}_{12", "gamma}_{22", "gamma}_{32", "gamma}_{03", 
                   "gamma}_{13", "gamma}_{23", "gamma}_{33")

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 24, by = 4)[i]
  for (j in 1:length(datasets_short)){
    ### basic models
    dataset = datasets_short[j]
    obj = apa_print(mod_summaries[[pos + j]]) # unfold list objects (lme4)
    obj_test = mod_summaries_test[[pos + j]] # unfold list objects (lmerTest)
    # reformatting: change beta^hat to gamma^hat (plus subscripts)
    for (k in 1:length(coefs)){ 
      coef <- coefs[k] # 9 coefficients for each model (object)
      gamma <- gammas[k]
      obj$estimate[coef] <- lapply(obj$estimate[coef], gsub, pattern="beta", replacement=gamma)
      obj$full_result[coef] <- lapply(obj$full_result[coef], gsub, pattern="beta", replacement=gamma)
    }
    obj_name <- paste0(outcome, "_", dataset, "_summary")
    eval(call("<-", as.name(obj_name), obj)) # save lme4 model
    obj_name_test <- paste0(outcome, "_", dataset, "_test")
    eval(call("<-", as.name(obj_name_test), obj_test)) # save lmerTest model
    # for better formatting in text: p-values
    obj_p <- as.data.frame(summary(mod_summaries_test[[pos + j]])$coefficients) %>% # unfold list
      rownames_to_column() %>% dplyr::select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
      mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
    obj_p["p"] <- # remove "0" from the chr's 
      lapply(obj_p["p"], gsub, pattern="0\\.", replacement="\\.")
    obj_name_p <- paste0(outcome, "_", dataset, "_p")
    eval(call("<-", as.name(obj_name_p), obj_p)) # save objects
    ### moderation by gender models
    obj_gender = apa_print(mod_summaries_gender[[pos + j]]) # unfold list objects
    obj_gender_test = mod_summaries_gender_test[[pos + j]] # unfold list objects (lmerTest)
    # reformatting: change beta^hat to gamma^hat (plus subscripts)
    for (k in 1:length(coefs_gender)){ 
      coef <- coefs_gender[k] # 17 coefficients for each model (object)
      gamma <- gammas_gender[k]
      obj_gender$estimate[coef] <- lapply(obj_gender$estimate[coef], gsub, 
                                          pattern="beta", replacement=gamma)
      obj_gender$full_result[coef] <- lapply(obj_gender$full_result[coef], gsub, 
                                             pattern="beta", replacement=gamma)
    }
    obj_gender_name <- paste0(outcome, "_", dataset, "_gender_summary")
    eval(call("<-", as.name(obj_gender_name), obj_gender)) # save object
    obj_gender_test_name <- paste0(outcome, "_", dataset, "_gender_test")
    eval(call("<-", as.name(obj_gender_test_name), obj_gender_test)) # save object
    # for better formatting in text: p-values
    obj_gender_p <- as.data.frame(summary(mod_summaries_gender_test[[pos + j]])$coefficients) %>% # unfold
      rownames_to_column() %>% dplyr::select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
      mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
    obj_gender_p["p"] <- # remove "0" from the chr's 
      lapply(obj_gender_p["p"], gsub, pattern="0\\.", replacement="\\.")
    obj_gender_name_p <- paste0(outcome, "_", dataset, "_gender_p")
    eval(call("<-", as.name(obj_gender_name_p), obj_gender_p)) # save objects  
    }
}

  #### moderation by paid work ####
  
  mod_summaries_work <- list()
  mod_summaries_work_test <- list()
  
  for (i in 1:length(outcomes)){
    outcome = outcomes[i]
    pos = seq(from = -2, to = 8, by = 2)[i] # changed this because we now only have the 2 HRS datasets
    for (j in 3:4){
      dataset = datasets[j]
      ### moderator: paid work (only HRS)
      if (icc_list[hid_icc_tbl[j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
        model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                               grandparent:before + grandparent:after + grandparent:shift)*working + 
                                (1 | pid), REML = FALSE, data = get(dataset))
        model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                    grandparent:before + grandparent:after + grandparent:shift)*working + 
                                    (1 | pid), REML = FALSE, data = get(dataset))
      } else { # cross-nesting in pid & hid for all other models
        model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                grandparent:before + grandparent:after + grandparent:shift)*working + 
                                (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
        model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                   grandparent:before + grandparent:after + grandparent:shift)*working + 
                                    (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      }      
      mod_summaries_work[[pos + j]] <- model_1
      names(mod_summaries_work)[[pos + j]] <- paste0(outcome, "_", dataset)
      mod_summaries_work_test[[pos + j]] <- model_2
      names(mod_summaries_work_test)[[pos + j]] <- paste0(outcome, "_", dataset)
    }
  }
  
  coefs_work <- c("Intercept", "pscore", "before", "after", "shift", "grandparent", 
                    "working", "before_grandparent", "after_grandparent", "shift_grandparent",
                    "before_working", "after_working", "shift_working", "grandparent_working", 
                    "before_grandparent_working", "after_grandparent_working", "shift_grandparent_working")
  gammas_work <- c("gamma}_{00", "gamma}_{02", "gamma}_{20", "gamma}_{40", "gamma}_{60", "gamma}_{01", 
                     "gamma}_{10", "gamma}_{21", "gamma}_{41", "gamma}_{61",
                     "gamma}_{30", "gamma}_{50", "gamma}_{70", "gamma}_{11", 
                     "gamma}_{31", "gamma}_{51", "gamma}_{71")
  
  for (i in 1:length(outcomes)){
    outcome = outcomes[i]
    pos = seq(from = -2, to = 8, by = 2)[i] # changed this because we now only have the 2 HRS datasets
    for (j in 3:4){
      dataset = datasets_short[j]
      ### moderation by paid work models
      obj_work = apa_print(mod_summaries_work[[pos + j]]) # unfold list objects
      obj_work_test = mod_summaries_work_test[[pos + j]] # unfold list objects (lmerTest)
      # reformatting: change beta^hat to gamma^hat (plus subscripts)
      for (k in 1:length(coefs_work)){ 
        coef <- coefs_work[k] # 17 coefficients for each model (object)
        gamma <- gammas_work[k]
        obj_work$estimate[coef] <- lapply(obj_work$estimate[coef], gsub, 
                                            pattern="beta", replacement=gamma)
        obj_work$full_result[coef] <- lapply(obj_work$full_result[coef], gsub, 
                                               pattern="beta", replacement=gamma)
      }
      obj_work_name <- paste0(outcome, "_", dataset, "_work_summary")
      eval(call("<-", as.name(obj_work_name), obj_work)) # save object
      obj_work_test_name <- paste0(outcome, "_", dataset, "_work_test")
      eval(call("<-", as.name(obj_work_test_name), obj_work_test)) # save object
      # for better formatting in text: p-values
      obj_work_p <- as.data.frame(summary(mod_summaries_work_test[[pos + j]])$coefficients) %>% # unfold
        rownames_to_column() %>% dplyr::select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
        mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
      obj_work_p["p"] <- # remove "0" from the chr's 
        lapply(obj_work_p["p"], gsub, pattern="0\\.", replacement="\\.")
      obj_work_name_p <- paste0(outcome, "_", dataset, "_work_p")
      eval(call("<-", as.name(obj_work_name_p), obj_work_p)) # save objects  
      }
  }

#### moderation by grandchild care ####

mod_summaries_care <- list()
mod_summaries_care_test <- list()

datasets_care <- c("hrsanalysis_care_parents", "hrsanalysis_care_nonparents")
  
for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 10, by = 2)[i] 
  for (j in 1:length(datasets_care)){
    dataset = datasets_care[j]
    ### moderator: grandchild care (only HRS)
    if (icc_list[hid_icc_tbl[2 + j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + (after + grandparent + 
                                                           grandparent:after)*caring + 
                              (1 | pid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (after + grandparent + 
                                                               grandparent:after)*caring + 
                                  (1 | pid), REML = FALSE, data = get(dataset))
    } else { # cross-nesting in pid & hid for all other models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + (after + grandparent + 
                                                           grandparent:after)*caring + 
                              (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (after + grandparent + 
                                                               grandparent:after)*caring + 
                                  (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
    }      
    mod_summaries_care[[pos + j]] <- model_1
    names(mod_summaries_care)[[pos + j]] <- paste0(outcome, "_", dataset)
    mod_summaries_care_test[[pos + j]] <- model_2
    names(mod_summaries_care_test)[[pos + j]] <- paste0(outcome, "_", dataset)
  }
}

coefs_care <- c("Intercept", "pscore", "after", "grandparent", 
                "caring", "after_grandparent", 
                "after_caring", "grandparent_caring", 
                "after_grandparent_caring")
gammas_care <- c("gamma}_{00", "gamma}_{02", "gamma}_{20", "gamma}_{01", 
                 "gamma}_{10", "gamma}_{21",
                 "gamma}_{30", "gamma}_{11", 
                 "gamma}_{31")

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = -2, to = 8, by = 2)[i] # changed this because we now only have the 2 HRS datasets
  for (j in 3:4){
    dataset = datasets_short[j]
    ### moderation by grandchild care
    obj_care = apa_print(mod_summaries_care[[pos + j]]) # unfold list objects
    obj_care_test = mod_summaries_care_test[[pos + j]] # unfold list objects (lmerTest)
    # reformatting: change beta^hat to gamma^hat (plus subscripts)
    for (k in 1:length(coefs_care)){ 
      coef <- coefs_care[k] # 17 coefficients for each model (object)
      gamma <- gammas_care[k]
      obj_care$estimate[coef] <- lapply(obj_care$estimate[coef], gsub, pattern="beta", replacement=gamma)
      obj_care$full_result[coef] <- lapply(obj_care$full_result[coef], gsub, 
                                           pattern="beta", replacement=gamma)
    }
    obj_care_name <- paste0(outcome, "_", dataset, "_care_summary")
    eval(call("<-", as.name(obj_care_name), obj_care)) # save object
    obj_care_test_name <- paste0(outcome, "_", dataset, "_care_test")
    eval(call("<-", as.name(obj_care_test_name), obj_care_test)) # save object
    # for better formatting in text: p-values
    obj_care_p <- as.data.frame(summary(mod_summaries_care_test[[pos + j]])$coefficients) %>% 
      rownames_to_column() %>% dplyr::select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
      mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
    obj_care_p["p"] <- # remove "0" from the chr's 
      lapply(obj_care_p["p"], gsub, pattern="0\\.", replacement="\\.")
    obj_care_name_p <- paste0(outcome, "_", dataset, "_care_p")
    eval(call("<-", as.name(obj_care_name_p), obj_care_p)) # save objects  
  }
}

#### models restricted to time [-2, 6] ####
lissanalysis_parents_restr <- lissanalysis_parents %>% filter(time %in% c(-2:6)) %>% 
  mutate(
    before = before - 4 # filtering changes meaning of before-slope (others stay the same)
  )
lissanalysis_nonparents_restr <- lissanalysis_nonparents %>% filter(time %in% c(-2:6)) %>% 
  mutate(
    before = before - 4 # filtering changes meaning of before-slope (others stay the same)
  )
hrsanalysis_parents_restr <- hrsanalysis_parents %>% filter(time %in% c(-2:6))
hrsanalysis_nonparents_restr <- hrsanalysis_nonparents %>% filter(time %in% c(-2:6))
  
datasets_restr <- c("lissanalysis_parents_restr", "lissanalysis_nonparents_restr", 
                    "hrsanalysis_parents_restr", "hrsanalysis_nonparents_restr")
mod_summaries_restr <- list()
mod_summaries_restr_test <- list()
mod_summaries_restr_gender <- list()
mod_summaries_restr_gender_test <- list()

# run models (save in list object)
for (i in 1:length(outcomes)){
    outcome = outcomes[i]
  pos = seq(from = 0, to = 24, by = 4)[i]
  for (j in 1:length(datasets_restr)){
    dataset = datasets_restr[j]
    # basic models (different specifications for LISS & HRS this time ...)
    if (dataset %in% datasets_restr[grep("^(?=.*liss)", datasets_restr, perl=T)]){ # filter LISS
      if ((icc_list[hid_icc_tbl[j], outcome] < 0.05) || #nesting in hid leads to singular fit for some models
          (outcome=="extra" & dataset=="lissanalysis_nonparents_restr")){ # needs to be added for the restricted models
        model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                                grandparent:before + grandparent:after + grandparent:shift + 
                                (1 | pid), REML = FALSE, data = get(dataset))
        model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                                    grandparent:before + grandparent:after + grandparent:shift + 
                                    (1 | pid), REML = FALSE, data = get(dataset))
      } else { # cross-nesting in pid & hid for all other models
        model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                                grandparent:before + grandparent:after + grandparent:shift + 
                                (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
        model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + before + after + shift + grandparent + 
                                    grandparent:before + grandparent:after + grandparent:shift + 
                                    (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      }
    } else { # HRS models now without before-slope 
      if (icc_list[hid_icc_tbl[j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
        model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + after + shift + grandparent + 
                                grandparent:after + grandparent:shift + 
                                (1 | pid), REML = FALSE, data = get(dataset))
        model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + after + shift + grandparent + 
                                    grandparent:after + grandparent:shift + 
                                    (1 | pid), REML = FALSE, data = get(dataset))
      } else { # cross-nesting in pid & hid for all other models
        model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + after + shift + grandparent + 
                                grandparent:after + grandparent:shift + 
                                (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
        model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + after + shift + grandparent + 
                                    grandparent:after + grandparent:shift + 
                                    (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      }
    }
    mod_summaries_restr[[pos + j]] <- model_1
    names(mod_summaries_restr)[[pos + j]] <- paste0(outcome, "_", dataset)
    mod_summaries_restr_test[[pos + j]] <- model_2
    names(mod_summaries_restr_test)[[pos + j]] <- paste0(outcome, "_", dataset)
    # moderation by gender models
    if (dataset %in% datasets_restr[grep("^(?=.*liss)", datasets_restr, perl=T)]){ # filter LISS
      if ((icc_list[hid_icc_tbl[j], outcome] < 0.05) || #nesting in hid leads to singular fit for some models
          (outcome=="extra" & dataset=="lissanalysis_nonparents_restr")){ # needs to be added for the restricted models
        model_3 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                grandparent:before + grandparent:after + grandparent:shift)*female + 
                                (1 | pid), REML = FALSE, data = get(dataset))
        model_4 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                    grandparent:before + grandparent:after + grandparent:shift)*female + 
                                    (1 | pid), REML = FALSE, data = get(dataset))
      } else { # cross-nesting in pid & hid for all other models
        model_3 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                grandparent:before + grandparent:after + grandparent:shift)*female + 
                                (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
        model_4 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                    grandparent:before + grandparent:after + grandparent:shift)*female + 
                                    (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      }
    } else { # HRS models now without before-slope 
      if (icc_list[hid_icc_tbl[j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
        model_3 <- lme4::lmer(get(outcome) ~ 1 + pscore + (after + shift + grandparent + 
                                grandparent:after + grandparent:shift)*female + 
                                (1 | pid), REML = FALSE, data = get(dataset))
        model_4 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (after + shift + grandparent + 
                                    grandparent:after + grandparent:shift)*female + 
                                    (1 | pid), REML = FALSE, data = get(dataset))
      } else { # cross-nesting in pid & hid for all other models
        model_3 <- lme4::lmer(get(outcome) ~ 1 + pscore + (after + shift + grandparent + 
                                grandparent:after + grandparent:shift)*female + 
                                (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
        model_4 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (after + shift + grandparent + 
                                    grandparent:after + grandparent:shift)*female + 
                                    (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      }
    }
    mod_summaries_restr_gender[[pos + j]] <- model_3
    names(mod_summaries_restr_gender)[[pos + j]] <- paste0(outcome, "_", dataset)
    mod_summaries_restr_gender_test[[pos + j]] <- model_4
    names(mod_summaries_restr_gender_test)[[pos + j]] <- paste0(outcome, "_", dataset)
  }
}

coefs_restr_hrs <- c("Intercept", "pscore", "after", "shift", 
                      "grandparent", "after_grandparent", "shift_grandparent") # without 'before'
gammas_restr_hrs<- c("gamma}_{00", "gamma}_{02", "gamma}_{20", 
                       "gamma}_{30", "gamma}_{01", "gamma}_{21", "gamma}_{31")

# gammas the same as before for LISS

coefs_gender_restr_hrs <- c("Intercept", "pscore", "after", "shift", "grandparent", # without 'before'
                       "female", "after_grandparent", "shift_grandparent",
                       "after_female", "shift_female", "grandparent_female", 
                       "after_grandparent_female", "shift_grandparent_female")
gammas_gender_restr_hrs <- c("gamma}_{00", "gamma}_{04", "gamma}_{20", "gamma}_{30", "gamma}_{01", 
                   "gamma}_{02", "gamma}_{21", "gamma}_{31",
                   "gamma}_{22", "gamma}_{32", "gamma}_{03", 
                   "gamma}_{23", "gamma}_{33")

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 24, by = 4)[i]
  for (j in 1:length(datasets_short)){
    ### basic models (need to differntiate between LISS & HRS models now)
    dataset = datasets_short[j]
    obj = apa_print(mod_summaries_restr[[pos + j]]) # unfold list objects (lme4)
    obj_test = mod_summaries_restr_test[[pos + j]] # unfold list objects (lmerTest)
    # reformatting: change beta^hat to gamma^hat (plus subscripts)
    if (dataset %in% datasets_short[grep("^(?=.*liss)", datasets_short, perl=T)]){ # filter LISS
      for (k in 1:length(coefs)){ 
        coef <- coefs[k] # 9 coefficients for each model (object)
        gamma <- gammas[k]
        obj$estimate[coef] <- lapply(obj$estimate[coef], gsub, pattern="beta", replacement=gamma)
        obj$full_result[coef] <- lapply(obj$full_result[coef], gsub, pattern="beta", replacement=gamma)
      }
    }
    else { # HRS
      for (k in 1:length(coefs_restr_hrs)){ 
        coef <- coefs_restr_hrs[k] # 7 coefficients for each model (object)
        gamma <- gammas_restr_hrs[k]
        obj$estimate[coef] <- lapply(obj$estimate[coef], gsub, pattern="beta", replacement=gamma)
        obj$full_result[coef] <- lapply(obj$full_result[coef], gsub, pattern="beta", replacement=gamma)
      }
    }
    obj_name <- paste0(outcome, "_", dataset, "_restr_summary")
    eval(call("<-", as.name(obj_name), obj)) # save lme4 model
    obj_name_test <- paste0(outcome, "_", dataset, "_restr_test")
    eval(call("<-", as.name(obj_name_test), obj_test)) # save lmerTest model
    # for better formatting in text: p-values
    obj_p <- as.data.frame(summary(mod_summaries_restr_test[[pos + j]])$coefficients) %>% # unfold list
      rownames_to_column() %>% dplyr::select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
      mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
    obj_p["p"] <- # remove "0" from the chr's 
      lapply(obj_p["p"], gsub, pattern="0\\.", replacement="\\.")
    obj_name_p <- paste0(outcome, "_", dataset, "_restr_p")
    eval(call("<-", as.name(obj_name_p), obj_p)) # save objects
    ### moderation by gender models
    obj_gender = apa_print(mod_summaries_restr_gender[[pos + j]]) # unfold list objects
    obj_gender_test = mod_summaries_restr_gender_test[[pos + j]] # unfold list objects (lmerTest)
    # reformatting: change beta^hat to gamma^hat (plus subscripts)
    if (dataset %in% datasets_short[grep("^(?=.*liss)", datasets_short, perl=T)]){ # filter LISS
      for (k in 1:length(coefs_gender)){ 
        coef <- coefs_gender[k] # 17 coefficients for each model (object)
        gamma <- gammas_gender[k]
        obj_gender$estimate[coef] <- lapply(obj_gender$estimate[coef], gsub, 
                                            pattern="beta", replacement=gamma)
        obj_gender$full_result[coef] <- lapply(obj_gender$full_result[coef], gsub, 
                                               pattern="beta", replacement=gamma)
      }
    }
    else { # HRS
      for (k in 1:length(coefs_gender_restr_hrs)){ 
        coef <- coefs_gender_restr_hrs[k] # 13 coefficients for each model (object)
        gamma <- gammas_gender_restr_hrs[k]
        obj_gender$estimate[coef] <- lapply(obj_gender$estimate[coef], gsub, 
                                            pattern="beta", replacement=gamma)
        obj_gender$full_result[coef] <- lapply(obj_gender$full_result[coef], gsub, 
                                               pattern="beta", replacement=gamma)
      }
    }
    obj_gender_name <- paste0(outcome, "_", dataset, "_restr_gender_summary")
    eval(call("<-", as.name(obj_gender_name), obj_gender)) # save object
    obj_gender_test_name <- paste0(outcome, "_", dataset, "_restr_gender_test")
    eval(call("<-", as.name(obj_gender_test_name), obj_gender_test)) # save object
    # for better formatting in text: p-values
    obj_gender_p <- 
      as.data.frame(summary(mod_summaries_restr_gender_test[[pos + j]])$coefficients) %>% # unfold
      rownames_to_column() %>% dplyr::select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
      mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
    obj_gender_p["p"] <- # remove "0" from the chr's 
      lapply(obj_gender_p["p"], gsub, pattern="0\\.", replacement="\\.")
    obj_gender_name_p <- paste0(outcome, "_", dataset, "_restr_gender_p")
    eval(call("<-", as.name(obj_gender_name_p), obj_gender_p)) # save objects  
  }
}

#### moderation by race (Reviewer suggestion) ####

mod_summaries_race <- list()
mod_summaries_race_test <- list()

datasets_race <- c("hrsanalysis_race_parents", "hrsanalysis_race_nonparents")

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 10, by = 2)[i] 
  for (j in 1:length(datasets_race)){
    dataset = datasets_race[j]
    ### moderator: Black/African American (only HRS)
    if (icc_list[hid_icc_tbl[2 + j], outcome] < 0.05){ # nesting in hid leads to singular fit for some models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                             grandparent:before + grandparent:after + grandparent:shift)*black + 
                              (1 | pid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                  grandparent:before + grandparent:after + grandparent:shift)*black + 
                                  (1 | pid), REML = FALSE, data = get(dataset))
    } else { # cross-nesting in pid & hid for all other models
      model_1 <- lme4::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                              grandparent:before + grandparent:after + grandparent:shift)*black + 
                              (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
      model_2 <- lmerTest::lmer(get(outcome) ~ 1 + pscore + (before + after + shift + grandparent + 
                                 grandparent:before + grandparent:after + grandparent:shift)*black + 
                                  (1 | pid) + (1 | hid), REML = FALSE, data = get(dataset))
    }      
    mod_summaries_race[[pos + j]] <- model_1
    names(mod_summaries_race)[[pos + j]] <- paste0(outcome, "_", dataset)
    mod_summaries_race_test[[pos + j]] <- model_2
    names(mod_summaries_race_test)[[pos + j]] <- paste0(outcome, "_", dataset)
  }
}

coefs_race <- c("Intercept", "pscore", "before", "after", "shift", "grandparent", 
                  "black", "before_grandparent", "after_grandparent", "shift_grandparent",
                  "before_black", "after_black", "shift_black", "grandparent_black", 
                  "before_grandparent_black", "after_grandparent_black", "shift_grandparent_black")
gammas_race <- c("gamma}_{00", "gamma}_{02", "gamma}_{20", "gamma}_{40", "gamma}_{60", "gamma}_{01", 
                   "gamma}_{10", "gamma}_{21", "gamma}_{41", "gamma}_{61",
                   "gamma}_{30", "gamma}_{50", "gamma}_{70", "gamma}_{11", 
                   "gamma}_{31", "gamma}_{51", "gamma}_{71")

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = -2, to = 8, by = 2)[i] # changed this because we now only have the 2 HRS datasets
  for (j in 3:4){
    dataset = datasets_short[j]
    ### moderation by paid race models
    obj_race = apa_print(mod_summaries_race[[pos + j]]) # unfold list objects
    obj_race_test = mod_summaries_race_test[[pos + j]] # unfold list objects (lmerTest)
    # reformatting: change beta^hat to gamma^hat (plus subscripts)
    for (k in 1:length(coefs_race)){ 
      coef <- coefs_race[k] # 17 coefficients for each model (object)
      gamma <- gammas_race[k]
      obj_race$estimate[coef] <- lapply(obj_race$estimate[coef], gsub, 
                                          pattern="beta", replacement=gamma)
      obj_race$full_result[coef] <- lapply(obj_race$full_result[coef], gsub, 
                                             pattern="beta", replacement=gamma)
    }
    obj_race_name <- paste0(outcome, "_", dataset, "_race_summary")
    eval(call("<-", as.name(obj_race_name), obj_race)) # save object
    obj_race_test_name <- paste0(outcome, "_", dataset, "_race_test")
    eval(call("<-", as.name(obj_race_test_name), obj_race_test)) # save object
    # for better formatting in text: p-values
    obj_race_p <- as.data.frame(summary(mod_summaries_race_test[[pos + j]])$coefficients) %>% # unfold
      rownames_to_column() %>% dplyr::select(rowname, "Pr(>|t|)") %>% rename(p = "Pr(>|t|)") %>% 
      mutate(p = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > "))) %>% column_to_rownames()
    obj_race_p["p"] <- # remove "0" from the chr's 
      lapply(obj_race_p["p"], gsub, pattern="0\\.", replacement="\\.")
    obj_race_name_p <- paste0(outcome, "_", dataset, "_race_p")
    eval(call("<-", as.name(obj_race_name_p), obj_race_p)) # save objects  
    }
}
```

```{r H1-linear-contrasts, include=FALSE, cache=T}

#### basic models ####

# test linear contrasts in cases where estimates of interest are represented by multiple FE coefs
to_be_tested <- c("shift_control", # shift of controls vs. 0
                  "shift_gp", # shift of GPs vs. 0
                  "shift_gp_vs_control", # shift of GPs vs. controls
                  "before_gp", # before-slope of GPs vs. 0
                  "after_gp") # after-slope of GPs vs. 0
contrasts <- list(c("shift", "after"),
                 c("shift", "after", "shift:grandparent", "after:grandparent"),
                 c("shift:grandparent", "after:grandparent"), 
                 c("before", "before:grandparent"),
                 c("after", "after:grandparent"))

gamma_comb_basic <- c("[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$]", 
                  "[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]",
                  "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]", 
                  "[$\\hat{\\gamma}_{10}$ + $\\hat{\\gamma}_{11}$]",
                  "[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{21}$]")

for (i in 1:length(outcomes)){
  for (j in 1:length(datasets_short)){
    ### basic models
    model <- get(paste0(outcomes[i], "_", datasets_short[j], "_test"))
    for (k in 1:length(to_be_tested)){
      contrast <- as.data.frame(
        cbind(est = sum(fixef(model)[contrasts[[k]]]), # estimate is the sum of all involved FE coefs
              chi = linearHypothesis(model, paste(contrasts[[k]], collapse = " + "))[2, "Chisq"], 
              df = linearHypothesis(model, paste(contrasts[[k]], collapse = " + "))[2, "Df"], 
              p = linearHypothesis(model, paste(contrasts[[k]], collapse = " + "))[2, "Pr(>Chisq)"])
        )
      conf_itvl <- confint(summary(multcomp::glht(model, # confidence intervals
                           linfct = paste(paste(contrasts[[k]], collapse = " + "), "= 0"))))
      contrast <- cbind(contrast, 
                        lwr = conf_itvl$confint[, "lwr"], 
                        upr = conf_itvl$confint[, "upr"])
      contrast <- contrast %>% mutate( # reformat for reporting in text
        est_num = paste(gamma_comb_basic[k], "=", printnum(est)),
        chi_print = paste0("$\\chi^2$", " (", contrast$df, ") = ", printnum(contrast$chi)),
        p_print = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
        conf = paste0("95% CI [", printnum(contrast$lwr), ", ", printnum(contrast$upr), "]")
      )
      contrast["p_print"] <- # remove "0" from the p-value chr
        lapply(contrast["p_print"], gsub, pattern="0\\.", replacement="\\.")
      contrast <- contrast %>% 
        unite(all, c(est_num, conf, p_print), sep = ", ", remove = F) # combined string
      contrast_name <- paste0(to_be_tested[k], "_", outcomes[i], "_", datasets_short[j])
      eval(call("<-", as.name(contrast_name), contrast))
    }
    collect_contrasts <- do.call(rbind, lapply(paste0(to_be_tested, "_", 
                              outcomes[i], "_", datasets_short[j]), get)) # all k's
    rownames(collect_contrasts) <- to_be_tested
    collected_name <- paste0("contrasts_", outcomes[i], "_", datasets_short[j])
    eval(call("<-", as.name(collected_name), collect_contrasts))
  }
  listed_contrasts <- do.call(list, lapply(paste0("contrasts_", 
                           outcomes[i], "_", datasets_short), get)) # all j's
  names(listed_contrasts) <- datasets_short
  listed_name <- paste0("contrasts_", outcomes[i])
  eval(call("<-", as.name(listed_name), listed_contrasts))
}

#### moderation by gender ####

to_be_tested_gender <- c("shift_control_male", # shift of male controls vs. 0
                         "shift_control_female", # shift of female controls vs. 0
                         "shift_gp_male", # shift of male GPs vs. 0
                         "shift_gp_female", # shift of female GPs vs. 0
                         "shift_gp_vs_control_men", # shift of m. GPs vs. m. controls
                         "before_gp_vs_control_women", # before-slope of f. GPs vs. f. controls
                         "after_gp_vs_control_women", # after-slope of f. GPs vs. f. controls
                         "shift_gp_vs_control_women", # shift of f. GPs vs. f. controls
                         "shift_male_vs_female_control", # shift of m. vs. f. controls
                         "before_male_vs_female_gp", # before-slope of m. vs. f. GPs
                         "after_male_vs_female_gp", # after-slope of m. vs. f. GPs
                         "shift_male_vs_female_gp") # shift of m. vs. f. GPs
contrasts_gender <- list(c("shift", "after"),
                         c("shift", "after", "shift:female", "after:female"),
                         c("shift", "after", "shift:grandparent", "after:grandparent"),
                         c("shift", "after", "shift:female", "after:female", "shift:grandparent", 
                           "after:grandparent", "shift:grandparent:female", "after:grandparent:female"),
                         c("shift:grandparent", "after:grandparent"), 
                         c("before:grandparent", "before:grandparent:female"), 
                         c("after:grandparent", "after:grandparent:female"), 
                         c("shift:grandparent", "after:grandparent", 
                           "shift:grandparent:female", "after:grandparent:female"), 
                         c("shift:female", "after:female"),
                         c("before:female", "before:grandparent:female"),
                         c("after:female", "after:grandparent:female"),
                         c("shift:female", "after:female", 
                           "shift:grandparent:female", "after:grandparent:female"))

gamma_comb_gender <- c("[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$]",
                   "[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{22}$ + $\\hat{\\gamma}_{32}$]",
                   "[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]", 
                   "[$\\hat{\\gamma}_{20}$ + $\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$ + $\\hat{\\gamma}_{22}$ + $\\hat{\\gamma}_{32}$ + $\\hat{\\gamma}_{23}$ + $\\hat{\\gamma}_{33}$]",
                   "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]",
                   "[$\\hat{\\gamma}_{11}$ + $\\hat{\\gamma}_{13}$]",
                   "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{23}$]",
                   "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$ + $\\hat{\\gamma}_{23}$ + $\\hat{\\gamma}_{33}$]",
                   "[$\\hat{\\gamma}_{22}$ + $\\hat{\\gamma}_{32}$]",
                   "[$\\hat{\\gamma}_{12}$ + $\\hat{\\gamma}_{13}$]",
                   "[$\\hat{\\gamma}_{22}$ + $\\hat{\\gamma}_{23}$]",
                   "[$\\hat{\\gamma}_{22}$ + $\\hat{\\gamma}_{32}$ + $\\hat{\\gamma}_{23}$ + $\\hat{\\gamma}_{33}$]")

for (i in 1:length(outcomes)){
  for (j in 1:length(datasets_short)){
    ### moderation by gender 
    model_gender <- get(paste0(outcomes[i], "_", datasets_short[j], "_gender_test"))
    for (k in 1:length(to_be_tested_gender)){
      contrast_gender <- as.data.frame(
        cbind(est = sum(fixef(model_gender)[contrasts_gender[[k]]]), 
              chi = linearHypothesis(model_gender, paste(contrasts_gender[[k]], 
                                                         collapse = " + "))[2, "Chisq"], 
              df = linearHypothesis(model_gender, paste(contrasts_gender[[k]], 
                                                        collapse = " + "))[2, "Df"], 
              p = linearHypothesis(model_gender, paste(contrasts_gender[[k]], 
                                                       collapse = " + "))[2, "Pr(>Chisq)"])
      )
      conf_itvl_gender <- confint(summary(multcomp::glht(model_gender, # confidence intervals
                           linfct = paste(paste(contrasts_gender[[k]], collapse = " + "), "= 0"))))
      contrast_gender <- cbind(contrast_gender, 
                        lwr = conf_itvl_gender$confint[, "lwr"], 
                        upr = conf_itvl_gender$confint[, "upr"])
      contrast_gender <- contrast_gender %>% mutate( # reformat for reporting in text
        est_num = paste(gamma_comb_gender[k], "=", printnum(est)),
        chi_print = paste0("$\\chi^2$", " (", contrast_gender$df, ") = ", printnum(contrast_gender$chi)),
        p_print = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
        conf = paste0("95% CI [", printnum(contrast_gender$lwr), ", ", printnum(contrast_gender$upr), "]")
      )
      contrast_gender["p_print"] <- # remove "0" from the chr
        lapply(contrast_gender["p_print"], gsub, pattern="0\\.", replacement="\\.")
      contrast_gender <- contrast_gender %>% 
        unite(all, c(est_num, conf, p_print), sep = ", ", remove = F) # combined string
      contrast_gender_name <- paste0(to_be_tested_gender[k], "_", outcomes[i], "_", datasets_short[j])
      eval(call("<-", as.name(contrast_gender_name), contrast_gender))
  }
    collect_contrasts_gender <- do.call(rbind, lapply(paste0(to_be_tested_gender, "_", 
                                        outcomes[i], "_", datasets_short[j]), get)) #all k's
    rownames(collect_contrasts_gender) <- to_be_tested_gender
    collected_gender_name <- paste0("contrasts_", outcomes[i], "_", datasets_short[j], "_gender")
    eval(call("<-", as.name(collected_gender_name), collect_contrasts_gender))
}
  listed_contrasts_gender <- do.call(list, lapply(paste0("contrasts_", outcomes[i], "_", 
                                                         datasets_short, "_gender"), get)) # all j's
  names(listed_contrasts_gender) <- datasets_short
  listed_gender_name <- paste0("contrasts_gender_", outcomes[i])
  eval(call("<-", as.name(listed_gender_name), listed_contrasts_gender))
}

#### moderation by paid work ####

to_be_tested_work <- c("shift_control_nowork", # shift of not-working controls vs. 0
                       "shift_control_work", # shift of working controls vs. 0
                       "shift_gp_nowork", # shift of not-working GPs vs. 0
                       "shift_gp_work", # shift of working GPs vs. 0
                       "shift_gp_vs_control_nowork", # shift of not-working GPs vs. not-working controls
                       "before_gp_vs_control_work", # before-slope of working GPs vs. working controls
                       "after_gp_vs_control_work", # after-slope of working GPs vs. working controls
                       "shift_gp_vs_control_work", # shift of working GPs vs. working controls
                       "shift_nowork_vs_work_control", # shift of not-working vs. working controls
                       "before_nowork_vs_work_gp", # before-slope of not-working vs. working GP
                       "after_nowork_vs_work_gp", # after-slope of not-working vs. working GPs
                       "shift_nowork_vs_work_gp") # shift of not-working vs. working GPs
contrasts_work <- list(c("shift", "after"),
                       c("shift", "after", "shift:working", "after:working"),
                       c("shift", "after", "shift:grandparent", "after:grandparent"),
                       c("shift", "after", "shift:working", "after:working", "shift:grandparent", 
                         "after:grandparent", "shift:grandparent:working", "after:grandparent:working"),
                       c("shift:grandparent", "after:grandparent"), 
                       c("before:grandparent", "before:grandparent:working"), 
                       c("after:grandparent", "after:grandparent:working"), 
                       c("shift:grandparent", "after:grandparent", 
                         "shift:grandparent:working", "after:grandparent:working"), 
                       c("shift:working", "after:working"),
                       c("before:working", "before:grandparent:working"),
                       c("after:working", "after:grandparent:working"),
                       c("shift:working", "after:working", 
                         "shift:grandparent:working", "after:grandparent:working"))

gamma_comb_work <- c("[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$]", 
                     "[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$ + $\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$]",
                     "[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$ + $\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$]",
                     "[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$ + $\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$ + $\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$ + $\\hat{\\gamma}_{51}$ + $\\hat{\\gamma}_{71}$]",
                     "[$\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$]",
                     "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]",
                     "[$\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{51}$]",
                     "[$\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$ + $\\hat{\\gamma}_{51}$ + $\\hat{\\gamma}_{71}$]",
                     "[$\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$]",
                     "[$\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{31}$]",
                     "[$\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{51}$]",
                     "[$\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$ + $\\hat{\\gamma}_{51}$ + $\\hat{\\gamma}_{71}$]")

datasets_short_hrs <- datasets_short[3:4]

for (i in 1:length(outcomes)){
  for (j in 1:length(datasets_short_hrs)){ # now only for the 2 HRS datasets
    ### moderation by paid work 
    model_work <- get(paste0(outcomes[i], "_", datasets_short_hrs[j], "_work_test"))
    for (k in 1:length(to_be_tested_work)){
      contrast_work <- as.data.frame(
        cbind(est = sum(fixef(model_work)[contrasts_work[[k]]]), 
              chi = linearHypothesis(model_work, paste(contrasts_work[[k]], 
                                                         collapse = " + "))[2, "Chisq"], 
              df = linearHypothesis(model_work, paste(contrasts_work[[k]], 
                                                        collapse = " + "))[2, "Df"], 
              p = linearHypothesis(model_work, paste(contrasts_work[[k]], 
                                                       collapse = " + "))[2, "Pr(>Chisq)"])
      )
      conf_itvl_work <- confint(summary(multcomp::glht(model_work, # confidence intervals
                           linfct = paste(paste(contrasts_work[[k]], collapse = " + "), "= 0"))))
      contrast_work <- cbind(contrast_work, 
                        lwr = conf_itvl_work$confint[, "lwr"], 
                        upr = conf_itvl_work$confint[, "upr"])
      contrast_work <- contrast_work %>% mutate( # reformat for reporting in text
        est_num = paste(gamma_comb_work[k], "=", printnum(est)),
        chi_print = paste0("$\\chi^2$", " (", contrast_work$df, ") = ", printnum(contrast_work$chi)),
        p_print = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
        conf = paste0("95% CI [", printnum(contrast_work$lwr), ", ", printnum(contrast_work$upr), "]")
      )
      contrast_work["p_print"] <- # remove "0" from the chr
        lapply(contrast_work["p_print"], gsub, pattern="0\\.", replacement="\\.")
      contrast_work <- contrast_work %>% 
        unite(all, c(est_num, conf, p_print), sep = ", ", remove = F) # combined string
      contrast_work_name <- paste0(to_be_tested_work[k], "_", outcomes[i], "_", datasets_short_hrs[j])
      eval(call("<-", as.name(contrast_work_name), contrast_work))
  }
    collect_contrasts_work <- do.call(rbind, lapply(paste0(to_be_tested_work, "_", 
                                        outcomes[i], "_", datasets_short_hrs[j]), get)) #all k's
    rownames(collect_contrasts_work) <- to_be_tested_work
    collected_work_name <- paste0("contrasts_", outcomes[i], "_", datasets_short_hrs[j], "_work")
    eval(call("<-", as.name(collected_work_name), collect_contrasts_work))
}
  listed_contrasts_work <- do.call(list, lapply(paste0("contrasts_", outcomes[i], "_", 
                                                         datasets_short_hrs, "_work"), get)) # all j's
  names(listed_contrasts_work) <- datasets_short_hrs
  listed_work_name <- paste0("contrasts_work_", outcomes[i])
  eval(call("<-", as.name(listed_work_name), listed_contrasts_work))
}

#### moderation by grandchild care ####

to_be_tested_care <- c("after_gp_vs_control_care", # after-slope of caring GPs vs. caring controls
                       "after_nocare_vs_care_gp") # after-slope of not-caring vs. caring GPs

contrasts_care <- list(c("after:grandparent", "after:grandparent:caring"),
                       c("after:caring", "after:grandparent:caring"))

gamma_comb_care <- c("[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]",
                     "[$\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{31}$]")

for (i in 1:length(outcomes)){
  for (j in 1:length(datasets_short_hrs)){ # now only for the 2 HRS datasets
    ### moderation by grandchild care
    model_care <- get(paste0(outcomes[i], "_", datasets_short_hrs[j], "_care_test"))
    for (k in 1:length(to_be_tested_care)){
      contrast_care <- as.data.frame(
        cbind(est = sum(fixef(model_care)[contrasts_care[[k]]]), 
              chi = linearHypothesis(model_care, paste(contrasts_care[[k]], 
                                                         collapse = " + "))[2, "Chisq"], 
              df = linearHypothesis(model_care, paste(contrasts_care[[k]], 
                                                        collapse = " + "))[2, "Df"], 
              p = linearHypothesis(model_care, paste(contrasts_care[[k]], 
                                                       collapse = " + "))[2, "Pr(>Chisq)"])
      )
      conf_itvl_care <- confint(summary(multcomp::glht(model_care, # confidence intervals
                           linfct = paste(paste(contrasts_care[[k]], collapse = " + "), "= 0"))))
      contrast_care <- cbind(contrast_care, 
                        lwr = conf_itvl_care$confint[, "lwr"], 
                        upr = conf_itvl_care$confint[, "upr"])
      contrast_care <- contrast_care %>% mutate( # reformat for reporting in text
        est_num = paste(gamma_comb_care[k], "=", printnum(est)),
        chi_print = paste0("$\\chi^2$", " (", contrast_care$df, ") = ", printnum(contrast_care$chi)),
        p_print = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
        conf = paste0("95% CI [", printnum(contrast_care$lwr), ", ", printnum(contrast_care$upr), "]")
      )
      contrast_care["p_print"] <- # remove "0" from the chr
        lapply(contrast_care["p_print"], gsub, pattern="0\\.", replacement="\\.")
      contrast_care <- contrast_care %>% 
        unite(all, c(est_num, conf, p_print), sep = ", ", remove = F) # combined string
      contrast_care_name <- paste0(to_be_tested_care[k], "_", outcomes[i], "_", datasets_short_hrs[j])
      eval(call("<-", as.name(contrast_care_name), contrast_care))
  }
    collect_contrasts_care <- do.call(rbind, lapply(paste0(to_be_tested_care, "_", 
                                        outcomes[i], "_", datasets_short_hrs[j]), get)) #all k's
    rownames(collect_contrasts_care) <- to_be_tested_care
    collected_care_name <- paste0("contrasts_", outcomes[i], "_", datasets_short_hrs[j], "_care")
    eval(call("<-", as.name(collected_care_name), collect_contrasts_care))
}
  listed_contrasts_care <- do.call(list, lapply(paste0("contrasts_", outcomes[i], "_", 
                                                         datasets_short_hrs, "_care"), get)) # all j's
  names(listed_contrasts_care) <- datasets_short_hrs
  listed_care_name <- paste0("contrasts_care_", outcomes[i])
  eval(call("<-", as.name(listed_care_name), listed_contrasts_care))
}


#### moderation by race (Reviewer suggestion) ####

to_be_tested_race <- c("shift_control_white", # shift of white controls vs. 0
                       "shift_control_black", # shift of black controls vs. 0
                       "shift_gp_white", # shift of white GPs vs. 0
                       "shift_gp_black", # shift of black GPs vs. 0
                       "shift_gp_vs_control_white", # shift of white GPs vs. white controls
                       "before_gp_vs_control_black", # before-slope of black GPs vs. black controls
                       "after_gp_vs_control_black", # after-slope of black GPs vs. black controls
                       "shift_gp_vs_control_black", # shift of black GPs vs. black controls
                       "shift_white_vs_black_control", # shift of white vs. black controls
                       "before_white_vs_black_gp", # before-slope of white vs. black GP
                       "after_white_vs_black_gp", # after-slope of white vs. black GPs
                       "shift_white_vs_black_gp") # shift of white vs. black GPs
contrasts_race <- list(c("shift", "after"),
                       c("shift", "after", "shift:black", "after:black"),
                       c("shift", "after", "shift:grandparent", "after:grandparent"),
                       c("shift", "after", "shift:black", "after:black", "shift:grandparent", 
                         "after:grandparent", "shift:grandparent:black", "after:grandparent:black"),
                       c("shift:grandparent", "after:grandparent"), 
                       c("before:grandparent", "before:grandparent:black"), 
                       c("after:grandparent", "after:grandparent:black"), 
                       c("shift:grandparent", "after:grandparent", 
                         "shift:grandparent:black", "after:grandparent:black"), 
                       c("shift:black", "after:black"),
                       c("before:black", "before:grandparent:black"),
                       c("after:black", "after:grandparent:black"),
                       c("shift:black", "after:black", 
                         "shift:grandparent:black", "after:grandparent:black"))

gamma_comb_race <- c("[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$]", 
                     "[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$ + $\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$]",
                     "[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$ + $\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$]",
                     "[$\\hat{\\gamma}_{40}$ + $\\hat{\\gamma}_{60}$ + $\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$ + $\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$ + $\\hat{\\gamma}_{51}$ + $\\hat{\\gamma}_{71}$]",
                     "[$\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$]",
                     "[$\\hat{\\gamma}_{21}$ + $\\hat{\\gamma}_{31}$]",
                     "[$\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{51}$]",
                     "[$\\hat{\\gamma}_{41}$ + $\\hat{\\gamma}_{61}$ + $\\hat{\\gamma}_{51}$ + $\\hat{\\gamma}_{71}$]",
                     "[$\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$]",
                     "[$\\hat{\\gamma}_{30}$ + $\\hat{\\gamma}_{31}$]",
                     "[$\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{51}$]",
                     "[$\\hat{\\gamma}_{50}$ + $\\hat{\\gamma}_{70}$ + $\\hat{\\gamma}_{51}$ + $\\hat{\\gamma}_{71}$]")

datasets_short_hrs <- datasets_short[3:4]

for (i in 1:length(outcomes)){
  for (j in 1:length(datasets_short_hrs)){ # now only for the 2 HRS datasets
    ### moderation by race (Reviewer suggestion)
    model_race <- get(paste0(outcomes[i], "_", datasets_short_hrs[j], "_race_test"))
    for (k in 1:length(to_be_tested_race)){
      contrast_race <- as.data.frame(
        cbind(est = sum(fixef(model_race)[contrasts_race[[k]]]), 
              chi = linearHypothesis(model_race, paste(contrasts_race[[k]], 
                                                         collapse = " + "))[2, "Chisq"], 
              df = linearHypothesis(model_race, paste(contrasts_race[[k]], 
                                                        collapse = " + "))[2, "Df"], 
              p = linearHypothesis(model_race, paste(contrasts_race[[k]], 
                                                       collapse = " + "))[2, "Pr(>Chisq)"])
      )
      conf_itvl_race <- confint(summary(multcomp::glht(model_race, # confidence intervals
                           linfct = paste(paste(contrasts_race[[k]], collapse = " + "), "= 0"))))
      contrast_race <- cbind(contrast_race, 
                        lwr = conf_itvl_race$confint[, "lwr"], 
                        upr = conf_itvl_race$confint[, "upr"])
      contrast_race <- contrast_race %>% mutate( # reformat for reporting in text
        est_num = paste(gamma_comb_race[k], "=", printnum(est)),
        chi_print = paste0("$\\chi^2$", " (", contrast_race$df, ") = ", printnum(contrast_race$chi)),
        p_print = scales::pvalue(p, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
        conf = paste0("95% CI [", printnum(contrast_race$lwr), ", ", printnum(contrast_race$upr), "]")
      )
      contrast_race["p_print"] <- # remove "0" from the chr
        lapply(contrast_race["p_print"], gsub, pattern="0\\.", replacement="\\.")
      contrast_race <- contrast_race %>% 
        unite(all, c(est_num, conf, p_print), sep = ", ", remove = F) # combined string
      contrast_race_name <- paste0(to_be_tested_race[k], "_", outcomes[i], "_", datasets_short_hrs[j])
      eval(call("<-", as.name(contrast_race_name), contrast_race))
  }
    collect_contrasts_race <- do.call(rbind, lapply(paste0(to_be_tested_race, "_", 
                                        outcomes[i], "_", datasets_short_hrs[j]), get)) #all k's
    rownames(collect_contrasts_race) <- to_be_tested_race
    collected_race_name <- paste0("contrasts_", outcomes[i], "_", datasets_short_hrs[j], "_race")
    eval(call("<-", as.name(collected_race_name), collect_contrasts_race))
}
  listed_contrasts_race <- do.call(list, lapply(paste0("contrasts_", outcomes[i], "_", 
                                                         datasets_short_hrs, "_race"), get)) # all j's
  names(listed_contrasts_race) <- datasets_short_hrs
  listed_race_name <- paste0("contrasts_race_", outcomes[i])
  eval(call("<-", as.name(listed_race_name), listed_contrasts_race))
}

# remove unnecessary objects
rm(list = ls(pattern = paste0(c(to_be_tested, to_be_tested_gender, 
                                to_be_tested_work, to_be_tested_care,
                                to_be_tested_race), collapse="|")))
#rm(list = ls(pattern = paste0("contrasts_", outcomes, "_", collapse = "|"))) # needed for plots
```

```{r H1-dataframes-plots, include=FALSE, cache=T}
# create predicted values data.frames for plots
# sources: 
# http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#lme/
# https://stackoverflow.com/questions/14358811/extract-prediction-band-from-lme-fit/
# https://stats.stackexchange.com/questions/29690/getting-fixed-effect-only-predictions-from-mixed-model-on-new-data-in-r/

#### basic models & moderation by gender ####

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 24, by = 4)[i]
  for (j in 1:length(datasets_short)){
    ### basic models
    dataset = datasets[j]
    dataset_short = datasets_short[j]
    obj_test = mod_summaries_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & time==0) %>% 
                               group_by(grandparent) %>% summarise(pscore = mean(pscore))) # pscore mean
    # different time sequences for LISS/HRS
    if (dataset_short %in% c("liss_parents", "liss_nonparents")){ 
      dframe <- data.frame( # for LISS
        pscore = c(rep(ps_mean[1,2], 13),  # controls
                   rep(ps_mean[2,2], 13)), # grandparents
        before = rep(c(0:5, rep(5, 7)), 2),
        after = rep(c(rep(0, 6), 1:7), 2),
        shift = rep(c(rep(0, 6), rep(1, 7)), 2),
        grandparent = c(rep(0, 13), rep(1, 13)),
        x = rep(-6:6, 2)
      )
    } else { # for HRS
      dframe <- data.frame(
        pscore = c(rep(ps_mean[1,2], 7), 
                   rep(ps_mean[2,2], 7)),
        before = rep(c(0:2, rep(2, 4)), 2),
        after = rep(c(rep(0, 3), 1:4), 2),
        shift = rep(c(rep(0, 3), rep(1, 4)), 2),
        grandparent = c(rep(0, 7), rep(1, 7)),
        x = rep(seq(-6, 6, by=2), 2)
      )
    }      
    # predict response (again, same procedure for LISS & HRS)
    dframe$pred <- predict(obj_test, newdata = dframe, re.form=NA)
    # create design matrix
    designmat <- model.matrix(as.formula(lme4::nobars(formula(obj_test))[-2]), 
                              dframe) # [-2] drops response from formula
    # compute standard error
    predvar <- diag(designmat %*% vcov(obj_test) %*% t(designmat)) 
    dframe$SE <- sqrt(predvar) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short %in% c("liss_parents", "hrs_parents")){ 
      dframe$gpgroup <- factor(dframe$grandparent, labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe$gpgroup <- factor(dframe$grandparent, labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe$gpgroup <- fct_rev(dframe$gpgroup)
    dframe_name <- paste0("dframe_", outcome, "_", dataset_short)
    eval(call("<-", as.name(dframe_name), dframe)) # save data.frame for later ggplot use
    ### moderation by gender models
    obj_test_gender = mod_summaries_gender_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean_gender <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & time==0) %>% 
                               group_by(grandparent, female) %>% summarise(pscore = mean(pscore)))
    # different time sequences for LISS/HRS
    if (dataset_short %in% c("liss_parents", "liss_nonparents")){ 
      dframe_gender <- data.frame(
        pscore = c(rep(ps_mean_gender[1,3], 13),  # male controls
                   rep(ps_mean_gender[2,3], 13),  # female controls
                   rep(ps_mean_gender[3,3], 13),  # male grandparents
                   rep(ps_mean_gender[4,3], 13)), # female grandparents
        before = rep(c(0:5, rep(5, 7)), 4),
        after = rep(c(rep(0, 6), 1:7), 4),
        shift = rep(c(rep(0, 6), rep(1, 7)), 4),
        grandparent = c(rep(0, 26), rep(1, 26)),
        female = rep(c(rep(0, 13), rep(1, 13)), 2),
        x = rep(-6:6, 4)
      )
    } else { # for HRS
      dframe_gender <- data.frame(
        pscore = c(rep(ps_mean_gender[1,3], 7),  # male controls
                   rep(ps_mean_gender[2,3], 7),  # female controls
                   rep(ps_mean_gender[3,3], 7),  # male grandparents
                   rep(ps_mean_gender[4,3], 7)), # female grandparents
        before = rep(c(0:2, rep(2, 4)), 4),
        after = rep(c(rep(0, 3), 1:4), 4),
        shift = rep(c(rep(0, 3), rep(1, 4)), 4),
        grandparent = c(rep(0, 14), rep(1, 14)),
        female = rep(c(rep(0, 7), rep(1, 7)), 2),
        x = rep(seq(-6, 6, by=2), 4)
      )
    }      
    # predict response (again, same procedure for LISS & HRS)
    dframe_gender$pred <- predict(obj_test_gender, newdata = dframe_gender, re.form=NA)
    # create design matrix
    designmat_gender <- model.matrix(as.formula(lme4::nobars(formula(obj_test_gender))[-2]), 
                              dframe_gender) # [-2] drops response from formula
    # compute standard error
    predvar_gender <- diag(designmat_gender %*% vcov(obj_test_gender) %*% t(designmat_gender)) 
    dframe_gender$SE <- sqrt(predvar_gender) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short %in% c("liss_parents", "hrs_parents")){ 
      dframe_gender$gpgroup <- factor(dframe_gender$grandparent, 
                                      labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe_gender$gpgroup <- factor(dframe_gender$grandparent, 
                                      labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe_gender$gpgroup <- fct_rev(dframe_gender$gpgroup)
    # add female variable as a factor
    dframe_gender$gender <- factor(dframe_gender$female, labels=c("Men","Women"))
    dframe_gender$gender <- fct_rev(dframe_gender$gender)
    dframe_name_gender <- paste0("dframe_", outcome, "_", dataset_short, "_gender")
    eval(call("<-", as.name(dframe_name_gender), dframe_gender)) # save data.frame for later ggplot use
  }
}

#### moderation by paid work ####

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = -2, to = 8, by = 2)[i] # changed this because we now only have the 2 HRS datasets
  for (j in 3:4){
    dataset = datasets[j]
    dataset_short = datasets_short[j]
    ### moderation by paid work models
    obj_test_work = mod_summaries_work_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean_work <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & 
                                           !is.na(working) & time==0) %>% 
                               group_by(grandparent, working) %>% summarise(pscore = mean(pscore)))
    # only HRS
      dframe_work <- data.frame(
        pscore = c(rep(ps_mean_work[1,3], 7),  # non-working controls
                   rep(ps_mean_work[2,3], 7),  # working controls
                   rep(ps_mean_work[3,3], 7),  # non-working grandparents
                   rep(ps_mean_work[4,3], 7)), # working grandparents
        before = rep(c(0:2, rep(2, 4)), 4),
        after = rep(c(rep(0, 3), 1:4), 4),
        shift = rep(c(rep(0, 3), rep(1, 4)), 4),
        grandparent = c(rep(0, 14), rep(1, 14)),
        working = rep(c(rep(0, 7), rep(1, 7)), 2),
        x = rep(seq(-6, 6, by=2), 4)
      )
    # predict response (again, same procedure for LISS & HRS)
    dframe_work$pred <- predict(obj_test_work, newdata = dframe_work, re.form=NA)
    # create design matrix
    designmat_work <- model.matrix(as.formula(lme4::nobars(formula(obj_test_work))[-2]), 
                              dframe_work) # [-2] drops response from formula
    # compute standard error
    predvar_work <- diag(designmat_work %*% vcov(obj_test_work) %*% t(designmat_work)) 
    dframe_work$SE <- sqrt(predvar_work) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short=="hrs_parents"){ 
      dframe_work$gpgroup <- factor(dframe_work$grandparent, 
                                      labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe_work$gpgroup <- factor(dframe_work$grandparent, 
                                      labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe_work$gpgroup <- fct_rev(dframe_work$gpgroup)
    # add paid work as a factor
    dframe_work$work <- factor(dframe_work$working, labels=c("Not Working","Working"))
    dframe_work$work <- fct_rev(dframe_work$work)
    dframe_name_work <- paste0("dframe_", outcome, "_", dataset_short, "_work")
    eval(call("<-", as.name(dframe_name_work), dframe_work)) # save data.frame for later ggplot use
  }
}

#### moderation by grandchild care ####

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 10, by = 2)[i] 
  for (j in 1:length(datasets_care)){
    dataset = datasets_care[j]
    dataset_short = datasets_short[j+2] # only HRS
    ### moderation by grandchild care models
    obj_test_care = mod_summaries_care_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean_care <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & 
                                           !is.na(caring) & time==0) %>% 
                                    group_by(grandparent, caring) %>% summarise(pscore = mean(pscore)))
    # only HRS (simplified post-transition model)
    dframe_care <- data.frame(
      pscore = c(rep(ps_mean_care[1,3], 4),  # non-caring controls
                 rep(ps_mean_care[2,3], 4),  # caring controls
                 rep(ps_mean_care[3,3], 4),  # non-caring grandparents (>100 h)
                 rep(ps_mean_care[4,3], 4)), # caring grandparents
      after = rep(c(1:4), 4),
      grandparent = c(rep(0, 8), rep(1, 8)),
      caring = rep(c(rep(0, 4), rep(1, 4)), 2),
      x = rep(seq(0, 6, by=2), 4)
    )
    # predict response (again, same procedure for LISS & HRS)
    dframe_care$pred <- predict(obj_test_care, newdata = dframe_care, re.form=NA)
    # create design matrix
    designmat_care <- model.matrix(as.formula(lme4::nobars(formula(obj_test_care))[-2]), 
                                   dframe_care) # [-2] drops response from formula
    # compute standard error
    predvar_care <- diag(designmat_care %*% vcov(obj_test_care) %*% t(designmat_care)) 
    dframe_care$SE <- sqrt(predvar_care) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short=="hrs_parents"){ 
      dframe_care$gpgroup <- factor(dframe_care$grandparent, 
                                    labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe_care$gpgroup <- factor(dframe_care$grandparent, 
                                    labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe_care$gpgroup <- fct_rev(dframe_care$gpgroup)
    # add grandchild care as a factor
    dframe_care$care <- factor(dframe_care$caring, labels=c("Less than 100h",
                                                            "More than 100h"))
    dframe_care$care <- fct_rev(dframe_care$care)
    dframe_name_care <- paste0("dframe_", outcome, "_", dataset_short, "_care")
    eval(call("<-", as.name(dframe_name_care), dframe_care)) # save data.frame for later ggplot use
  }
}

#### models restricted to time [-2, 6] ####

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 24, by = 4)[i]
  for (j in 1:length(datasets_restr)){
    ### basic models
    dataset = datasets_restr[j]
    dataset_short = datasets_short[j]
    obj_test = mod_summaries_restr_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & time==0) %>% 
                               group_by(grandparent) %>% summarise(pscore = mean(pscore))) # pscore mean
    # different time sequences for LISS/HRS
    if (dataset_short %in% c("liss_parents", "liss_nonparents")){ 
      dframe <- data.frame( # for LISS
        pscore = c(rep(ps_mean[1,2], 9),  # controls
                   rep(ps_mean[2,2], 9)), # grandparents
        before = rep(c(0:1, rep(1, 7)), 2),
        after = rep(c(rep(0, 2), 1:7), 2),
        shift = rep(c(rep(0, 2), rep(1, 7)), 2),
        grandparent = c(rep(0, 9), rep(1, 9)),
        x = rep(-2:6, 2)
      )
    } else { # for HRS
      dframe <- data.frame(
        pscore = c(rep(ps_mean[1,2], 5), 
                   rep(ps_mean[2,2], 5)),
        #before = rep(c(0:2, rep(2, 4)), 2),
        after = rep(c(0:4), 2),
        shift = rep(c(0, rep(1, 4)), 2),
        grandparent = c(rep(0, 5), rep(1, 5)),
        x = rep(seq(-2, 6, by=2), 2)
      )
    }      
    # predict response (again, same procedure for LISS & HRS)
    dframe$pred <- predict(obj_test, newdata = dframe, re.form=NA)
    # create design matrix
    designmat <- model.matrix(as.formula(lme4::nobars(formula(obj_test))[-2]), 
                              dframe) # [-2] drops response from formula
    # compute standard error
    predvar <- diag(designmat %*% vcov(obj_test) %*% t(designmat)) 
    dframe$SE <- sqrt(predvar) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short %in% c("liss_parents", "hrs_parents")){ 
      dframe$gpgroup <- factor(dframe$grandparent, labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe$gpgroup <- factor(dframe$grandparent, labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe$gpgroup <- fct_rev(dframe$gpgroup)
    dframe_name <- paste0("dframe_", outcome, "_", dataset_short, "_restr")
    eval(call("<-", as.name(dframe_name), dframe)) # save data.frame for later ggplot use
    ### moderation by gender models
    obj_test_gender = mod_summaries_restr_gender_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean_gender <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & time==0) %>% 
                                      group_by(grandparent, female) %>% summarise(pscore = mean(pscore)))
    # different time sequences for LISS/HRS
    if (dataset_short %in% c("liss_parents", "liss_nonparents")){ 
      dframe_gender <- data.frame(
        pscore = c(rep(ps_mean_gender[1,3], 9),  # male controls
                   rep(ps_mean_gender[2,3], 9),  # female controls
                   rep(ps_mean_gender[3,3], 9),  # male grandparents
                   rep(ps_mean_gender[4,3], 9)), # female grandparents
        before = rep(c(0:1, rep(1, 7)), 4),
        after = rep(c(rep(0, 2), 1:7), 4),
        shift = rep(c(rep(0, 2), rep(1, 7)), 4),
        grandparent = c(rep(0, 18), rep(1, 18)),
        female = rep(c(rep(0, 9), rep(1, 9)), 2),
        x = rep(-2:6, 4)
      )
    } else { # for HRS
      dframe_gender <- data.frame(
        pscore = c(rep(ps_mean_gender[1,3], 5),  # male controls
                   rep(ps_mean_gender[2,3], 5),  # female controls
                   rep(ps_mean_gender[3,3], 5),  # male grandparents
                   rep(ps_mean_gender[4,3], 5)), # female grandparents
        #before = rep(c(0:2, rep(2, 4)), 4),
        after = rep(c(0:4), 4),
        shift = rep(c(0, rep(1, 4)), 4),
        grandparent = c(rep(0, 10), rep(1, 10)),
        female = rep(c(rep(0, 5), rep(1, 5)), 2),
        x = rep(seq(-2, 6, by=2), 4)
      )
    }      
    # predict response (again, same procedure for LISS & HRS)
    dframe_gender$pred <- predict(obj_test_gender, newdata = dframe_gender, re.form=NA)
    # create design matrix
    designmat_gender <- model.matrix(as.formula(lme4::nobars(formula(obj_test_gender))[-2]), 
                                     dframe_gender) # [-2] drops response from formula
    # compute standard error
    predvar_gender <- diag(designmat_gender %*% vcov(obj_test_gender) %*% t(designmat_gender)) 
    dframe_gender$SE <- sqrt(predvar_gender) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short %in% c("liss_parents", "hrs_parents")){ 
      dframe_gender$gpgroup <- factor(dframe_gender$grandparent, 
                                      labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe_gender$gpgroup <- factor(dframe_gender$grandparent, 
                                      labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe_gender$gpgroup <- fct_rev(dframe_gender$gpgroup)
    # add female variable as a factor
    dframe_gender$gender <- factor(dframe_gender$female, labels=c("Men","Women"))
    dframe_gender$gender <- fct_rev(dframe_gender$gender)
    dframe_name_gender <- paste0("dframe_", outcome, "_", dataset_short, "_restr_gender")
    eval(call("<-", as.name(dframe_name_gender), dframe_gender)) # save data.frame for later ggplot use
  }
}

#### moderation by race (Reviewer suggestion) ####

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 10, by = 2)[i] 
  for (j in 1:length(datasets_race)){
    dataset = datasets_race[j]
    dataset_short = datasets_short[2 + j] # (select only HRS)
    ### moderation by race models
    obj_test_race = mod_summaries_race_test[[pos + j]] # unfold list objects (lmerTest)
    # create data.frame (with all predictors)
    ps_mean_race <- as.data.frame(subset(get(dataset), !is.na(get(outcome)) & 
                                           !is.na(black) & time==0) %>% 
                               group_by(grandparent, black) %>% summarise(pscore = mean(pscore)))
    # only HRS
      dframe_race <- data.frame(
        pscore = c(rep(ps_mean_race[1,3], 7),  # white controls
                   rep(ps_mean_race[2,3], 7),  # black controls
                   rep(ps_mean_race[3,3], 7),  # white grandparents
                   rep(ps_mean_race[4,3], 7)), # black grandparents
        before = rep(c(0:2, rep(2, 4)), 4),
        after = rep(c(rep(0, 3), 1:4), 4),
        shift = rep(c(rep(0, 3), rep(1, 4)), 4),
        grandparent = c(rep(0, 14), rep(1, 14)),
        black = rep(c(rep(0, 7), rep(1, 7)), 2),
        x = rep(seq(-6, 6, by=2), 4)
      )
    # predict response (again, same procedure for LISS & HRS)
    dframe_race$pred <- predict(obj_test_race, newdata = dframe_race, re.form=NA)
    # create design matrix
    designmat_race <- model.matrix(as.formula(lme4::nobars(formula(obj_test_race))[-2]), 
                              dframe_race) # [-2] drops response from formula
    # compute standard error
    predvar_race <- diag(designmat_race %*% vcov(obj_test_race) %*% t(designmat_race)) 
    dframe_race$SE <- sqrt(predvar_race) # for confidence intervals
    # add grandparent variable as a factor
    if (dataset_short=="hrs_parents"){ 
      dframe_race$gpgroup <- factor(dframe_race$grandparent, 
                                      labels=c("Parent\nControls","Grandparents"))
    } else { # for nonparent controls
      dframe_race$gpgroup <- factor(dframe_race$grandparent, 
                                      labels=c("Nonparent\nControls","Grandparents"))
    }      
    dframe_race$gpgroup <- fct_rev(dframe_race$gpgroup)
    # add race (White / Black) as a factor
    dframe_race$race <- factor(dframe_race$black, labels=c("White","Black"))
    dframe_race$race <- fct_rev(dframe_race$race)
    dframe_name_race <- paste0("dframe_", outcome, "_", dataset_short, "_race")
    eval(call("<-", as.name(dframe_name_race), dframe_race)) # save data.frame for later ggplot use
  }
}

# remove list objects from environment (needed for plots later)
#rm(mod_summaries_test, mod_summaries_gender, mod_summaries_gender_test, #mod_summaries
#   mod_summaries_work, mod_summaries_work_test, mod_summaries_care, mod_summaries_care_test)
```

```{r H1-build-plots, include=FALSE, cache=T}
outcomes_plots <- c(rep("Agreeableness", 4), rep("Conscientiousness", 4), rep("Extraversion", 4),  
                   rep("Neuroticism", 4), rep("Openness", 4), rep("Life Satisfaction", 4))
# y-axis limits (same span but different sections)
limits_lower <- c(rep(3, 4), rep(3, 4), rep(2.5, 4), rep(1.5, 4), rep(2.5, 4), rep(4.25, 4)) 
limits_upper <- c(rep(4.5, 4), rep(4.5, 4), rep(4, 4), rep(3, 4), rep(4, 4), rep(5.75, 4))
limits <- cbind(limits_lower, limits_upper)
rownames(limits) <- outcomes_plots

#### basic models & moderation by gender ####

# collect data frames in correct order (ACENO+LS -> LISS-p, LISS-np, HRS-p, HRS-np)
dframes <- c(sort(ls()[grep("^(?=.*dframe_agree)(?!.*gender)(?!.*work)(?!.*care)(?!.*restr)(?!.*race)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_con)(?!.*gender)(?!.*work)(?!.*care)(?!.*restr)(?!.*race)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_extra)(?!.*gender)(?!.*work)(?!.*care)(?!.*restr)(?!.*race)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_neur)(?!.*gender)(?!.*work)(?!.*care)(?!.*restr)(?!.*race)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_open)(?!.*gender)(?!.*work)(?!.*care)(?!.*restr)(?!.*race)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_swls)(?!.*gender)(?!.*work)(?!.*care)(?!.*restr)(?!.*race)", 
                            ls(), perl=T)], decreasing=T))
dframes_gender <- c(sort(ls()[grep("^(?=.*dframe_agree)(?=.*gender)(?!.*restr)", 
                                   ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_con)(?=.*gender)(?!.*restr)", 
                                   ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_extra)(?=.*gender)(?!.*restr)", 
                                   ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_neur)(?=.*gender)(?!.*restr)", 
                                   ls(), perl=T)], decreasing=T),    
                    sort(ls()[grep("^(?=.*dframe_open)(?=.*gender)(?!.*restr)", 
                                   ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_swls)(?=.*gender)(?!.*restr)", 
                                   ls(), perl=T)], decreasing=T))

for (i in 1:length(dframes)){
  ### basic
  plot <- ggplot(get(dframes[i]), aes(x=x,y=pred,colour=gpgroup))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i, 1], limits[i, 2]))+ # loop over limits as defined above
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          legend.position = "none",
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1))+
    scale_y_continuous(name=outcomes_plots[i]) 
  if (dframes[i] %in% dframes[grep("^(?=.*liss)", dframes, perl=T)]){ # filter LISS
    plot <- plot + scale_x_continuous(name="Time (in Years)",breaks=c(-6:6)) +
      geom_vline(xintercept=-0.5, colour="darkgrey") # LISS
  } else { 
    plot <- plot + scale_x_continuous(name="Time (in Years)",breaks=seq(-6,6,2)) + 
    geom_vline(xintercept=-1, colour="darkgrey") # HRS
  }      
  if (dframes[i] %in% dframes[grep("^(?=.*_parents)", dframes, perl=T)]){ # filter parent df's
    plot <- plot + theme(axis.title.x=element_blank())
  } 
  plot_name <- gsub("dframe", "plot", dframes[i])
  eval(call("<-", as.name(plot_name), plot)) # save plots for later assembly
  ### moderation by gender
  plot_gender <- ggplot(get(dframes_gender[i]), aes(x=x,y=pred,colour=gpgroup,linetype=gender))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    scale_linetype_discrete(name="Gender")+
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i, 1], limits[i, 2]))+ # loop over limits as defined above
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1),
          axis.title.y=element_blank())+
    guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 2))+ # legend element order
    scale_y_continuous() # name=outcomes_plots[i]
  if (dframes_gender[i] %in% dframes_gender[grep("^(?=.*liss)", dframes_gender, perl=T)]){ # filter LISS
    plot_gender <- plot_gender + scale_x_continuous(name="Time (in Years)",breaks=c(-6:6)) +
      geom_vline(xintercept=-0.5, colour="darkgrey") # LISS
  } else { 
    plot_gender <- plot_gender + scale_x_continuous(name="Time (in Years)",breaks=seq(-6,6,2)) + 
      geom_vline(xintercept=-1, colour="darkgrey") # HRS
  }      
  if (dframes_gender[i] %in% dframes_gender[grep("^(?=.*_parents_)", dframes_gender, perl=T)]){ 
    plot_gender <- plot_gender + theme(axis.title.x=element_blank()) # omit x-axis title for parent plots
  } 
  plot_name_gender <- gsub("dframe", "plot", dframes_gender[i])
  eval(call("<-", as.name(plot_name_gender), plot_gender)) # save plots for later assembly
}

#### moderation by paid work ####

dframes_work <- c(sort(ls()[grep("^(?=.*dframe_agree)(?=.*work)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_con)(?=.*work)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_extra)(?=.*work)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_neur)(?=.*work)", ls(), perl=T)], decreasing=T),    
                    sort(ls()[grep("^(?=.*dframe_open)(?=.*work)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_swls)(?=.*work)", ls(), perl=T)], decreasing=T))

for (i in 1:length(dframes_work)){
  ### moderation by paid work
  plot_work <- ggplot(get(dframes_work[i]), aes(x=x,y=pred,colour=gpgroup,linetype=work))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    scale_linetype_discrete(name="Work Status")+
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i*2, 1], limits[i*2, 2]))+ # loop over limits (but *2 because of length)
    scale_x_continuous(name="Time (in Years)",breaks=seq(-6,6,2))+ 
    geom_vline(xintercept=-1, colour="darkgrey")+
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1),
          axis.title.y=element_blank())+
    guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 2))+ # legend element order
    scale_y_continuous() # name=outcomes_plots[i]
  if (dframes_work[i] %in% dframes_work[grep("^(?=.*_parents_)", dframes_work, perl=T)]){ 
    plot_work <- plot_work + theme(axis.title.x=element_blank()) # omit x-axis title for parent plots
  } 
  plot_name_work <- gsub("dframe", "plot", dframes_work[i])
  eval(call("<-", as.name(plot_name_work), plot_work)) # save plots for later assembly
}

#### moderation by grandchild care ####

dframes_care <- c(sort(ls()[grep("^(?=.*dframe_agree)(?=.*care)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_con)(?=.*care)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_extra)(?=.*care)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_neur)(?=.*care)", ls(), perl=T)], decreasing=T),    
                    sort(ls()[grep("^(?=.*dframe_open)(?=.*care)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_swls)(?=.*care)", ls(), perl=T)], decreasing=T))

dframes_hrs <- dframes[grep("^(?=.*hrs)", dframes, perl=T)]

for (i in 1:length(dframes_hrs)){
  ### shortened version of basic plots for comparison (only post-transition)
  dframe_short = get(dframes_hrs[i]) %>% filter(x %in% 0:6)
  plot_short <- ggplot(dframe_short, aes(x=x,y=pred,colour=gpgroup))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i*2, 1], limits[i*2, 2]))+ # loop over limits (but *2 because of length)
    scale_x_continuous(name="Time (in Years)",breaks=seq(0,6,2))+ # starts at 0 now
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1),
          #axis.title.y=element_blank()
          )+
    scale_y_continuous(name=outcomes_plots[i*2])
  if (dframes_hrs[i] %in% dframes_hrs[grep("^(?=.*_parents)", dframes_hrs, perl=T)]){ 
    plot_short <- plot_short + theme(axis.title.x=element_blank()) # omit x-axis title for parent plots
  } 
  plot_name_short <- paste0(gsub("dframe", "plot", dframes_hrs[i]), "_short")
  eval(call("<-", as.name(plot_name_short), plot_short)) # save plots for later assembly
}
for (i in 1:length(dframes_care)){
  ### moderation by grandchild care
  plot_care <- ggplot(get(dframes_care[i]), aes(x=x,y=pred,colour=gpgroup,linetype=care))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    scale_linetype_discrete(name="Grandchild Care")+
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i*2, 1], limits[i*2, 2]))+ # loop over limits (but *2 because of length)
    scale_x_continuous(name="Time (in Years)",breaks=seq(0,6,2))+ # starts at 0 now
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1),
          axis.title.y=element_blank())+
    guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 2)) # legend element order
    #scale_y_continuous(name=outcomes_plots[i*2])
  if (dframes_care[i] %in% dframes_care[grep("^(?=.*_parents_)", dframes_care, perl=T)]){ 
    plot_care <- plot_care + theme(axis.title.x=element_blank()) # omit x-axis title for parent plots
  } 
  plot_name_care <- gsub("dframe", "plot", dframes_care[i])
  eval(call("<-", as.name(plot_name_care), plot_care)) # save plots for later assembly
}

#### models restricted to time [-2, 6] ####

# collect data frames in correct order (ACENO+LS -> LISS-p, LISS-np, HRS-p, HRS-np)
dframes_restr <- c(sort(ls()[grep("^(?=.*dframe_agree)(?=.*restr)(?!.*gender)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_con)(?=.*restr)(?!.*gender)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_extra)(?=.*restr)(?!.*gender)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_neur)(?=.*restr)(?!.*gender)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_open)(?=.*restr)(?!.*gender)", 
                            ls(), perl=T)], decreasing=T),
             sort(ls()[grep("^(?=.*dframe_swls)(?=.*restr)(?!.*gender)", 
                            ls(), perl=T)], decreasing=T))
dframes_restr_gender <- c(sort(ls()[grep("^(?=.*dframe_agree)(?=.*restr_gender)", 
                                         ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_con)(?=.*restr_gender)", 
                                   ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_extra)(?=.*restr_gender)", 
                                   ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_neur)(?=.*restr_gender)", 
                                   ls(), perl=T)], decreasing=T),    
                    sort(ls()[grep("^(?=.*dframe_open)(?=.*restr_gender)", 
                                   ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_swls)(?=.*restr_gender)", 
                                   ls(), perl=T)], decreasing=T))

for (i in 1:length(dframes_restr)){
  ### basic
  plot <- ggplot(get(dframes_restr[i]), aes(x=x,y=pred,colour=gpgroup))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i, 1], limits[i, 2]))+ # loop over limits as defined above
    theme(#axis.text = element_text(face="bold"), #, size=14
      #axis.title = element_text(size=18),
      #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
      #legend.text=element_text(size=14),
      #legend.title=element_text(size=14),
      legend.position = "none",
      panel.border=element_rect(colour="darkgrey", fill=NA, size=1))+
    scale_y_continuous(name=outcomes_plots[i]) 
  if (dframes_restr[i] %in% dframes_restr[grep("^(?=.*liss)", dframes_restr, perl=T)]){ # filter LISS
    plot <- plot + scale_x_continuous(name="Time (in Years)",breaks=c(-2:6)) +
      geom_vline(xintercept=-0.5, colour="darkgrey") # LISS
  } else { 
    plot <- plot + scale_x_continuous(name="Time (in Years)",breaks=seq(-2,6,2)) + 
      geom_vline(xintercept=-1, colour="darkgrey") # HRS
  }      
  if (dframes_restr[i] %in% dframes_restr[grep("^(?=.*_parents)", 
                                               dframes_restr, perl=T)]){ # filter parent df's
    plot <- plot + theme(axis.title.x=element_blank())
  } 
  plot_name <- gsub("dframe", "plot", dframes_restr[i])
  eval(call("<-", as.name(plot_name), plot)) # save plots for later assembly
  ### moderation by gender
  plot_gender <- ggplot(get(dframes_restr_gender[i]), aes(x=x,y=pred,colour=gpgroup,linetype=gender))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    scale_linetype_discrete(name="Gender")+
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i, 1], limits[i, 2]))+ # loop over limits as defined above
    theme(#axis.text = element_text(face="bold"), #, size=14
      #axis.title = element_text(size=18),
      #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
      #legend.text=element_text(size=14),
      #legend.title=element_text(size=14),
      panel.border=element_rect(colour="darkgrey", fill=NA, size=1),
      axis.title.y=element_blank())+
    guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 2))+ # legend element order
    scale_y_continuous() # name=outcomes_plots[i]
  if (dframes_restr_gender[i] %in% 
      dframes_restr_gender[grep("^(?=.*liss)", dframes_restr_gender, perl=T)]){ # filter LISS
    plot_gender <- plot_gender + scale_x_continuous(name="Time (in Years)",breaks=c(-2:6)) +
      geom_vline(xintercept=-0.5, colour="darkgrey") # LISS
  } else { 
    plot_gender <- plot_gender + scale_x_continuous(name="Time (in Years)",breaks=seq(-2,6,2)) + 
      geom_vline(xintercept=-1, colour="darkgrey") # HRS
  }      
  if (dframes_restr_gender[i] %in% 
      dframes_restr_gender[grep("^(?=.*_parents_)", dframes_restr_gender, perl=T)]){ 
    plot_gender <- plot_gender + theme(axis.title.x=element_blank()) # omit x-axis title for parent plots
  } 
  plot_name_gender <- gsub("dframe", "plot", dframes_restr_gender[i])
  eval(call("<-", as.name(plot_name_gender), plot_gender)) # save plots for later assembly
}

#### moderation by race (Reviewer suggestion) ####

dframes_race <- c(sort(ls()[grep("^(?=.*dframe_agree)(?=.*race)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_con)(?=.*race)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_extra)(?=.*race)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_neur)(?=.*race)", ls(), perl=T)], decreasing=T),    
                    sort(ls()[grep("^(?=.*dframe_open)(?=.*race)", ls(), perl=T)], decreasing=T),
                    sort(ls()[grep("^(?=.*dframe_swls)(?=.*race)", ls(), perl=T)], decreasing=T))

for (i in 1:length(dframes_race)){
  ### moderation by race
  plot_race <- ggplot(get(dframes_race[i]), aes(x=x,y=pred,colour=gpgroup,linetype=race))+
    geom_line(position=position_dodge(width=0.2),size=1)+
    geom_point(position=position_dodge(width=0.2),size=1.5)+
    scale_colour_brewer(palette = "Set1", name="Group")+ 
    scale_linetype_discrete(name="Race")+
    geom_errorbar(aes(ymin=pred-1.96*SE,ymax=pred+1.96*SE),width=0.6,position=position_dodge(width=0.2))+
    coord_cartesian(ylim=c(limits[i*2, 1], limits[i*2, 2]))+ # loop over limits (but *2 because of length)
    scale_x_continuous(name="Time (in Years)",breaks=seq(-6,6,2))+ 
    geom_vline(xintercept=-1, colour="darkgrey")+
    theme(#axis.text = element_text(face="bold"), #, size=14
          #axis.title = element_text(size=18),
          #legend.background = element_rect(fill="gray90", size=.5, linetype="dotted"),
          #legend.text=element_text(size=14),
          #legend.title=element_text(size=14),
          panel.border=element_rect(colour="darkgrey", fill=NA, size=1),
          axis.title.y=element_blank())+
    guides(colour = guide_legend(order = 1), linetype = guide_legend(order = 2))+ # legend element order
    scale_y_continuous() # name=outcomes_plots[i]
  if (dframes_race[i] %in% dframes_race[grep("^(?=.*_parents_)", dframes_race, perl=T)]){ 
    plot_race <- plot_race + theme(axis.title.x=element_blank()) # omit x-axis title for parent plots
  } 
  plot_name_race <- gsub("dframe", "plot", dframes_race[i])
  eval(call("<-", as.name(plot_name_race), plot_race)) # save plots for later assembly
}

# need wider y-axis limits for LS & moderation by race
plot_swls_hrs_parents_race <- plot_swls_hrs_parents_race + coord_cartesian(ylim=c(3.25, 5.75))
plot_swls_hrs_nonparents_race <- plot_swls_hrs_nonparents_race + coord_cartesian(ylim=c(3.25, 5.75))
```

```{r H2-test-random-slopes, include=FALSE, cache=T}
# H2: Individual differences in intraindividual change

anova_summaries <- list()

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 20, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = datasets[j]
    # update basic models with random slopes (one at a time) -> random slopes for pid (not hid)
    rs_before <- update(mod_summaries[[pos + j]], . ~ . -(1 | pid) + (1 + before | pid), 
                        control = lme4::lmerControl(optimizer="bobyqa")) # some nonconvergence with default opt
    rs_after <-  update(mod_summaries[[pos + j]], . ~ . -(1 | pid) + (1 + after | pid), 
                        control = lme4::lmerControl(optimizer="bobyqa"))
    rs_shift <-  update(mod_summaries[[pos + j]], . ~ . -(1 | pid) + (1 + shift | pid), 
                        control = lme4::lmerControl(optimizer="bobyqa"))
    # run anova() for model comparison
    before_anov <- as.numeric(anova(mod_summaries[[pos + j]], rs_before)[2, c("Chisq", "Pr(>Chisq)")])
    after_anov <-  as.numeric(anova(mod_summaries[[pos + j]], rs_after)[2, c("Chisq", "Pr(>Chisq)")])
    shift_anov <-  as.numeric(anova(mod_summaries[[pos + j]], rs_shift)[2, c("Chisq", "Pr(>Chisq)")])
    # together
    comp_anov <- as.data.frame(rbind(before_anov, after_anov, shift_anov))
    comp_anov <- comp_anov %>% mutate(
      chi2 = printnum(V1),
      p = scales::pvalue(V2, prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
      ) %>% dplyr::select(chi2, p)
    comp_anov["p"] <- # remove "0" from the chr's
      lapply(comp_anov["p"], gsub, pattern="0\\.", replacement="\\.")
    rownames(comp_anov) <- c("before", "after", "shift")
    # save in list object
    anova_summaries[[pos + j]] <- comp_anov
    names(anova_summaries)[[pos + j]] <- paste0(outcome, "_", dataset, "_comp")
  }
}
# all p < .001 -> no table needed?
```

```{r H2-heterogeneous-variance, include=FALSE, cache=T}
# H2: Individual differences in intraindividual change

hetvar_summaries <- list()

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 20, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = datasets[j]
    # test heterogeneous variance ('slopes' = model with separate random slope variances for each group)
    # heterogeneous variance models in 'nlme' (also possible in 'lme4' but we preregistered 'nlme')
    # same number of fixed effects just coded differently 
    dummyfixed <- formula(paste(outcome, '0 + pscore + dummy(grandparent,"0") + dummy(grandparent,"1") + 
                  before:dummy(grandparent,"0") + before:dummy(grandparent,"1") +
                  after:dummy(grandparent,"0") + after:dummy(grandparent,"1") +
                  shift:dummy(grandparent,"0") + shift:dummy(grandparent,"1")', sep = "~"))
    ### before-slope -> random slope
    # built an if/else condition here, because:
    # different 'control' settings for one of the models needed that would not converge otherwise
    # https://stackoverflow.com/questions/68122117/nlminb-problem-convergence-error-code-1-message-iteration-limit-reached-wit
    if (outcome=="con" & dataset=="lissanalysis_nonparents"){
      before_mod_hetvar_slopes <- 
        nlme::lme(fixed = dummyfixed,
                  random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0") +
                                                                        before:dummy(grandparent,"0")),
                                                         nlme::pdSymm(~ 0 + dummy(grandparent,"1") + 
                                                                        before:dummy(grandparent,"1"))))), 
                  data = get(dataset), method = 'REML', na.action = 'na.omit', 
                  control=list(msMaxIter = 1000, msMaxEval = 1000))
    } else { # all other models
      before_mod_hetvar_slopes <- 
        nlme::lme(fixed = dummyfixed,
                  random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0") +
                                                                        before:dummy(grandparent,"0")),
                                                         nlme::pdSymm(~ 0 + dummy(grandparent,"1") + 
                                                                        before:dummy(grandparent,"1"))))), 
                  data = get(dataset), method = 'REML', na.action = 'na.omit')
    }
    # base model with same FE specification but uniform random slope variance
    before_mod_hetvar_base <- 
      nlme::lme(fixed = dummyfixed,
                random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0")),
                                                       nlme::pdSymm(~ 0 + dummy(grandparent,"1")),
                                                       nlme::pdSymm(~ 0 + before)))), 
                data = get(dataset), method = 'REML', na.action = 'na.omit')
    ### after-slope -> random slope
    # built an if/else condition here, because:
    # different 'control' settings for one of the models that would not converge otherwise
    # https://stackoverflow.com/questions/68122117/nlminb-problem-convergence-error-code-1-message-iteration-limit-reached-wit
    # -> added "lissanalysis_nonparents", too, because it would not converge on Windows machine
    # -> does not alter model results!
    if (outcome=="open" & dataset %in% c("lissanalysis_parents", "lissanalysis_nonparents")){
      after_mod_hetvar_slopes <- 
        nlme::lme(fixed = dummyfixed,
                  random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0") +
                                                                        after:dummy(grandparent,"0")),
                                                         nlme::pdSymm(~ 0 + dummy(grandparent,"1") + 
                                                                        after:dummy(grandparent,"1"))))), 
                  data = get(dataset), method = 'REML', na.action = 'na.omit',
                  control=list(msMaxIter = 1000, msMaxEval = 1000))
    } else { # all other models
      after_mod_hetvar_slopes <- 
        nlme::lme(fixed = dummyfixed,
                  random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0") +
                                                                        after:dummy(grandparent,"0")),
                                                         nlme::pdSymm(~ 0 + dummy(grandparent,"1") + 
                                                                        after:dummy(grandparent,"1"))))), 
                  data = get(dataset), method = 'REML', na.action = 'na.omit')
    }
    # base model with same FE specification but uniform random slope variance
    after_mod_hetvar_base <- 
      nlme::lme(fixed = dummyfixed,
                random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0")),
                                                       nlme::pdSymm(~ 0 + dummy(grandparent,"1")),
                                                       nlme::pdSymm(~ 0 + after)))), 
                data = get(dataset), method = 'REML', na.action = 'na.omit')
    ### shift -> random slope
    shift_mod_hetvar_slopes <- 
      nlme::lme(fixed = dummyfixed,
                random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0") +
                                                                      shift:dummy(grandparent,"0")),
                                                       nlme::pdSymm(~ 0 + dummy(grandparent,"1") + 
                                                                      shift:dummy(grandparent,"1"))))), 
                data = get(dataset), method = 'REML', na.action = 'na.omit')
    # base model with same FE specification but uniform random slope variance
    shift_mod_hetvar_base <- 
      nlme::lme(fixed = dummyfixed,
                random=list(pid = nlme::pdBlocked(list(nlme::pdSymm(~ 0 + dummy(grandparent,"0")),
                                                       nlme::pdSymm(~ 0 + dummy(grandparent,"1")),
                                                       nlme::pdSymm(~ 0 + shift)))), 
                data = get(dataset), method = 'REML', na.action = 'na.omit')
    # variance estimates
    varest <- # row1 = single random slope var; row2 / row3 = het. random slope var (controls / GPs) etc.
      as.data.frame(rbind(
        cbind(as.numeric(VarCorr(before_mod_hetvar_base)[3, 1]),
              as.numeric(VarCorr(before_mod_hetvar_base)[3, 2])), 
        cbind(as.numeric(VarCorr(before_mod_hetvar_slopes)[c(2,4), 1]), 
              as.numeric(VarCorr(before_mod_hetvar_slopes)[c(2,4), 2])),
        cbind(as.numeric(VarCorr(after_mod_hetvar_base)[3, 1]), 
              as.numeric(VarCorr(after_mod_hetvar_base)[3, 2])), 
        cbind(as.numeric(VarCorr(after_mod_hetvar_slopes)[c(2,4), 1]), 
              as.numeric(VarCorr(after_mod_hetvar_slopes)[c(2,4), 2])),
        cbind(as.numeric(VarCorr(shift_mod_hetvar_base)[3, 1]), 
              as.numeric(VarCorr(shift_mod_hetvar_base)[3, 2])), 
        cbind(as.numeric(VarCorr(shift_mod_hetvar_slopes)[c(2,4), 1]), 
              as.numeric(VarCorr(shift_mod_hetvar_slopes)[c(2,4), 2]))))
    colnames(varest) <- c("var", "sd")
    varest_names <- c("before_uni_rand_slope", "before_control_rand_slope", "before_gp_rand_slope",
                      "after_uni_rand_slope", "after_control_rand_slope", "after_gp_rand_slope",
                      "shift_uni_rand_slope", "shift_control_rand_slope", "shift_gp_rand_slope")
    rownames(varest) <- varest_names
    # run anova() for model comparison
    before_hetvar_anov <- as.numeric(anova(before_mod_hetvar_base, 
                                           before_mod_hetvar_slopes)[2, c("L.Ratio", "p-value")])
    after_hetvar_anov <-  as.numeric(anova(after_mod_hetvar_base, 
                                           after_mod_hetvar_slopes)[2, c("L.Ratio", "p-value")])
    shift_hetvar_anov <-  as.numeric(anova(shift_mod_hetvar_base, 
                                           shift_mod_hetvar_slopes)[2, c("L.Ratio", "p-value")])
    before_hetvar_anov[3] <- ifelse(varest["before_control_rand_slope","var"] < 
                                      varest["before_gp_rand_slope","var"], "yes", "no")
    after_hetvar_anov[3] <- ifelse(varest["after_control_rand_slope","var"] < 
                                      varest["after_gp_rand_slope","var"], "yes", "no")
    shift_hetvar_anov[3] <- ifelse(varest["shift_control_rand_slope","var"] < 
                                      varest["shift_gp_rand_slope","var"], "yes", "no")
    # together
    comp_hetvar_anov <- as.data.frame(rbind(
      do.call("rbind", replicate(3, before_hetvar_anov, simplify = FALSE)), # three times for later cbind
      do.call("rbind", replicate(3, after_hetvar_anov, simplify = FALSE)),
      do.call("rbind", replicate(3, shift_hetvar_anov, simplify = FALSE))))
    comp_hetvar_anov <- comp_hetvar_anov %>% mutate(
      lratio = printnum(as.numeric(V1)),
      p = scales::pvalue(as.numeric(V2), prefix = c("$p$ < ", "$p$ = ", "$p$ > ")),
    ) %>% dplyr::select(lratio, p, gp_greater = V3)
    comp_hetvar_anov["p"] <- # remove "0" from the chr's 
      lapply(comp_hetvar_anov["p"], gsub, pattern="0\\.", replacement="\\.")
    rownames(comp_hetvar_anov) <- varest_names
    # bind variance estimates + anova results
    varest <- cbind(varest, comp_hetvar_anov)
    # save in list object
    hetvar_summaries[[pos + j]] <- varest
    names(hetvar_summaries)[[pos + j]] <- paste0(outcome, "_", dataset, "_hetvar")
  }
}
# for supplemental tables 
```

```{r H3-rank-order-stab, include=FALSE, cache=T}
# H3: rank-order stability

# construct data sets with the time point of matching and the first post-transition assessment (within-person)
draw_below <- function(x) { 
  x %>% 
    filter(time==matchtime) %>% 
    dplyr::select(match_number, grandparent, time_pre = time, # using match_number instead of pid
           agree_pre = agree, con_pre = con, extra_pre = extra, 
           neur_pre = neur, open_pre = open, swls_pre = swls) }
draw_above <- function(x) { 
  x %>% 
  filter(time>=0) %>% group_by(match_number) %>% slice_min(time) %>% ungroup() %>% 
  dplyr::select(match_number, grandparent, time, all_of(outcomes)) }

list_below <- list(lissanalysis_parents, lissanalysis_nonparents,
                   hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_below)
list_above <- list(lissanalysis_parents, lissanalysis_nonparents,
                   hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_above)
names(list_below) <- paste0(datasets, "_rank_below")
names(list_above) <- paste0(datasets, "_rank_above")

list2env(c(list_below, list_above), .GlobalEnv)

# liss
lissanalysis_parents_rank <- left_join(lissanalysis_parents_rank_above, 
                                       lissanalysis_parents_rank_below) %>% 
  mutate(yr_lag = time - time_pre)
lissanalysis_nonparents_rank <- left_join(lissanalysis_nonparents_rank_above, 
                                          lissanalysis_nonparents_rank_below) %>% 
  mutate(yr_lag = time - time_pre)
# hrs
hrsanalysis_parents_rank <- left_join(hrsanalysis_parents_rank_above, 
                                      hrsanalysis_parents_rank_below) %>% 
  mutate(yr_lag = time - time_pre)
hrsanalysis_nonparents_rank <- left_join(hrsanalysis_nonparents_rank_above, 
                                         hrsanalysis_nonparents_rank_below) %>% 
  mutate(yr_lag = time - time_pre)

rm(list = ls(pattern = paste0(c("_below", "_above"), collapse="|")))

rank_order_df <- as.data.frame(
  cbind(cor_all = rep(NA, 24), cor_gp = rep(NA, 24), cor_con = rep(NA, 24), p = rep(NA, 24)))

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 20, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = paste0(datasets[j], "_rank")
    # simple correlations
    cor_all <- as.numeric(get(dataset) %>% 
      filter(!is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_gp <-  as.numeric(get(dataset) %>% 
      filter(grandparent==1 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_con <- as.numeric(get(dataset) %>% 
      filter(grandparent==0 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    # interaction model as significance test for group differences
    formula_rank <- formula(paste(outcome, paste0(outcome, "_pre*grandparent"), sep = "~"))
    rank_order_int <- lm(formula = formula_rank, data = get(dataset))
    # save in df
    rank_order_df[pos + j, ] <- 
      c(cor_all, cor_gp, cor_con, summary(rank_order_int)$coef[4, 4]) # interaction p-val. 
    rownames(rank_order_df)[pos + j] <- paste0(outcomes[i], "_", datasets_short[j], "_rank")
  }
}

# alternatively: 
# construct data sets with the first pre- and the last post-transition assessment (within-person)
# -> maximally large gap for retest
draw_below_max <- function(x) { 
  x %>% 
    filter(time<0) %>% group_by(match_number) %>% slice_min(time) %>% ungroup() %>%
    dplyr::select(match_number, grandparent, time_pre = time, # using match_number instead of pid
           agree_pre = agree, con_pre = con, extra_pre = extra, 
           neur_pre = neur, open_pre = open, swls_pre = swls) }
draw_above_max <- function(x) { 
  x %>% 
  filter(time>=0) %>% group_by(match_number) %>% slice_max(time) %>% ungroup() %>% 
  dplyr::select(match_number, grandparent, time, all_of(outcomes)) }

list_below_max <- list(lissanalysis_parents, lissanalysis_nonparents,
                       hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_below_max)
list_above_max <- list(lissanalysis_parents, lissanalysis_nonparents,
                       hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_above_max)
names(list_below_max) <- paste0(datasets, "_rank_below_max")
names(list_above_max) <- paste0(datasets, "_rank_above_max")

list2env(c(list_below_max, list_above_max), .GlobalEnv)

# liss
lissanalysis_parents_rank_max <- left_join(lissanalysis_parents_rank_above_max, 
                                           lissanalysis_parents_rank_below_max) %>% 
  mutate(yr_lag = time - time_pre)
lissanalysis_nonparents_rank_max <- left_join(lissanalysis_nonparents_rank_above_max, 
                                              lissanalysis_nonparents_rank_below_max) %>% 
  mutate(yr_lag = time - time_pre)
# hrs
hrsanalysis_parents_rank_max <- left_join(hrsanalysis_parents_rank_above_max, 
                                          hrsanalysis_parents_rank_below_max) %>% 
  mutate(yr_lag = time - time_pre)
hrsanalysis_nonparents_rank_max <- left_join(hrsanalysis_nonparents_rank_above_max, 
                                             hrsanalysis_nonparents_rank_below_max) %>% 
  mutate(yr_lag = time - time_pre)

rm(list = ls(pattern = paste0(c("_below_max", "_above_max"), collapse="|")))

rank_order_df_max <- as.data.frame(
  cbind(cor_all = rep(NA, 24), cor_gp = rep(NA, 24), cor_con = rep(NA, 24), p = rep(NA, 24)))

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 20, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = paste0(datasets[j], "_rank_max")
    # simple correlations
    cor_all <- as.numeric(get(dataset) %>% 
      filter(!is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_gp <-  as.numeric(get(dataset) %>% 
      filter(grandparent==1 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_con <- as.numeric(get(dataset) %>% 
      filter(grandparent==0 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    # interaction model as significance test for group differences
    formula_rank <- formula(paste(outcome, paste0(outcome, "_pre*grandparent"), sep = "~"))
    rank_order_int_max <- lm(formula = formula_rank, data = get(dataset))
    # save in df
    rank_order_df_max[pos + j, ] <- 
      c(cor_all, cor_gp, cor_con, summary(rank_order_int_max)$coef[4, 4]) # interaction p-val. 
    rownames(rank_order_df_max)[pos + j] <- paste0(outcomes[i], "_", datasets_short[j], "_rank")
  }
}

# third alternative: unique pid's
# remove pid duplicates resulting from matching with replacement 
# (might bias results towards greater stability in the controls)
draw_below_uni <- function(x) { 
  x %>% 
  group_by(pid) %>% 
  filter(time==matchtime) %>% arrange(desc(time)) %>% # match time closest to transition 
  slice(n=1) %>% ungroup() %>% # only 1 row per pid
  dplyr::select(pid, grandparent, time_pre = time, 
         agree_pre = agree, con_pre = con, extra_pre = extra, 
         neur_pre = neur, open_pre = open, swls_pre = swls) }
draw_above_uni <- function(x) { 
  x %>% 
  filter(time>=0) %>% group_by(match_number) %>% slice_min(time) %>% ungroup() %>% 
  group_by(pid) %>% slice(n=1) %>% ungroup() %>% # 1 row per pid (closest to transition)
  dplyr::select(pid, grandparent, time, all_of(outcomes)) }

list_below_uni <- list(lissanalysis_parents, lissanalysis_nonparents,
                       hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_below_uni)
list_above_uni <- list(lissanalysis_parents, lissanalysis_nonparents,
                       hrsanalysis_parents, hrsanalysis_nonparents) %>% lapply(draw_above_uni)
names(list_below_uni) <- paste0(datasets, "_rank_below_uni")
names(list_above_uni) <- paste0(datasets, "_rank_above_uni")

list2env(c(list_below_uni, list_above_uni), .GlobalEnv)

# liss
lissanalysis_parents_rank_uni <- left_join(lissanalysis_parents_rank_above_uni, 
                                           lissanalysis_parents_rank_below_uni) %>% 
  mutate(yr_lag = time - time_pre)
lissanalysis_nonparents_rank_uni <- left_join(lissanalysis_nonparents_rank_above_uni, 
                                              lissanalysis_nonparents_rank_below_uni) %>% 
  mutate(yr_lag = time - time_pre)
# hrs
hrsanalysis_parents_rank_uni <- left_join(hrsanalysis_parents_rank_above_uni, 
                                          hrsanalysis_parents_rank_below_uni) %>% 
  mutate(yr_lag = time - time_pre)
hrsanalysis_nonparents_rank_uni <- left_join(hrsanalysis_nonparents_rank_above_uni, 
                                             hrsanalysis_nonparents_rank_below_uni) %>% 
  mutate(yr_lag = time - time_pre)

rm(list = ls(pattern = paste0(c("_below_uni", "_above_uni"), collapse="|")))

rank_order_df_uni <- as.data.frame(
  cbind(cor_all = rep(NA, 24), cor_gp = rep(NA, 24), cor_con = rep(NA, 24), p = rep(NA, 24)))

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  pos = seq(from = 0, to = 20, by = 4)[i]
  for (j in 1:length(datasets)){
    dataset = paste0(datasets[j], "_rank_uni")
    # simple correlations
    cor_all <- as.numeric(get(dataset) %>% 
      filter(!is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_gp <-  as.numeric(get(dataset) %>% 
      filter(grandparent==1 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    cor_con <- as.numeric(get(dataset) %>% 
      filter(grandparent==0 & !is.na(get(outcome)) & !is.na(get(paste0(outcome, "_pre")))) %>% 
      summarise(cor(get(outcome), get(paste0(outcome, "_pre")))))
    # interaction model as significance test for group differences
    formula_rank <- formula(paste(outcome, paste0(outcome, "_pre*grandparent"), sep = "~"))
    rank_order_int_uni <- lm(formula = formula_rank, data = get(dataset))
    # save in df
    rank_order_df_uni[pos + j, ] <- 
      c(cor_all, cor_gp, cor_con, summary(rank_order_int_uni)$coef[4, 4]) # interaction p-val. 
    rownames(rank_order_df_uni)[pos + j] <- paste0(outcomes[i], "_", datasets_short[j], "_rank")
  }
}
```

## Descriptive Results

Means and standard deviations of the Big Five and life satisfaction over the analyzed time points are presented in Tables \@ref(tab:descriptives-liss) and \@ref(tab:descriptives-hrs). Visually represented (see Figures \@ref(fig:loess-agree)-\@ref(fig:loess-swls)), all six outcomes display marked stability over time in both LISS and HRS. Intra-class correlations (see Table \@ref(tab:icc-table)) show that large portions of the total variance in the Big Five could be explained by nesting in respondents (*median* = `r median(c(icc_list[c(1,4,7,10), 1], icc_list[c(1,4,7,10), 2], icc_list[c(1,4,7,10), 3], icc_list[c(1,4,7,10), 4], icc_list[c(1,4,7,10), 5]))`), while nesting in households only accounted for minor portions of the total variance ($ICC_{hid}$, *median* = `r median(c(icc_list[c(2,5,8,11), 1], icc_list[c(2,5,8,11), 2], icc_list[c(2,5,8,11), 3], icc_list[c(2,5,8,11), 4], icc_list[c(2,5,8,11), 5]))`). For outcome-subsample combinations with $ICC_{hid}$ below $0.05$ we omitted the household nesting factor from all models to bypass computational errors---a small deviation from our preregistration. For life satisfaction, the nesting in households accounted for slightly larger portions of the total variance (*median* = `r median(icc_list[c(2,5,8,11), 6])`) than nesting in respondents (*median* = `r median(icc_list[c(1,4,7,10), 6])`). Across all outcomes, the proportion of variance due to within-person factors was relatively low (*median* = `r 1 - median(c(icc_list[c(3,6,9,12), 1], icc_list[c(3,6,9,12), 2], icc_list[c(3,6,9,12), 3], icc_list[c(3,6,9,12), 4], icc_list[c(3,6,9,12), 5], icc_list[c(3,6,9,12), 6]))`).  

## Mean-Level Changes

Figures \@ref(fig:effects-basic-plot) and \@ref(fig:effects-gender-plot) summarize the effects of the basic models and those including the gender interaction for all outcomes and across the four analysis samples.  

(ref:effects-basic-plot-cap) Unstandardized Effect Sizes of the Basic Models Across Analysis Samples (Regression Coefficients $\hat{\gamma}$ or Linear Contrasts $\hat{\gamma}_{c}$ From Multilevel Models, see Tables \@ref(tab:H1-agree-tab), \@ref(tab:H1-agree-contrasts), \@ref(tab:H1-con-tab), \@ref(tab:H1-con-contrasts), \@ref(tab:H1-extra-tab), \@ref(tab:H1-extra-contrasts), \@ref(tab:H1-neur-tab), \@ref(tab:H1-neur-contrasts), \@ref(tab:H1-open-tab), \@ref(tab:H1-open-contrasts), \@ref(tab:H1-swls-tab), \@ref(tab:H1-swls-contrasts)). Error Bars Represent 95% Confidence Intervals.

```{r effects-basic-plot, fig.cap = "(ref:effects-basic-plot-cap)", fig.height=6, fig.width=8, cache=T}
# see Matz & Harari (2021) JPSP : https://osf.io/qae5y/

effects_basic <- summary(agree_liss_parents_test)$coefficients[c("before:grandparent", 
                                                                 "after:grandparent"), 
                                                               c("Estimate", "Std. Error")]
colnames(effects_basic) <- c("est", "err")
# compute 95% CIs
effects_basic <- effects_basic %>% as.data.frame() %>% mutate(
  lwr = est - qnorm(.975)*err,
  upr = est + qnorm(.975)*err,
) %>% dplyr::select(-err)
# add shift effect from contrast object
effects_basic <- rbind(effects_basic, 
                       contrasts_agree_liss_parents["shift_gp_vs_control", c("est", "lwr", "upr")])
rownames(effects_basic) <- NULL
# add descriptive factor variables for later ggplot use 
effects_basic$parameter <- factor(c("Before-slope", "After-slope", "Shift"), 
                                  levels = c("Before-slope", "After-slope", "Shift"))
effects_basic$outcome <- factor(c(df_outcomes["agree", "maj"]))
effects_basic$sample <- factor(c("LISS"))
effects_basic$comparison <- factor(c("Parents"))

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  for (j in 1:length(c("liss", "hrs"))){
    panel = c("liss", "hrs")[j]
    for (k in 1:length(c("parents", "nonparents"))){
      comp = c("parents", "nonparents")[k]
      model = get(paste(outcome, panel, comp, "test", sep = "_"))
      # all but first one (which we created above)
      if (paste(outcome, panel, comp, "test", sep = "_")!="agree_liss_parents_test"){ 
      # grab effects from previously saved models
      more_effects <- summary(model)$coefficients[c("before:grandparent", "after:grandparent"), 
                                                   c("Estimate", "Std. Error")]
      colnames(more_effects) <- c("est", "err")
      # compute 95% CIs
      more_effects <- more_effects %>% as.data.frame() %>% mutate(
        lwr = est - qnorm(.975)*err,
        upr = est + qnorm(.975)*err,
      ) %>% dplyr::select(-err)
      # add shift effect from contrast object
      contrast = get(paste("contrasts", outcome, panel, comp, sep = "_"))
      more_effects <- rbind(more_effects, 
                             contrast["shift_gp_vs_control", c("est", "lwr", "upr")])
      rownames(more_effects) <- NULL
      # add descriptive factor variables for later ggplot use 
      more_effects$parameter <- factor(c("Before-slope", "After-slope", "Shift"), 
                                       levels = c("Before-slope", "After-slope", "Shift"))
      more_effects$outcome <- factor(c(df_outcomes[outcome, "maj"]))
      more_effects$sample <- factor(c(c("LISS", "HRS")[j]))
      more_effects$comparison <- factor(c(c("Parents", "Nonparents")[k]))
      # bind with all effects created in previous loops
      effects_basic <- rbind(effects_basic, more_effects)
      }
    }
  }
}
# a single grouping factor turned out easier to handle
effects_basic$analysissample <- paste(effects_basic$sample, effects_basic$comparison)
effects_basic$analysissample <- factor(effects_basic$analysissample, 
                                       levels = c("LISS Parents", "LISS Nonparents", 
                                                  "HRS Parents", "HRS Nonparents"))
# more intuitive label (appears in legend later)
levels(effects_basic$analysissample) <- c("LISS: Grandparents vs. Parents", 
                                          "LISS: Grandparents vs. Nonparents", 
                                          "HRS: Grandparents vs. Parents", 
                                          "HRS: Grandparents vs. Nonparents")

ggplot(effects_basic, aes(x = fct_rev(parameter), y = est, colour = fct_rev(analysissample), 
                          group = fct_rev(analysissample))) +
  geom_hline(yintercept=0) +
  geom_point(aes(color = fct_rev(analysissample), shape = fct_rev(analysissample)), 
             size=2, position=position_dodge(0.4)) + 
  geom_errorbar(aes(ymin = lwr, ymax = upr), width=.3, position=position_dodge(0.4)) +
  facet_wrap( ~ outcome, ncol = 6) +
  theme_bw() + 
  scale_shape_manual(values=c(18,17,16,15))+
  scale_color_manual(values=c("#009E73", "#56B4E9", "#E69F00", "#000000"))+
  ylab("Unstandardized Effect Size (95% CI)") +
  xlab("") +
  theme(legend.position="top") +
  guides(colour = guide_legend(reverse = TRUE, ncol=1), shape = guide_legend(reverse = TRUE, ncol=1)) + 
  theme(legend.title=element_blank()) +
  theme(legend.text=element_text(size=12)) +
  coord_flip() +
  theme(strip.text.x = element_text(size = 8)) +
  theme(axis.text.x=element_text(size=7), axis.text.y=element_text(size=12))
```

(ref:effects-gender-plot-cap) Unstandardized Effect Sizes of the Models Including the Gender Interaction Across Analysis Samples (Regression Coefficients $\hat{\gamma}$ or Linear Contrasts $\hat{\gamma}_{c}$ From Multilevel Models, see Tables \@ref(tab:H1-agree-gender-tab), \@ref(tab:H1-agree-gender-contrasts), \@ref(tab:H1-con-gender-tab), \@ref(tab:H1-con-gender-contrasts), \@ref(tab:H1-extra-gender-tab), \@ref(tab:H1-extra-gender-contrasts), \@ref(tab:H1-neur-gender-tab), \@ref(tab:H1-neur-gender-contrasts), \@ref(tab:H1-open-gender-tab), \@ref(tab:H1-open-gender-contrasts), \@ref(tab:H1-swls-gender-tab), \@ref(tab:H1-swls-gender-contrasts)). Error Bars Represent 95% Confidence Intervals.

```{r effects-gender-plot, fig.cap = "(ref:effects-gender-plot-cap)", fig.height=9, fig.width=8, cache=T}
# next, for moderation by gender, I want grandfathers vs. male controls, grandmothers vs. female controls,
# and grandfathers vs. grandmothers
effects_gender <- summary(agree_liss_parents_gender_test)$coefficients[c("before:grandparent", 
                                                                         "after:grandparent"), 
                                                                       c("Estimate", "Std. Error")]
colnames(effects_gender) <- c("est", "err")
# compute 95% CIs
effects_gender <- effects_gender %>% as.data.frame() %>% mutate(
  lwr = est - qnorm(.975)*err,
  upr = est + qnorm(.975)*err,
) %>% dplyr::select(-err)
# add shift effect from contrast object (plus all the other gender comparisons...)
effects_gender <- rbind(effects_gender, 
                        contrasts_agree_liss_parents_gender[c("shift_gp_vs_control_men",
                                                              "before_gp_vs_control_women",
                                                              "after_gp_vs_control_women",
                                                              "shift_gp_vs_control_women",
                                                              "before_male_vs_female_gp",
                                                              "after_male_vs_female_gp",
                                                              "shift_male_vs_female_gp"), 
                                                            c("est", "lwr", "upr")])
rownames(effects_gender) <- NULL
# add descriptive factor variables for later ggplot use 
effects_gender$parameter <- factor(c("Before-slope\n(grandfathers vs.\nmale controls)", 
                                     "After-slope\n(grandfathers vs.\nmale controls)", 
                                     "Shift\n(grandfathers vs.\nmale controls)",
                                     "Before-slope\n(grandmothers vs.\nfemale controls)", 
                                     "After-slope\n(grandmothers vs.\nfemale controls)", 
                                     "Shift\n(grandmothers vs.\nfemale controls)",
                                     "Before-slope\n(grandfathers vs.\ngrandmothers)", 
                                     "After-slope\n(grandfathers vs.\ngrandmothers)", 
                                     "Shift\n(grandfathers vs.\ngrandmothers)"),
                                   levels = c("Before-slope\n(grandfathers vs.\nmale controls)", 
                                              "After-slope\n(grandfathers vs.\nmale controls)", 
                                              "Shift\n(grandfathers vs.\nmale controls)",
                                              "Before-slope\n(grandmothers vs.\nfemale controls)", 
                                              "After-slope\n(grandmothers vs.\nfemale controls)", 
                                              "Shift\n(grandmothers vs.\nfemale controls)",
                                              "Before-slope\n(grandfathers vs.\ngrandmothers)", 
                                              "After-slope\n(grandfathers vs.\ngrandmothers)", 
                                              "Shift\n(grandfathers vs.\ngrandmothers)"))
effects_gender$outcome <- factor(c(df_outcomes["agree", "maj"]))
effects_gender$sample <- factor(c("LISS"))
effects_gender$comparison <- factor(c("Parents"))

for (i in 1:length(outcomes)){
  outcome = outcomes[i]
  for (j in 1:length(c("liss", "hrs"))){
    panel = c("liss", "hrs")[j]
    for (k in 1:length(c("parents", "nonparents"))){
      comp = c("parents", "nonparents")[k]
      model = get(paste(outcome, panel, comp, "gender_test", sep = "_"))
      # all but first one (which we already created above)
      if (paste(outcome, panel, comp, "gender_test", sep = "_")!="agree_liss_parents_gender_test"){ 
        # grab effects from previously saved models
        more_effects_gender <- summary(model)$coefficients[c("before:grandparent", "after:grandparent"), 
                                                           c("Estimate", "Std. Error")]
        colnames(more_effects_gender) <- c("est", "err")
        # compute 95% CIs
        more_effects_gender <- more_effects_gender %>% as.data.frame() %>% mutate(
          lwr = est - qnorm(.975)*err,
          upr = est + qnorm(.975)*err,
        ) %>% dplyr::select(-err)
        # add shift effect from contrast object (& other gender comparisons)
        contrast = get(paste("contrasts", outcome, panel, comp, "gender", sep = "_"))
        more_effects_gender <- rbind(more_effects_gender, 
                              contrast[c("shift_gp_vs_control_men",
                                         "before_gp_vs_control_women",
                                         "after_gp_vs_control_women",
                                         "shift_gp_vs_control_women",
                                         "before_male_vs_female_gp",
                                         "after_male_vs_female_gp",
                                         "shift_male_vs_female_gp"), 
                                       c("est", "lwr", "upr")])
        rownames(more_effects_gender) <- NULL
        # add descriptive factor variables for later ggplot use 
        more_effects_gender$parameter <- factor(c("Before-slope\n(grandfathers vs.\nmale controls)", 
                                                  "After-slope\n(grandfathers vs.\nmale controls)", 
                                                  "Shift\n(grandfathers vs.\nmale controls)",
                                                  "Before-slope\n(grandmothers vs.\nfemale controls)", 
                                                  "After-slope\n(grandmothers vs.\nfemale controls)", 
                                                  "Shift\n(grandmothers vs.\nfemale controls)",
                                                  "Before-slope\n(grandfathers vs.\ngrandmothers)", 
                                                  "After-slope\n(grandfathers vs.\ngrandmothers)", 
                                                  "Shift\n(grandfathers vs.\ngrandmothers)"),
                                         levels = c("Before-slope\n(grandfathers vs.\nmale controls)", 
                                                    "After-slope\n(grandfathers vs.\nmale controls)", 
                                                    "Shift\n(grandfathers vs.\nmale controls)",
                                                    "Before-slope\n(grandmothers vs.\nfemale controls)",
                                                    "After-slope\n(grandmothers vs.\nfemale controls)", 
                                                    "Shift\n(grandmothers vs.\nfemale controls)",
                                                    "Before-slope\n(grandfathers vs.\ngrandmothers)", 
                                                    "After-slope\n(grandfathers vs.\ngrandmothers)", 
                                                    "Shift\n(grandfathers vs.\ngrandmothers)"))
        more_effects_gender$outcome <- factor(c(df_outcomes[outcome, "maj"]))
        more_effects_gender$sample <- factor(c(c("LISS", "HRS")[j]))
        more_effects_gender$comparison <- factor(c(c("Parents", "Nonparents")[k]))
        # bind with all effects created in previous loops
        effects_gender <- rbind(effects_gender, more_effects_gender)
      }
    }
  }
}
# a single grouping factor turned out easier to handle
effects_gender$analysissample <- paste(effects_gender$sample, effects_gender$comparison)
effects_gender$analysissample <- factor(effects_gender$analysissample, 
                                        levels = c("LISS Parents", "LISS Nonparents", 
                                                   "HRS Parents", "HRS Nonparents"))
# more intuitive label (appears in legend later)
levels(effects_gender$analysissample) <- c("LISS: Grandparents vs. Parents", 
                                           "LISS: Grandparents vs. Nonparents",
                                           "HRS: Grandparents vs. Parents", 
                                           "HRS: Grandparents vs. Nonparents")

ggplot(effects_gender, aes(x = fct_rev(parameter), y = est, colour = fct_rev(analysissample), 
                           group = fct_rev(analysissample))) +
  geom_hline(yintercept=0) +
  geom_point(aes(color = fct_rev(analysissample), shape = fct_rev(analysissample)), 
             size=2, position=position_dodge(0.4)) + 
  geom_errorbar(aes(ymin = lwr, ymax = upr), width=.3, position=position_dodge(0.4)) +
  facet_wrap( ~ outcome, ncol = 6) +
  theme_bw() + 
  scale_shape_manual(values=c(18,17,16,15))+
  scale_color_manual(values=c("#009E73", "#56B4E9", "#E69F00", "#000000"))+
  ylab("Unstandardized Effect Size (95% CI)") +
  xlab("") +
  theme(legend.position="top") +
  guides(colour = guide_legend(reverse = TRUE, ncol=1), shape = guide_legend(reverse = TRUE, ncol=1)) + 
  theme(legend.title=element_blank()) +
  theme(legend.text=element_text(size=12)) +
  coord_flip() +
  geom_vline(xintercept = c(3.5, 6.5), linetype=3) + 
  theme(strip.text.x = element_text(size = 8)) +
  theme(axis.text.x=element_text(size=7), axis.text.y=element_text(size=12))
```

### Agreeableness

In the basic models, we found no evidence that grandparents increased in agreeableness as compared to the controls (see Tables \@ref(tab:H1-agree-tab) & \@ref(tab:H1-agree-contrasts) and Figure \@ref(fig:H1-agree-fig)). The models including the gender interaction (see Tables \@ref(tab:H1-agree-gender-tab) & \@ref(tab:H1-agree-gender-contrasts) and Figure \@ref(fig:H1-agree-fig)) indicated that grandfathers increased slightly in agreeableness after the transition to grandparenthood as compared to the parent controls (LISS: `r agree_liss_parents_gender_summary$estimate$after_grandparent`, `r agree_liss_parents_gender_p["after:grandparent",]`; suggestive evidence in the HRS: `r agree_hrs_parents_gender_summary$estimate$after_grandparent`, `r agree_hrs_parents_gender_p["after:grandparent",]`), whereas grandmothers did not differ from the female controls.  
There was no consistent evidence for moderation by paid work (see Tables \@ref(tab:H1-agree-work-tab) & \@ref(tab:H1-agree-work-contrasts) and Figure \@ref(fig:H1-agree-work-fig)), providing substantial grandchild care (see Tables \@ref(tab:H1-agree-care-tab) & \@ref(tab:H1-agree-care-contrasts) and Figure \@ref(fig:H1-agree-care-fig)), or race/ethnicity (see Tables \@ref(tab:H1-agree-race-tab) & \@ref(tab:H1-agree-race-contrasts) and Figure \@ref(fig:H1-agree-race-fig)).  

(ref:H1-agree-fig-cap) Change trajectories of `r df_outcomes["agree", "min"]` based on the basic models (left column) and the models including the gender interaction (right column). The error bars are 95% confidence intervals of the predicted values, which only account for the fixed-effects portion of the model. The vertical line indicates the approximate time of the transition to grandparenthood.

```{r H1-agree-fig, fig.cap = "(ref:H1-agree-fig-cap)", fig.height=9, fig.width=7, cache=T}
# extract the legends
legend_parents <- get_legend(plot_agree_liss_parents_gender + 
                               theme(legend.box.margin = margin(0, 0, 0, 20)))
legend_nonparents <- get_legend(plot_agree_liss_nonparents_gender + 
                                  theme(legend.box.margin = margin(0, 0, 0, 20)))

# add the legend to the row we made earlier - adjust width via rel_widths
grid_agree_liss <- cowplot::plot_grid(
  plot_agree_liss_parents, 
  plot_agree_liss_parents_gender + theme(legend.position="none"),
  plot_agree_liss_nonparents, 
  plot_agree_liss_nonparents_gender + theme(legend.position="none"), 
  align = "vh", ncol = 2)
grid_agree_liss <- cowplot::plot_grid(
  grid_agree_liss, 
  cowplot::plot_grid(legend_parents, legend_nonparents, ncol = 1),
  rel_widths = c(3, .75), ncol = 2)

grid_agree_hrs <- cowplot::plot_grid(
  plot_agree_hrs_parents, 
  plot_agree_hrs_parents_gender + theme(legend.position="none"),
  plot_agree_hrs_nonparents, 
  plot_agree_hrs_nonparents_gender + theme(legend.position="none"), 
  align = "vh", ncol = 2)
grid_agree_hrs <- cowplot::plot_grid(
  grid_agree_hrs, 
  cowplot::plot_grid(legend_parents, legend_nonparents, ncol = 1),
  rel_widths = c(3, .75), ncol = 2)

# now add the title
title_liss <- ggdraw() + 
  draw_label("LISS", fontface = 'bold', x = 0, hjust = 0) +
  theme(plot.margin = margin(0, 0, 0, 7))
title_HRS <- ggdraw() + 
  draw_label("HRS", fontface = 'bold', x = 0, hjust = 0) +
  theme(plot.margin = margin(0, 0, 0, 7))

# print final object
plot_grid(title_liss, grid_agree_liss, title_HRS, grid_agree_hrs, 
          ncol = 1, rel_heights = c(0.1, 1, 0.1, 1))
```

(ref:H1-agree-gender-tab-cap) Fixed Effects of `r df_outcomes["agree", "maj"]` Over the Transition to Grandparenthood Moderated by Gender.
(ref:H1-agree-gender-tab-note) Two models were computed for each of the two samples (LISS, HRS): grandparents matched with parent controls and with nonparent controls. CI = confidence interval.

```{r H1-agree-gender-tab, results="asis"}
agree_gender_liss_df <- 
  cbind(printnum(agree_liss_parents_gender_summary$table)[, -1],   # parents: estimate, CI, t-value
        summary(agree_liss_parents_gender_test)$coefficients[, 5], # parents: p-value
        printnum(agree_liss_nonparents_gender_summary$table)[, -1],    # nonparents: estimate, CI, t-value
        summary(agree_liss_nonparents_gender_test)$coefficients[, 5])  # nonparents: p-value

agree_gender_hrs_df <- 
  cbind(printnum(agree_hrs_parents_gender_summary$table)[, -1],   # parents: estimate, CI, t-value
        summary(agree_hrs_parents_gender_test)$coefficients[, 5], # parents: p-value
        printnum(agree_hrs_nonparents_gender_summary$table)[, -1],    # nonparents: estimate, CI, t-value
        summary(agree_hrs_nonparents_gender_test)$coefficients[, 5])  # nonparents: p-value

# make one large table
colnames(agree_gender_liss_df)[c(4,8)] <- c("p", "p")
colnames(agree_gender_hrs_df)[c(4,8)] <- c("p", "p")
agree_gender_df <- rbind(agree_gender_liss_df, agree_gender_hrs_df)

# duplicate rownames are apparently forbidden - I circumvent this by adding a white letter to duplicates
rownames_agree_gender_df <- c("Intercept, $\\hat{\\gamma}_{00}$ \\textcolor{white}{L}", # LISS
                      "Propensity score, $\\hat{\\gamma}_{04}$ \\textcolor{white}{L}", 
                      "Before-slope, $\\hat{\\gamma}_{10}$ \\textcolor{white}{L}", 
                      "After-slope, $\\hat{\\gamma}_{20}$ \\textcolor{white}{L}", 
                      "Shift, $\\hat{\\gamma}_{30}$ \\textcolor{white}{L}",
                      "Grandparent, $\\hat{\\gamma}_{01}$ \\textcolor{white}{L}", 
                      "Female, $\\hat{\\gamma}_{02}$ \\textcolor{white}{L}", 
                      "Before-slope * Grandparent, $\\hat{\\gamma}_{11}$ \\textcolor{white}{L}", 
                      "After-slope * Grandparent, $\\hat{\\gamma}_{21}$ \\textcolor{white}{L}", 
                      "Shift * Grandparent, $\\hat{\\gamma}_{31}$ \\textcolor{white}{L}",
                      "Before-slope * Female, $\\hat{\\gamma}_{12}$ \\textcolor{white}{L}", 
                      "After-slope * Female, $\\hat{\\gamma}_{22}$ \\textcolor{white}{L}", 
                      "Shift * Female, $\\hat{\\gamma}_{32}$ \\textcolor{white}{L}",
                      "Grandparent * Female, $\\hat{\\gamma}_{03}$ \\textcolor{white}{L}", 
                      "Before-slope * Grandparent * Female, $\\hat{\\gamma}_{13}$ \\textcolor{white}{L}", 
                      "After-slope * Grandparent * Female, $\\hat{\\gamma}_{23}$ \\textcolor{white}{L}", 
                      "Shift * Grandparent * Female, $\\hat{\\gamma}_{33}$ \\textcolor{white}{L}",
                      "Intercept, $\\hat{\\gamma}_{00}$ \\textcolor{white}{H}", # HRS
                      "Propensity score, $\\hat{\\gamma}_{04}$ \\textcolor{white}{H}", 
                      "Before-slope, $\\hat{\\gamma}_{10}$ \\textcolor{white}{H}", 
                      "After-slope, $\\hat{\\gamma}_{20}$ \\textcolor{white}{H}", 
                      "Shift, $\\hat{\\gamma}_{30}$ \\textcolor{white}{H}",
                      "Grandparent, $\\hat{\\gamma}_{01}$ \\textcolor{white}{H}", 
                      "Female, $\\hat{\\gamma}_{02}$ \\textcolor{white}{H}", 
                      "Before-slope * Grandparent, $\\hat{\\gamma}_{11}$ \\textcolor{white}{H}", 
                      "After-slope * Grandparent, $\\hat{\\gamma}_{21}$ \\textcolor{white}{H}", 
                      "Shift * Grandparent, $\\hat{\\gamma}_{31}$ \\textcolor{white}{H}",
                      "Before-slope * Female, $\\hat{\\gamma}_{12}$ \\textcolor{white}{H}", 
                      "After-slope * Female, $\\hat{\\gamma}_{22}$ \\textcolor{white}{H}", 
                      "Shift * Female, $\\hat{\\gamma}_{32}$ \\textcolor{white}{H}",
                      "Grandparent * Female, $\\hat{\\gamma}_{03}$ \\textcolor{white}{H}", 
                      "Before-slope * Grandparent * Female, $\\hat{\\gamma}_{13}$ \\textcolor{white}{H}", 
                      "After-slope * Grandparent * Female, $\\hat{\\gamma}_{23}$ \\textcolor{white}{H}", 
                      "Shift * Grandparent * Female, $\\hat{\\gamma}_{33}$ \\textcolor{white}{H}")
rownames(agree_gender_df) <- rownames_agree_gender_df

apa_table(
  agree_gender_df
  , caption = "(ref:H1-agree-gender-tab-cap)"
  , note = "(ref:H1-agree-gender-tab-note)"
  , col.names = c("Parameter", 
                  "$\\hat{\\gamma}$", "95\\% CI", "$t$", "$p$", 
                  "$\\hat{\\gamma}$", "95\\% CI", "$t$", "$p$")
  , align = c("l", "r", "c", "r", "r", "r", "c", "r", "r")
  , format.args = list(gt1 = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE),
                       digits = c(2,2,2,2,3,2,2,2,3),
                       zero = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE))
  , col_spanners = list("Parent controls" = c(2,5), "Nonparent controls" = c(6,9))
  #, stub_indents = list("Fixed effects" = 1:12)
  , escape = F
  , landscape = T
  , font_size = "footnotesize"
  , stub_indents = list("LISS" = 1:17, "HRS" = 18:34)
  , placement = "H"
)
```

### Conscientiousness

We found no differences between grandparents and both parent and nonparent controls in their trajectories of conscientiousness (see Tables \@ref(tab:H1-con-tab) & \@ref(tab:H1-con-contrasts) and Figure \@ref(fig:H1-con-fig)). There was only inconsistent evidence for gender moderation (see Tables \@ref(tab:H1-con-gender-tab) & \@ref(tab:H1-con-gender-contrasts) and Figure \@ref(fig:H1-con-fig)): Grandfathers' conscientiousness decreased immediately following the transition to grandparenthood as compared to male nonparents in the HRS, `r contrasts_gender_con$hrs_nonparents["shift_gp_vs_control_men", "all"]`, but not in any of the other three analysis samples.  
There were significant differences in conscientiousness trajectories depending on grandparents' work status (see Tables \@ref(tab:H1-con-work-tab) & \@ref(tab:H1-con-work-contrasts) and Figure \@ref(fig:H1-con-work-fig)): non-working grandparents saw more pronounced increases in conscientiousness in the years before the transition to grandparenthood compared to non-working parents, `r con_hrs_parents_work_summary$estimate$before_grandparent`, `r con_hrs_parents_work_p["before:grandparent",]`, and nonparent controls, `r con_hrs_nonparents_work_summary$estimate$before_grandparent`, `r con_hrs_nonparents_work_p["before:grandparent",]`, and compared to working grandparents (difference in *before* parameter; parents: `r contrasts_work_con$hrs_parents["before_nowork_vs_work_gp", "all"]`; nonparents: `r contrasts_work_con$hrs_nonparents["before_nowork_vs_work_gp", "all"]`). Grandparents providing substantial grandchild care increased in conscientiousness to a greater degree than the matched controls (difference in *after* parameter; parents: `r contrasts_care_con$hrs_parents["after_gp_vs_control_care", "all"]`; nonparents: `r contrasts_care_con$hrs_nonparents["after_gp_vs_control_care", "all"]`; see Tables \@ref(tab:H1-con-care-tab) & \@ref(tab:H1-con-care-contrasts) and Figure \@ref(fig:H1-con-care-fig)). There was only suggestive evidence that grandparents who provided substantial grandchild care increased more strongly in conscientiousness after the transition than grandparents who did not (difference in *after* parameter; parents: `r contrasts_care_con$hrs_parents["after_nocare_vs_care_gp", "all"]`; nonparents: `r contrasts_care_con$hrs_nonparents["after_nocare_vs_care_gp", "all"]`). Conscientiousness trajectories were not moderated by race/ethnicity (see Tables \@ref(tab:H1-con-race-tab) & \@ref(tab:H1-con-race-contrasts) and Figure \@ref(fig:H1-con-race-fig)). 

### Extraversion

The trajectories of grandparents' extraversion closely followed those of the matched controls. There were no significant effects indicating differences between grandparents and

(ref:H1-con-work-tab-cap) Fixed Effects of `r df_outcomes["con", "maj"]` Over the Transition to Grandparenthood Moderated by Performing Paid Work.
(ref:H1-con-work-tab-note) Two models were computed (only HRS): grandparents matched with parent controls and with nonparent controls. CI = confidence interval. $working=1$ indicates being employed in paid work.

```{r H1-con-work-tab, results="asis"}
con_work_df <- 
  cbind(printnum(con_hrs_parents_work_summary$table)[, -1],   # parents: estimate, CI, t-value
        summary(con_hrs_parents_work_test)$coefficients[, 5], # parents: p-value
        printnum(con_hrs_nonparents_work_summary$table)[, -1],    # nonparents: estimate, CI, t-value
        summary(con_hrs_nonparents_work_test)$coefficients[, 5])  # nonparents: p-value

colnames(con_work_df)[c(4,8)] <- c("p", "p")

rownames_work <- c("Intercept, $\\hat{\\gamma}_{00}$",
                      "Propensity score, $\\hat{\\gamma}_{02}$", 
                      "Before-slope, $\\hat{\\gamma}_{20}$", 
                      "After-slope, $\\hat{\\gamma}_{40}$", 
                      "Shift, $\\hat{\\gamma}_{60}$",
                      "Grandparent, $\\hat{\\gamma}_{01}$", 
                      "Working, $\\hat{\\gamma}_{10}$", 
                      "Before-slope * Grandparent, $\\hat{\\gamma}_{21}$", 
                      "After-slope * Grandparent, $\\hat{\\gamma}_{41}$", 
                      "Shift * Grandparent, $\\hat{\\gamma}_{61}$",
                      "Before-slope * Working, $\\hat{\\gamma}_{30}$", 
                      "After-slope * Working, $\\hat{\\gamma}_{50}$", 
                      "Shift * Working, $\\hat{\\gamma}_{70}$",
                      "Grandparent * Working, $\\hat{\\gamma}_{11}$", 
                      "Before-slope * Grandparent * Working, $\\hat{\\gamma}_{31}$", 
                      "After-slope * Grandparent * Working, $\\hat{\\gamma}_{51}$", 
                      "Shift * Grandparent * Working, $\\hat{\\gamma}_{71}$")
rownames(con_work_df) <- rownames_work # defined above (agree)

apa_table(
  con_work_df
  , caption = "(ref:H1-con-work-tab-cap)"
  , note = "(ref:H1-con-work-tab-note)"
  , col.names = c("Parameter", 
                  "$\\hat{\\gamma}$", "95\\% CI", "$t$", "$p$", 
                  "$\\hat{\\gamma}$", "95\\% CI", "$t$", "$p$")
  , align = c("l", "r", "c", "r", "r", "r", "c", "r", "r")
  , format.args = list(gt1 = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE),
                       digits = c(2,2,2,2,3,2,2,2,3),
                       zero = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE))
  , col_spanners = list("Parent controls" = c(2,5), "Nonparent controls" = c(6,9))
  #, stub_indents = list("Fixed effects" = 1:12)
  , escape = F
  , landscape = T
  , font_size = "footnotesize"
  , placement = "H"
)
```

(ref:H1-con-work-fig-cap) Change trajectories of `r df_outcomes["con", "min"]` based on the models of moderation by paid work (see Table \@ref(tab:H1-con-work-tab)). The error bars are 95% confidence intervals of the predicted values, which only account for the fixed-effects portion of the model. The vertical line indicates the approximate time of the transition to grandparenthood. The plots in the left column are the same as in Figure \@ref(fig:H1-con-fig) (basic models) and added here for better comparability.

```{r H1-con-work-fig, fig.cap = "(ref:H1-con-work-fig-cap)", fig.height=6, fig.width=7, cache=T}
# extract the legends
legend_work_parents <- get_legend(plot_con_hrs_parents_work + 
                               theme(legend.box.margin = margin(0, 0, 0, 20)))
legend_work_nonparents <- get_legend(plot_con_hrs_nonparents_work + 
                                  theme(legend.box.margin = margin(0, 0, 0, 20)))

# add the legend to the row we made earlier - adjust width via rel_widths
grid_con_work <- cowplot::plot_grid(
  plot_con_hrs_parents, 
  plot_con_hrs_parents_work + theme(legend.position="none"),
  plot_con_hrs_nonparents, 
  plot_con_hrs_nonparents_work + theme(legend.position="none"), 
  align = "vh", ncol = 2)
grid_con_work <- cowplot::plot_grid(
  grid_con_work, 
  cowplot::plot_grid(legend_work_parents, legend_work_nonparents, ncol = 1),
  rel_widths = c(3, .75), ncol = 2)

# now add the title
title_HRS <- ggdraw() + 
  draw_label("HRS", fontface = 'bold', x = 0, hjust = 0) +
  theme(plot.margin = margin(0, 0, 0, 7))

# print final object
plot_grid(title_HRS, grid_con_work, 
          ncol = 1, rel_heights = c(0.1, 1, 0.1, 1))
```

(ref:H1-con-care-tab-cap) Fixed Effects of `r df_outcomes["con", "maj"]` Over the Transition to Grandparenthood Moderated by Grandchild Care.
(ref:H1-con-care-tab-note) Two models were computed (only HRS): grandparents matched with parent controls and with nonparent controls. CI = confidence interval. $caring=1$ indicates more than 100 hours of grandchild care since the last assessment.

```{r H1-con-care-tab, results="asis"}
con_care_df <- 
  cbind(printnum(con_hrs_parents_care_summary$table)[, -1],   # parents: estimate, CI, t-value
        summary(con_hrs_parents_care_test)$coefficients[, 5], # parents: p-value
        printnum(con_hrs_nonparents_care_summary$table)[, -1],    # nonparents: estimate, CI, t-value
        summary(con_hrs_nonparents_care_test)$coefficients[, 5])  # nonparents: p-value

colnames(con_care_df)[c(4,8)] <- c("p", "p")

rownames_care_df <- c("Intercept, $\\hat{\\gamma}_{00}$",
                      "Propensity score, $\\hat{\\gamma}_{02}$", 
                      "After-slope, $\\hat{\\gamma}_{20}$", 
                      "Grandparent, $\\hat{\\gamma}_{01}$", 
                      "Caring, $\\hat{\\gamma}_{10}$", 
                      "After-slope * Grandparent, $\\hat{\\gamma}_{21}$", 
                      "After-slope * Caring, $\\hat{\\gamma}_{30}$", 
                      "Grandparent * Caring, $\\hat{\\gamma}_{11}$", 
                      "After-slope * Grandparent * Caring, $\\hat{\\gamma}_{31}$")
rownames(con_care_df) <- rownames_care_df 

apa_table(
  con_care_df
  , caption = "(ref:H1-con-care-tab-cap)"
  , note = "(ref:H1-con-care-tab-note)"
  , col.names = c("Parameter", 
                  "$\\hat{\\gamma}$", "95\\% CI", "$t$", "$p$", 
                  "$\\hat{\\gamma}$", "95\\% CI", "$t$", "$p$")
  , align = c("l", "r", "c", "r", "r", "r", "c", "r", "r")
  , format.args = list(gt1 = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE),
                       digits = c(2,2,2,2,3,2,2,2,3),
                       zero = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE))
  , col_spanners = list("Parent controls" = c(2,5), "Nonparent controls" = c(6,9))
  , escape = F
  , landscape = T
  , font_size = "footnotesize"
  , placement = "H"
)
```

(ref:H1-con-care-fig-cap) Change trajectories of `r df_outcomes["con", "min"]` based on the models of moderation by grandchild care (see Table \@ref(tab:H1-con-care-tab)). The error bars are 95% confidence intervals of the predicted values, which only account for the fixed-effects portion of the model. The plots in the left column are the same as in Figure \@ref(fig:H1-con-fig) (basic models) but restricted to the post-transition period for better comparability.

```{r H1-con-care-fig, fig.cap = "(ref:H1-con-care-fig-cap)", fig.height=6, fig.width=7, cache=T}
# extract the legends 
legend_care_parents <- get_legend(plot_con_hrs_parents_care + 
                               theme(legend.box.margin = margin(0, 0, 0, 20)))
legend_care_nonparents <- get_legend(plot_con_hrs_nonparents_care + 
                                  theme(legend.box.margin = margin(0, 0, 0, 20)))

# add the legend to the row we made earlier - adjust width via rel_widths
grid_con_care <- cowplot::plot_grid(
  plot_con_hrs_parents_short + theme(legend.position="none"), 
  plot_con_hrs_parents_care + theme(legend.position="none"),
  plot_con_hrs_nonparents_short + theme(legend.position="none"), 
  plot_con_hrs_nonparents_care + theme(legend.position="none"), 
  align = "vh", ncol = 2)
grid_con_care <- cowplot::plot_grid(
  grid_con_care, 
  cowplot::plot_grid(legend_care_parents, legend_care_nonparents, ncol = 1),
  rel_widths = c(3, .80), ncol = 2)

# now add the title
title_HRS <- ggdraw() + 
  draw_label("HRS", fontface = 'bold', x = 0, hjust = 0) +
  theme(plot.margin = margin(0, 0, 0, 7))

# print final object
plot_grid(title_HRS, grid_con_care, 
          ncol = 1, rel_heights = c(0.1, 1, 0.1, 1))
```

\noindent controls in the basic models (see Tables \@ref(tab:H1-extra-tab) & \@ref(tab:H1-extra-contrasts) and Figure \@ref(fig:H1-extra-fig)) or the models including the gender interaction (see Tables \@ref(tab:H1-extra-gender-tab) & \@ref(tab:H1-extra-gender-contrasts) and Figure \@ref(fig:H1-extra-fig)). We also found no evidence for moderation by paid work (see Tables \@ref(tab:H1-extra-work-tab) & \@ref(tab:H1-extra-work-contrasts) and Figure \@ref(fig:H1-extra-work-fig)), grandchild care (see Tables \@ref(tab:H1-extra-care-tab) & \@ref(tab:H1-extra-care-contrasts) and Figure \@ref(fig:H1-extra-care-fig)), or race/ethnicity (see Tables \@ref(tab:H1-extra-race-tab) & \@ref(tab:H1-extra-race-contrasts) and Figure \@ref(fig:H1-extra-race-fig)).  

### Neuroticism

The basic models for neuroticism (see Tables \@ref(tab:H1-neur-tab) & \@ref(tab:H1-neur-contrasts) and Figure \@ref(fig:H1-neur-fig)) showed only minor differences between grandparents and matched controls: Compared to HRS parent controls, HRS grandparents shifted slightly downward in their neuroticism immediately after the transition to grandparenthood (difference in *shift* parameter: `r contrasts_neur$hrs_parents["shift_gp_vs_control", "all"]`; suggestive evidence in the nonparent sample: `r contrasts_neur$hrs_nonparents["shift_gp_vs_control", "all"]`), which was not the case in the LISS samples. The models including the gender interaction (see Tables \@ref(tab:H1-neur-gender-tab) & \@ref(tab:H1-neur-gender-contrasts) and Figure \@ref(fig:H1-neur-fig)) showed one significant effect in the comparison of grandparents and controls: In the HRS, grandfathers, compared to male parent controls, shifted downward in neuroticism directly after the transition to grandparenthood (difference in *shift* parameter: `r contrasts_gender_neur$hrs_parents["shift_gp_vs_control_men", "all"]`). Thus, the effect present in the basic models seemed to be mostly due to differences in the grandfathers (vs. male controls).  
Grandparents' trajectories of neuroticism as compared to the controls were significantly moderated by paid work in one instance (see Tables \@ref(tab:H1-neur-work-tab) & \@ref(tab:H1-neur-work-contrasts) and Figure \@ref(fig:H1-neur-work-fig)): Compared to working controls, working grandparents increased more strongly in neuroticism in the years before the transition to grandparenthood (difference in *before* parameter; parents: `r contrasts_work_neur$hrs_parents["before_gp_vs_control_work", "all"]`; nonparents: `r contrasts_work_neur$hrs_nonparents["before_gp_vs_control_work", "all"]`). There was no evidence that grandparents providing substantial grandchild care differed in neuroticism from grandparents who did not (see Tables \@ref(tab:H1-neur-care-tab) & \@ref(tab:H1-neur-care-contrasts) and Figure \@ref(fig:H1-neur-care-fig)). Neuroticism trajectories were not moderated by race/ethnicity (see Tables \@ref(tab:H1-neur-race-tab) & \@ref(tab:H1-neur-race-contrasts) and Figure \@ref(fig:H1-neur-race-fig)).  

### Openness

For openness, we found a high degree of similarity between grandparents and matched control respondents in their trajectories based on the basic models (see Tables \@ref(tab:H1-open-tab) & \@ref(tab:H1-open-contrasts) and Figure \@ref(fig:H1-open-fig)) and models including the gender interaction (see Tables \@ref(tab:H1-open-gender-tab) & \@ref(tab:H1-open-gender-contrasts) and Figure \@ref(fig:H1-open-fig)). Grandfathers in the HRS shifted downward in openness in the first assessment after the transition to grandparenthood to a greater extent than the male parent controls (difference in *shift* parameter: `r contrasts_gender_open$hrs_parents["shift_gp_vs_control_men", "all"]`). However, this was not the case in the other three analysis samples.  
The analysis of moderation by performing paid work revealed only one significant effect for openness trajectories (see Tables \@ref(tab:H1-open-work-tab) & \@ref(tab:H1-open-work-contrasts) and Figure \@ref(fig:H1-open-work-fig)): Non-working grandparents increased more strongly in openness post-transition than non-working parent controls (`r open_hrs_parents_work_summary$estimate$after_grandparent`, `r open_hrs_parents_work_p["after:grandparent",]`; suggestive evidence in the nonparent sample: `r open_hrs_nonparents_work_summary$estimate$after_grandparent`, `r open_hrs_nonparents_work_p["after:grandparent",]`). We found that grandparents providing substantial grandchild care increased more strongly in openness than matched parent controls (difference in *after* parameter: `r contrasts_care_open$hrs_parents["after_gp_vs_control_care", "all"]`; suggestive evidence in the nonparent sample: `r contrasts_care_open$hrs_nonparents["after_gp_vs_control_care", "all"]`). However, grandparents who provided substantial grandchild care did not differ significantly from grandparents who did not (see Tables \@ref(tab:H1-open-care-tab) & \@ref(tab:H1-open-care-contrasts) and Figure \@ref(fig:H1-open-care-fig)). We found no evidence for moderation of openness by race/ethnicity (see Tables \@ref(tab:H1-open-race-tab) & \@ref(tab:H1-open-race-contrasts) and Figure \@ref(fig:H1-open-race-fig)).  

### Life Satisfaction

We found no consistent evidence that grandparents' life satisfaction trajectories differed significantly from those of the controls in either the basic models (see Tables \@ref(tab:H1-swls-tab) & \@ref(tab:H1-swls-contrasts) and Figure \@ref(fig:H1-swls-fig)) or the models including the gender interaction (see Tables \@ref(tab:H1-swls-gender-tab) & \@ref(tab:H1-swls-gender-contrasts) and Figure \@ref(fig:H1-swls-fig)). There was also no evidence of a moderation of life satisfaction by performing paid work (see Tables \@ref(tab:H1-swls-work-tab) & \@ref(tab:H1-swls-work-contrasts) and Figure \@ref(fig:H1-swls-work-fig)) or grandchild care (see Tables \@ref(tab:H1-swls-care-tab) & \@ref(tab:H1-swls-care-contrasts) and Figure \@ref(fig:H1-swls-care-fig)).  
Black/African American grandparents increased to a higher degree in life satisfaction after the transition to grandparenthood than Black/African American nonparent controls (difference in *after* parameter: `r contrasts_race_swls$hrs_nonparents["after_gp_vs_control_black", "all"]`; suggestive evidence in the parent sample: `r contrasts_race_swls$hrs_parents["after_gp_vs_control_black", "all"]`; see Tables \@ref(tab:H1-swls-race-tab) & \@ref(tab:H1-swls-race-contrasts) and Figure \@ref(fig:H1-swls-race-fig)). In addition, there was suggestive evidence that Black/African American grandparents' post-transition increases were more pronounced than those of White grandparents (difference in *after* parameter; parents: `r contrasts_race_swls$hrs_parents["after_white_vs_black_gp", "all"]`; nonparents: `r contrasts_race_swls$hrs_nonparents["after_white_vs_black_gp", "all"]`). However, the model uncertainty regarding these effects was comparatively high.  

## Interindividual Differences in Change

First, we conducted model fit comparisons between the random intercept models reported previously and models where a random slope variance was estimated, separately for each change parameter because joint random effects modeling frequently led to model nonconvergence. These comparisons showed a substantial amount of interindividual differences in change for all random slopes in all models, as indicated by increases in model fit significant at `r anova_summaries$agree_lissanalysis_parents_comp$p[1]`.  
Second, we estimated models with heterogeneous random slope variances of the grandparents and each control group to test whether interindividual differences in change were significantly larger in the grandparents. Contrary to hypothesis H2, for agreeableness, conscientiousness, extraversion, and neuroticism, interindividual differences in intraindividual change were greater in the control group for all tested effects (see Tables \@ref(tab:H2-hetvar-tab-agree), \@ref(tab:H2-hetvar-tab-con), \@ref(tab:H2-hetvar-tab-extra), & \@ref(tab:H2-hetvar-tab-neur)). In the two HRS samples, assuming group heterogeneity in the random slope variances led to significant improvements in model fit in all model comparisons. In the two LISS samples, this was the case for around half the tests.  
For openness, interindividual differences in change before the transition to grandparenthood were significantly greater in the HRS grandparents than the nonparent controls (random slope variances of the *before* parameter), *likelihood ratio* = `r hetvar_summaries$open_hrsanalysis_nonparents_hetvar$lratio[1]`, `r hetvar_summaries$open_hrsanalysis_nonparents_hetvar$p[1]`. This result could not be replicated in the other three samples. The other parameters of change either did not differ between groups in their random slope variances or had significantly larger random slope variances in the respective control group (see Table \@ref(tab:H2-hetvar-tab-open)).  
We found larger interindividual differences in grandparents' changes in life satisfaction before the transition to grandparenthood compared to the nonparent controls in the HRS (random slope variances of the *before* parameter), *likelihood ratio* = `r hetvar_summaries$swls_hrsanalysis_nonparents_hetvar$lratio[1]`, `r hetvar_summaries$swls_hrsanalysis_nonparents_hetvar$p[1]` (see Table \@ref(tab:H2-hetvar-tab-swls)). This was not corroborated in the other three analysis samples. Overall, most tests for heterogeneous random slope variances in life satisfaction indicated either non-significant differences or significantly larger random slope variances in the control sample.  

## Rank-Order Stability 

We computed test-retest correlations for the Big Five and life satisfaction for the matched sample and separately for grandparents only and controls only (see Table \@ref(tab:H3-rankorder-tab)). In `r rank_order_df %>% filter(cor_gp<cor_con) %>% summarise(n())` out of `r rank_order_df %>% summarise(n())` comparisons, grandparents' test-retest correlation was lower than the respective control group's. However, differences in rank-order stability between grandparents and control respondents did not reach significance in any of these comparisons.<!-- We found suggestive evidence that the rank-order stability of extraversion in the HRS was higher in the grandparents than in either parent, `r gsub(scales::pvalue(rank_order_df["extra_hrs_parents_rank", "p"], prefix = c("$p$ < ", "$p$ = ", "$p$ > ")), pattern="0\\.", replacement="\\.")`, or nonparent controls, `r gsub(scales::pvalue(rank_order_df["extra_hrs_nonparents_rank", "p"], prefix = c("$p$ < ", "$p$ = ", "$p$ > ")), pattern="0\\.", replacement="\\.")`, and that for openness it was larger in the grandparents than in the parent controls, `r gsub(scales::pvalue(rank_order_df["open_hrs_parents_rank", "p"], prefix = c("$p$ < ", "$p$ = ", "$p$ > ")), pattern="0\\.", replacement="\\.")`. In the LISS, there was suggestive evidence that grandparents' rank-order stability in agreeableness was higher than that of the nonparent controls, `r gsub(scales::pvalue(rank_order_df["agree_liss_nonparents_rank", "p"], prefix = c("$p$ < ", "$p$ = ", "$p$ > ")), pattern="0\\.", replacement="\\.")`. --> Overall, we found no confirmatory evidence in support of hypothesis H3.[^f14]  

[^f14]: In addition to the preregistered retest interval, we computed a maximally large interval between the first available assessment before and the last assessment after the transition. Here, `r rank_order_df_max %>% filter(cor_gp<cor_con) %>% summarise(n())` out of `r rank_order_df_max %>% summarise(n())` comparisons indicated that rank-order stability was lower in the grandparents. There was only one significant difference supporting our hypothesis: HRS grandparents' rank-order stability in openness was lower than that of the nonparents, `r gsub(scales::pvalue(rank_order_df_max["open_hrs_nonparents_rank", "p"], prefix = c("$p$ < ", "$p$ = ", "$p$ > ")), pattern="0\\.", replacement="\\.")` (see Table \@ref(tab:H3-rankordermax-tab)). Another analysis also failed to provide convincing evidence that grandparents' rank-order stability was lower: We excluded duplicate control respondents resulting from matching with replacement who might bias results towards greater stability in the controls. Descriptively, `r rank_order_df_uni %>% filter(cor_gp<cor_con) %>% summarise(n())` out of `r rank_order_df_uni %>% summarise(n())` comparisons showed lower rank-order stability in the grandparents (see Table \@ref(tab:H3-rankorderuni-tab)). However, group differences were small and nonsignificant.  

(ref:H3-rankorder-tab-cap) Rank-Order Stability.

(ref:H3-rankorder-tab-note) Test-retest correlations as indicators of rank-order stability, and p-values indicating significant group differences therein between grandparents and each control group. The average retest intervals in years are `r printnum(mean(lissanalysis_parents_rank$yr_lag))` ($SD$ = `r printnum(sd(lissanalysis_parents_rank$yr_lag))`) for the LISS parent sample, `r printnum(mean(lissanalysis_nonparents_rank$yr_lag))` ($SD$ = `r printnum(sd(lissanalysis_nonparents_rank$yr_lag))`) for the LISS nonparent sample, `r printnum(mean(hrsanalysis_parents_rank$yr_lag))` ($SD$ = `r printnum(sd(hrsanalysis_parents_rank$yr_lag))`) for the HRS parent sample, and `r printnum(mean(hrsanalysis_nonparents_rank$yr_lag))` ($SD$ = `r printnum(sd(hrsanalysis_nonparents_rank$yr_lag))`) for the HRS nonparent sample. $Cor$ = correlation; $GP$ = grandparents; $con$ = controls.

```{r H3-rankorder-tab, results="asis"}
rank_order_df_ordered <- rbind(
  cbind(rank_order_df[seq(1, 24, 4), ], # LISS parents
        rank_order_df[seq(2, 24, 4), ]), # LISS nonparents
  cbind(rank_order_df[seq(3, 24, 4), ], # HRS parents
        rank_order_df[seq(4, 24, 4), ]) # HRS nonparents
)

# duplicate rownames are apparently forbidden - I circumvent this by adding a white letter to duplicates
rownames_rank_order_df <- c(paste(df_outcomes[outcomes, "maj"], "\\textcolor{white}{L}"),
                            paste(df_outcomes[outcomes, "maj"], "\\textcolor{white}{H}"))
rownames(rank_order_df_ordered) <- rownames_rank_order_df

apa_table(
  rank_order_df_ordered
  , caption = "(ref:H3-rankorder-tab-cap)"
  , note = "(ref:H3-rankorder-tab-note)"
  , col.names = c("Outcome", 
                  "$Cor_{all}$", "$Cor_{GP}$", "$Cor_{con}$", "$p$", 
                  "$Cor_{all}$", "$Cor_{GP}$", "$Cor_{con}$", "$p$")
  , align = c("l", "r", "r", "r", "r", "r", "r", "r", "r")
  , format.args = list(gt1 = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE),
                       digits = c(2,2,2,2,3,2,2,2,3),
                       zero = c(TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE))
  , col_spanners = list("Parent controls" = c(2,5), "Nonparent controls" = c(6,9))
  , escape = F
  , landscape = T
  , font_size = "small"
  , stub_indents = list("LISS" = 1:6, "HRS" = 7:12)
  , placement = "H"
)
```

# Discussion

In an analysis of first-time grandparents compared to both parent and nonparent matched control respondents, we found pronounced stability in the Big Five and life satisfaction over the transition to grandparenthood. There were a few isolated effects in line with our hypotheses on mean-level increases in agreeableness and conscientiousness, and decreases in neuroticism (H1a). However, they were very small in size, only present in grandfathers, and not consistent over the two analyzed panel studies (LISS and HRS) or the two matched control groups (parents and nonparents). We found no robust evidence that grandparents providing substantial grandchild care experienced more pronounced positive personality development than those who did not (H1b). Evidence for moderation of mean-level trajectories by performing paid work was inconsistent. There was no evidence that grandmothers (or grandfathers) reached higher levels of life satisfaction following the transition to grandparenthood (H1c). Although interindividual differences in change were present for all change parameters, they were only greater in the grandparents than the controls in a small minority of model comparisons (H2). Finally, rank-order stability did not differ between grandparents and either control group, or it was lower in the control group---contrary to expectations (H3).  

## Social Investment Principle

We conducted a preregistered, cross-study, and multi-comparison test of the social investment principle [@robertsPersonalityDevelopmentContext2006; @lodi-smithSocialInvestmentPersonality2007] with grandparenthood as a candidate catalyst of personality change [@huttemanDevelopmentalTasksFramework2014]. We found more evidence of trait stability than of change.  
Still, the direction of the few effects we found generally supported the social investment principle---in contrast to development following parenthood [@asselmannTestingSocialInvestment2020; @vanscheppingenPersonalityTraitDevelopment2016]. Below, we summarize our findings supporting the social investment principle because even small psychological effects may be meaningful and involve real-world consequences [@gotzSmallEffectsIndispensable2021]. For agreeableness and conscientiousness, we found slight post-transition increases in grandfathers compared to matched male controls that were in line with the social investment principle. However, the effects were not only small but also inconsistent across samples. Agreeableness only increased in the LISS (compared to parents) and conscientiousness only in the HRS (compared to nonparents). In the HRS, neuroticism decreased in grandparents directly following the transition to grandparenthood compared to matched parent respondents. This was not the case in the LISS and only at a lower significance level compared to HRS nonparents.  
In contrast, past research---mostly in the domains of well-being and health---found more pronounced effects of the transition to grandparenthood for grandmothers [@digessaBecomingGrandparentIts2019; @digessaImpactCaringGrandchildren2016; @sheppardBecomingFirstTimeGrandparent2019; @tanskanenTransitionGrandparenthoodSubjective2019]. This has been discussed in the context of grandmothers spending more time with their grandchildren than grandfathers and providing more hours of care [@condonAustralianFirsttimeGrandparents2013; @digessaLookingGrandchildrenGender2020], thus making a higher social investment.[^f15] Our results for the Big Five were not in agreement with this line of thought. One possible explanation is that (future) grandfathers were previously more invested in their work lives than in child rearing, and at the end of their career or after retirement, found investments in grandchild care to be a more novel and meaningful transition than grandmothers [@stgeorgeMenExperiencesGrandfatherhood2014; @tanskanenDoesTransitionRetirement2021a]. Currently, however, empirical research specifically on the grandfather role is sparse [for a qualitative approach, see @mannGrandfathersContemporaryFamilies2010], while the demography of grandparenthood is undergoing sweeping changes, with rising proportions of grandfathers actively involved in grandchild care [see @coallNewNicheTheory2016; @mannOutShadowsGrandfatherhood2007]. Thus, more research into grandfathers' experience of the transition to grandparenthood is needed to substantiate our tentative findings.   
We tested paid work and grandchild care as moderators to gain more insight into social investment mechanisms. For conscientiousness, we found that grandparents who were not employed increased in anticipation of the transition to grandparenthood compared to working grandparents (and matched nonworking controls). This could imply that working grandparents did not find as much time for social investment because of the role conflict with the employee/worker role [@goodeTheoryRoleStrain1960; see also, @arpinoJugglingGrandchildCare2022; @tanskanenDoesTransitionRetirement2021a]. Worth noting, we expected these moderation effects after the transition, when grandparents were able to spend time with their grandchild. However, such post-transition differences did not surface. Results for neuroticism were even less in line with the social investment principle: Working grandparents increased in neuroticism in anticipation of the transition to grandparenthood compared to the matched controls. Regarding moderation by grandchild care, our results suggested that grandparents who provided substantial grandchild care increased slightly more in conscientiousness than grandparents who did not. However, the strength of the evidence was weak and indicates a need for temporally more fine-grained assessments with more extensive instruments of grandchild care [e.g., @vermoteImpactNonresidentialGrandchild2021a; see also @fingermanDecadeResearchIntergenerational2020].  
In total, evidence in favor of the social investment principle was very thin, and our analyses do not support the view that becoming a grandparent, in and of itself, changes personality in any meaningful way. This adds to other recent empirical tests in the context of parenthood and romantic relationships [@asselmannTestingSocialInvestment2020; @vanscheppingenPersonalityTraitDevelopment2016; @asselmannTakingUpsDowns2020; @spikicDoesDivorceChange2021] that have challenged the original core assumption of personality maturation through age-graded social role transitions. It now seems likely that distinct (or additional) theoretical assumptions and mechanisms are required to explain empirical findings of personality development in middle and older adulthood. First steps in that direction include the recent distinction between social investment and divestment [@schwabaPersonalityTraitDevelopment2019] in the context of retirement [for the related distinction between personality maturation and relaxation, see @asselmannPersonalityMaturationPersonality2021]. Further, personality development may be more closely tied to subjective perceptions of role competency and mastery than to transitions per se [@robertsYoungAdulthoodCrucible2016; @robertsCriticalEvaluationNeoSocioanalytic2017].  
Nonetheless, the possibility remains that preconditions we have not considered have to be met for grandparents to undergo personality development. For example, grandparents might need to live near their grandchild, see them regularly, and provide care above a certain quantity and quality. To our knowledge, however, there are presently no datasets with such detailed information regarding the grandparent role in conjunction with multiple waves of Big Five personality data. Studies on well-being have provided initial evidence that more frequent contact with grandchildren is associated with higher grandparental well-being [@arpinoGrandparentingEducationSubjective2018; @danielsbackaAssociationGrandparentalInvestment2016; @danielsbackaGrandparentalChildcareHealth2019; @dunifonTimeGrandchildrenSubjective2020]. However, Danielsbacka et al. [-@danielsbackaGrandparentalChildcareHealth2019] noted that this effect is due to between-person differences in grandparents, thus limiting a causal interpretation of frequency of grandchild care as a mechanism of development in psychological characteristics like life satisfaction and personality.  

[^f15]: In the HRS, a higher proportion of first-time grandmothers  (*M* = `r printnum(hrsanalysis_care_parents %>% filter(grandparent==1 & female==1) %>% summarise(mean(caring)))`, *SD* = `r printnum(hrsanalysis_care_parents %>% filter(grandparent==1 & female==1) %>% summarise(sd(caring)))`) than grandfathers (*M* = `r printnum(hrsanalysis_care_parents %>% filter(grandparent==1 & female==0) %>% summarise(mean(caring)))`, *SD* = `r printnum(hrsanalysis_care_parents %>% filter(grandparent==1 & female==0) %>% summarise(sd(caring)))`) reported that they provided at least 100 hours of grandchild care since the last assessment.  

## Life Satisfaction

Similar to our findings on the Big Five personality traits, we did not find convincing evidence that life satisfaction changed due to grandparenthood. As mentioned in the introduction, a study of the effects of the transition on first-time grandparents' life satisfaction that used fixed effects regressions also did not discover any positive within-person effects of the transition [@sheppardBecomingFirstTimeGrandparent2019; see also @atesWellBeingGrandparentsGermany2019]. Further, in line with this study, we did not find evidence that grandparents who provided substantial grandchild care increased more strongly in life satisfaction than those who did not, and grandparents' life satisfaction trajectories were also not moderated by employment status [@sheppardBecomingFirstTimeGrandparent2019].  
Overall, evidence has accumulated that there is an association between having grandchildren and higher life satisfaction on the between-person level---especially for (maternal) non-coresiding grandmothers who provide grandchild care [@danielsbackaAssociationGrandparentalInvestment2016; @danielsbackaGrandparentalChildCare2011; @danielsbackaGrandparentingHealthWellbeing2022]---but no within-person effect of the transition. The main reason for this divergence is the presence of *selection* effects. Specifically, through propensity score matching we controlled for confounding [@vanderweeleOutcomeWideLongitudinalDesigns2020; @thoemmesSystematicReviewPropensity2011; @luhmannStudyingChangesLife2014], but its influence was present in previous studies.  
In an exploratory analysis, Black/African American grandparents---usually lower in life satisfaction compared to White HRS respondents [e.g., @zhangEducationalRacialGender2017]---increased in life satisfaction following the transition to grandparenthood bringing them up on par with White respondents. This is in line with cross-sectional data indicating no ethnic differences in life satisfaction between African American and White grandmothers [@goodmanGrandmothersRaisingGrandchildren2006]. Corroboration of this tentative finding in other samples should be awaited, though.  

## Interindividual Differences in Change

Analyzing how grandparents differed interindividually in their trajectories of change provided additional insight beyond the analysis of mean-level change. All parameters of change exhibited considerable interindividual differences. Similar to Denissen et al. [-@denissenTransactionsLifeEvents2019], who found model fit improvements with random slopes in most models [see also @dorePopulationIndividuallevelChanges2018], respondents---both grandparents and matched controls---deviated to a considerable extent from average trajectories.  
We expected larger interindividual differences in grandparents because life events differ in their impact on daily life and in the degree to which they are perceived as meaningful or emotionally significant [@luhmannDimensionalTaxonomyPerceived2020; @dorePopulationIndividuallevelChanges2018]. Another reason for expecting heterogeneity in the individual trajectories were the considerable differences between grandparents in the amount of grandparental investment [e.g., @danielsbackaGrandparentingHealthWellbeing2022] and competing role demands [e.g., @arpinoJugglingGrandchildCare2022] present in our samples. Our results, however, indicated that interindividual differences were larger in the controls than the grandparents for many models, or not significantly different between groups. Only in a small minority of tests were interindividual differences significantly larger in grandparents (concerning the linear slope in anticipation of grandparenthood for openness and life satisfaction). Overall, we did not find evidence supporting the hypothesis that interindividual differences in change would be larger in the grandparents than the controls (H2).  
It is important to keep in mind that most previous studies do not compare interindividual differences in personality change between an event group and a comparison group [even if they use comparison groups for the main analyses; @denissenTransactionsLifeEvents2019; @schwabaPersonalityTraitDevelopment2019; cf. @jacksonPersonalityDevelopmentMean2021]. Interindividual differences in personality change are substantial up until around 70 years of age [@schwabaIndividualDifferencesPersonality2018]. Regarding the substantive question of how the transition to grandparenthood affects interindividual differences in change, we propose that it is more informative to test grandparents' variability in change against well-matched control groups than against no groups.  
Recently, Jackson and Beck [-@jacksonPersonalityDevelopmentMean2021] presented evidence that the experience of sixteen commonly analyzed life events was mostly associated with decreases in interindividual variation in the Big Five compared to those not experiencing the respective event. They used a comparable approach to ours but in a SEM latent growth curve framework and without accounting for pre-existing group differences (i.e., without matching). Their results based on the German SOEP data suggested---contrary to their expectations---that most life events made people *more* similar to each other [@jacksonPersonalityDevelopmentMean2021]. Thus, taken together with our results, it seems that the assumption that life events and transitions ostensibly produce increased heterogeneity between people needs to be scrutinized in future studies.  

## Rank-Order Stability

We also investigated grandparents' rank-order stability in the Big Five personality traits and life satisfaction. We expected lower stability over the transition to grandparenthood in grandparents compared to the matched controls based on the assumption that grandparents' personality is reorganized through the experience of the event and the addition of the new social role. Conceptually, rank-order stability represents to which extent individual differences endure over time and it can be low even in the absence of mean-level changes if traits change nonsystematically. Empirically, though, we did not find evidence supporting our hypothesis (H3): Descriptively, rank-order stability was highly similar in most comparisons of grandparents and controls, and it was not significantly lower in these comparisons. In a recent study of the effects of eight different life events on the development of the Big Five personality traits and life satisfaction [@denissenTransactionsLifeEvents2019], comparably high rank-order stability was reported in the event groups. Only particularly adverse events such as widowhood and disability significantly lowered respondents' rank-order stability [@denissenTransactionsLifeEvents2019; @chopikDoesPersonalityChange2018].  
Regarding the Big Five's general age trajectories of rank-order stability, support for inverted U-shape trajectories was recently strengthened in a study of two panel data sets [@seifertDevelopmentRankOrderStability2021]. This study also explored that health deterioration accounted for parts of the decline of personality stability in old age. Therefore, it is possible that in later developmental phases [see also @huttemanDevelopmentalTasksFramework2014] rank-order stability of personality is largely influenced by health status and less by normative life events. In the context of grandparenthood, this relates to research into health benefits [@chungLongitudinalEffectsGrandchild2018; @condonTransitionGrandparenthoodProspective2018; @digessaHealthImpactIntensive2016; @digessaImpactCaringGrandchildren2016; cf. @atesDoesGrandchildCare2017] and decreases to mortality risk associated with grandparenthood or grandchild care [@christiansenAssociationGrandparenthoodMortality2014; @choiGrandparentingMortalityHow2020; @hilbrandCaregivingFamilyAssociated2017; cf.  @ellwardtGrandparenthoodRiskMortality2021]. Grandparenthood might therefore have a time-lagged effect on personality stability through protective effects on health. However, with the currently available data, such a mediating effect cannot be reliably recovered [under realistic assumptions; @rohrerThatLotPROCESS2021].  

## Limitations and Future Directions

A number of limitations need to be addressed: First, there remains some doubt whether we were able to follow truly socially invested grandparents over time. More detailed information regarding a grandparent's relationship with their first and later grandchildren and the level of care a grandparent provides would be a valuable source of information on social investment, as would information on constraining factors such as length and cost of travel between grandparent and grandchild. One way to obtain comprehensive information on mechanisms of grandparental development would be a measurement burst design in a sample of grandparents with diverse social backgrounds [see @crawfordIncorporatingEcologicalMomentary2022; @springsteinSupportingRobustResearch2022]. This would allow differentiating contexts of social investment while also providing insight into daily-life social activities [e.g., @dunifonTimeGrandchildrenSubjective2020] and their medium- to long-term influence on personality development [@wrzusProcessesPersonalityDevelopment2017]. On a similar note, we did not examine grandparents' subjective perception of the transition to grandparenthood in terms of the emotional significance, meaningfulness, and impact on daily lives, which might be responsible for differential individual change trajectories [@luhmannDimensionalTaxonomyPerceived2020; @kritzlerHowAreCommon2021; @haehnerPerceptionMajorLife2021]. Grandparents' perception of potential role conflicts [@goodeTheoryRoleStrain1960], and whether they perceive caregiving as a burden or obligation [@xuGrandparentCaregivingPsychological2017], could also uncover mechanisms of personality development.  
Second, a causal interpretation of our results rests on a number of assumptions that are not directly testable with the data [@liUsingPropensityScore2013; @stuartMatchingMethodsCausal2010]: We assumed that we picked the right sets of covariates, that our model to estimate the propensity score was correctly specified, and that there was no substantial remaining bias due to unmeasured confounding. Importantly, we selected covariates following state-of-the-art recommendations and substantiated each covariate's selection explicitly within our preregistration. Regarding the propensity score estimation, we computed grandparents' propensity scores at a specific time point at least two years before the transition to grandparenthood, which had the advantages that (*1*) the covariates were uncontaminated by anticipation of the transition, and (*2*) the matched controls had a clear counterfactual timeline of transition [for similar approaches, see @balboRoleFamilyOrientations2016; @kramerImpactHavingChildren2020; @vanscheppingenTrajectoriesLifeSatisfaction2020]. It also has to be emphasized that the timing of measurements might have missed more short-term effects of grandparenthood playing out over months instead of years.  
Third, our results only pertain to the countries for which our data are representative on a population level: the Netherlands and the United States. Personality development has been examined cross-culturally [e.g., @bleidornPersonalityMaturationWorld2013; @chopikPersonalityChangeLife2018]: On the one hand, these studies showed universal average patterns of positive personality development over the life span. On the other hand, they emphasized cultural differences regarding norms and values and the temporal onset of social roles [see @arshadPracticalRecommendationsConsidering2022]. For grandparenthood, there are substantial demographic differences between countries [@leopoldDemographyGrandparenthoodInternational2015], as well as differences in public child care systems that may demand different levels of grandparental involvement [@bordonePatternsGrandparentalChild2017; @hankGrandparentsCaringTheir2009]. In the Netherlands, people become grandparents six years later on average than in the United States [@leopoldDemographyGrandparenthoodInternational2015]. Furthermore, although both countries have largely market-based systems for early child care, parents in the Netherlands on average have access to more extensive childcare services through (capped) governmental benefits [@oecdChildcareAffordablePolicy2020]. Despite these differences, our results from the Dutch and US samples did not indicate systematic discrepancies.  

## Conclusion
Do personality traits change over the transition to grandparenthood? In two nationally representative panel studies in a preregistered propensity score matching design, Big Five personality traits and life satisfaction remained predominantly stable in first-time grandparents over this transition compared to matched parents and nonparents. We found slight post-transition increases to grandparents' agreeableness and conscientiousness in line with the social investment principle. However, these effects were minuscule and inconsistent across analysis samples. In addition, our analyses revealed (*1*) a lack of consistent moderators of personality development, (*2*) interindividual differences in change that were mostly smaller in grandparents than in matched respondents, and (*3*) comparable rank-order stability in grandparents and matched respondents. Thus, we conclude that the transition to grandparenthood did not act as a straightforwardly important developmental task driving personality development [as previously proposed, see @huttemanDevelopmentalTasksFramework2014]. With more detailed assessment of the grandparent role, future research can investigate whether personality development occurs in grandparents with specific degrees of role investment.  

## Acknowledgements
We thank Joe Rodgers, Jaap Denissen, Oliver Huxhold, and Julia Rohrer for helpful comments on earlier versions of this paper.  

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup

\newpage

# (APPENDIX) Appendix {-}

```{r child = "gp-manuscript-papaja-appendix.Rmd"}
```

